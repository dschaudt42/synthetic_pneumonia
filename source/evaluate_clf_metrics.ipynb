{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import configparser\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import itertools\n",
    "from itertools import cycle\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report,ConfusionMatrixDisplay,RocCurveDisplay,roc_auc_score,roc_curve,auc,precision_recall_fscore_support,accuracy_score, balanced_accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader,WeightedRandomSampler\n",
    "from torch.utils.data import Dataset as BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mean = IMAGENET_DEFAULT_MEAN\n",
    "img_std = IMAGENET_DEFAULT_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_object_to_str(obj):\n",
    "    if isinstance(obj, Path):\n",
    "        return str(obj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_additional_data_frame(folder,num_images=1000):\n",
    "    files = [item for row in [glob.glob(f'{folder}/{x}/*')[:num_images] for x in ['B','C','V','H','F']] for item in row]\n",
    "    file_paths = [Path(x).resolve() for x in files]\n",
    "    file_names = [Path(x).name for x in file_paths]\n",
    "    classes = [Path(x).parent.name for x in file_paths]\n",
    "\n",
    "    df_synth = pd.DataFrame(zip(file_paths,file_names,classes),columns=['file_path','file_name','class'])\n",
    "\n",
    "    df_synth['file_path'] = df_synth['file_path'].apply(lambda x: path_object_to_str(x))\n",
    "    df_synth['file_name'] = df_synth['file_name'].apply(lambda x: path_object_to_str(x))\n",
    "    df_synth['split_old'] = 'train'\n",
    "    df_synth['split'] = 'train'\n",
    "    df_synth['patient_id'] = 'synth'\n",
    "\n",
    "    return df_synth\n",
    "\n",
    "\n",
    "def create_final_dataframe(metadata_file,synth_df):\n",
    "    df = pd.concat([pd.read_csv(metadata_file),synth_df],ignore_index=True)\n",
    "\n",
    "    # encode labels\n",
    "    df['class'] = df['class'].astype('category')\n",
    "    df['label_encoded'] = df['class'].cat.codes.astype('int64')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weak_transforms(img_size,img_mean,img_std):\n",
    "    weak_transforms = A.Compose([\n",
    "                        A.Resize(img_size, img_size),\n",
    "                        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=10, shift_limit=0.1, p=1, border_mode=0),\n",
    "                        A.Normalize(mean=img_mean, std=img_std),\n",
    "                        ToTensorV2(),\n",
    "                    ])\n",
    "    return weak_transforms\n",
    "\n",
    "def get_strong_transforms(img_size,img_mean,img_std):\n",
    "    strong_transforms = A.Compose([\n",
    "                        A.Resize(img_size, img_size),\n",
    "                        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=10, shift_limit=0.1, p=1, border_mode=0),\n",
    "                        A.OneOf(\n",
    "                            [\n",
    "                                A.CLAHE(p=1),\n",
    "                                A.RandomBrightnessContrast(p=1),\n",
    "                                A.RandomGamma(p=1),\n",
    "                            ],\n",
    "                            p=0.9,\n",
    "                        ),\n",
    "                        A.OneOf(\n",
    "                            [\n",
    "                                A.Sharpen(p=1),\n",
    "                                A.Blur(blur_limit=3, p=1),\n",
    "                                A.MotionBlur(blur_limit=3, p=1),\n",
    "                            ],\n",
    "                            p=0.9,\n",
    "                        ),\n",
    "                        A.OneOf(\n",
    "                            [\n",
    "                                A.RandomBrightnessContrast(p=1),\n",
    "                                A.HueSaturationValue(p=1),\n",
    "                            ],\n",
    "                            p=0.9,\n",
    "                        ),\n",
    "                        A.Normalize(mean=img_mean, std=img_std),\n",
    "                        ToTensorV2(),\n",
    "                    ])\n",
    "    return strong_transforms\n",
    "\n",
    "def get_valid_transforms(img_size,img_mean,img_std):\n",
    "    valid_transforms = A.Compose([\n",
    "                        A.Resize(img_size, img_size),\n",
    "                        A.Normalize(mean=img_mean, std=img_std),\n",
    "                        ToTensorV2(),\n",
    "                    ])\n",
    "    return valid_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "    \"\"\"Read images, apply augmentation and preprocessing transformations.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            df,\n",
    "            augmentation=None,\n",
    "            visualize = False\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.ids = self.df.loc[:,'file_name'].values\n",
    "        self.images_fps = self.df.loc[:,'file_path'].values\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.visualize = visualize\n",
    "\n",
    "        self.labels = sorted(self.df['label_encoded'].unique().tolist())\n",
    "        self.label_names = self.df['class'].cat.categories\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        label = self.df.loc[i,'label_encoded']\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image)\n",
    "            image = sample['image']\n",
    "\n",
    "        \n",
    "        # Revert Normalize to visualize the image\n",
    "            if self.visualize:\n",
    "                invTrans = A.Normalize(mean=[-x/y for x,y in zip(img_mean,img_std)],\n",
    "                                       std=[1/x for x in img_std],\n",
    "                                       max_pixel_value=1.0,\n",
    "                                       always_apply=True)\n",
    "                image = image.detach().cpu().numpy().transpose(1,2,0)\n",
    "                image = invTrans(image=image)['image']\n",
    "                image = (image*255).astype(np.uint8)\n",
    "        \n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionModel:\n",
    "    def __init__(self,\n",
    "                 model_architecture,\n",
    "                 num_classes,\n",
    "                 dropout_percent=0.5,\n",
    "                 pretrained=True,\n",
    "                 device='cuda',\n",
    "                 checkpoint=False,\n",
    "                 eval_mode=True):\n",
    "        self.model_architecture = model_architecture\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout_percent = dropout_percent\n",
    "        self.pretrained = pretrained\n",
    "        self.device = torch.device(device)\n",
    "        self.checkpoint=checkpoint\n",
    "        self.eval_mode = eval_mode\n",
    "        \n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        if self.model_architecture == 'convnext_small' or self.model_architecture == 'convnext_tiny':\n",
    "            self.model = timm.create_model(self.model_architecture, pretrained=self.pretrained, num_classes=self.num_classes,drop_rate=self.dropout_percent)\n",
    "\n",
    "        if self.model_architecture == 'efficientnet_b0' or self.model_architecture == 'efficientnet_b1':\n",
    "            self.model = timm.create_model(self.model_architecture, pretrained=self.pretrained, num_classes=self.num_classes)\n",
    "            num_ftrs = self.model.get_classifier().in_features\n",
    "            if self.dropout_percent:\n",
    "                self.model.classifier = nn.Sequential(\n",
    "                                        nn.Dropout(self.dropout_percent),\n",
    "                                        nn.Linear(num_ftrs,self.num_classes)\n",
    "                )\n",
    "            else:\n",
    "                self.model.classifier = nn.Linear(num_ftrs, self.num_classes)\n",
    "\n",
    "        if self.model_architecture == 'resnet50':\n",
    "            self.model = timm.create_model(self.model_architecture, pretrained=self.pretrained, num_classes=self.num_classes)\n",
    "            num_ftrs = self.model.get_classifier().in_features\n",
    "            if self.dropout_percent:\n",
    "                self.model.fc = nn.Sequential(\n",
    "                                        nn.Dropout(self.dropout_percent),\n",
    "                                        nn.Linear(num_ftrs,self.num_classes)\n",
    "                )\n",
    "            else:\n",
    "                self.model.fc = nn.Linear(num_ftrs, self.num_classes)\n",
    "\n",
    "\n",
    "        if self.checkpoint:\n",
    "            self.model.load_state_dict(torch.load(self.checkpoint))\n",
    "        if self.eval_mode:\n",
    "            self.model = self.model.eval()\n",
    "        \n",
    "        self.model = self.model.to(self.device)   \n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    def __init__(self,model,dataset,teacher=False):\n",
    "        self.model = model()\n",
    "        self.model_class = model\n",
    "        self.dataset = dataset\n",
    "        self.teacher = teacher\n",
    "        self.class_ids = self.dataset.labels\n",
    "        self.class_names = self.dataset.label_names\n",
    "        self.label_array = np.array([], dtype='int64')\n",
    "        self.prediction_array = np.array([], dtype='int64')\n",
    "        self.softmax_array = np.array([], dtype='float64')\n",
    "        \n",
    "        self._perform_cls()\n",
    "        self._fpr_tpr_calc()\n",
    "\n",
    "\n",
    "\n",
    "    def _perform_cls(self):\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            for self.images, self.labels in self.dataset:\n",
    "                self.images = self.images.to(self.model_class.device).unsqueeze(0)\n",
    "                #labels = labels.to(device)\n",
    "                self.cls_outputs = self.model(self.images)\n",
    "                self.softmax_array = np.append(self.softmax_array,F.softmax(self.cls_outputs,dim=1).detach().cpu().numpy())\n",
    "                self.softmax_array = np.reshape(self.softmax_array,(-1,self.model.num_classes))\n",
    "                _, self.predicted = torch.max(self.cls_outputs.data, 1)\n",
    "                #_,labels = torch.max(labels.data, 0)\n",
    "                self.label_array = np.append(self.label_array, self.labels)\n",
    "                self.prediction_array = np.append(self.prediction_array, self.predicted.detach().cpu().numpy())\n",
    "        \n",
    "        self.label_array_oh = np.zeros((self.label_array.size, self.label_array.max()+1), dtype=int)\n",
    "        self.label_array_oh[np.arange(self.label_array.size),self.label_array] = 1\n",
    "    \n",
    "    @property\n",
    "    def print_cls_report(self):\n",
    "        return classification_report(self.label_array, self.prediction_array, digits=4,zero_division=0)\n",
    "    \n",
    "    @property\n",
    "    def cls_report(self):\n",
    "        pre_rec_fs_sups = dict()\n",
    "        \n",
    "        for label in ['micro','macro','weighted']:\n",
    "            prfs = precision_recall_fscore_support(\n",
    "                self.label_array,\n",
    "                self.prediction_array,\n",
    "                average=label,\n",
    "                zero_division=0\n",
    "            )\n",
    "            \n",
    "            \n",
    "            pre_rec_fs_sups[label] = {'precision' : prfs[0],\n",
    "                                      'recall' : prfs[1],\n",
    "                                      'f1-score' : prfs[2],\n",
    "                                      'support' : prfs[3]\n",
    "                                     }\n",
    "        \n",
    "        per_label_prfs = precision_recall_fscore_support(\n",
    "            self.label_array,\n",
    "            self.prediction_array,\n",
    "            average=None,\n",
    "            zero_division=0\n",
    "        )\n",
    "        \n",
    "        for class_id in self.class_ids:\n",
    "                pre_rec_fs_sups[class_id] = {'precision':per_label_prfs[0][class_id],\n",
    "                                             'recall': per_label_prfs[1][class_id],\n",
    "                                             'f1-score' : per_label_prfs[2][class_id],\n",
    "                                             'support' : per_label_prfs[3][class_id]\n",
    "                                            }\n",
    "                \n",
    "        \n",
    "        acc = accuracy_score(self.label_array,self.prediction_array)\n",
    "        pre_rec_fs_sups['accuracy'] = acc\n",
    "\n",
    "        bal_acc = balanced_accuracy_score(self.label_array,self.prediction_array)\n",
    "        pre_rec_fs_sups['balanced_accuracy'] = bal_acc\n",
    "        \n",
    "        return pre_rec_fs_sups\n",
    "    \n",
    "    @property\n",
    "    def auc(self):\n",
    "        aucs = dict()\n",
    "        for label in ['micro','macro','weighted']:\n",
    "            aucs[label] = roc_auc_score(\n",
    "                self.label_array_oh,\n",
    "                self.softmax_array,\n",
    "                multi_class=\"ovr\",\n",
    "                average=label,\n",
    "            )\n",
    "        \n",
    "        aucs['macro_ovo'] = roc_auc_score(\n",
    "                self.label_array_oh,\n",
    "                self.softmax_array,\n",
    "                multi_class=\"ovo\",\n",
    "                average='macro',\n",
    "        )\n",
    "        \n",
    "        per_label_auc = roc_auc_score(\n",
    "            self.label_array_oh,\n",
    "            self.softmax_array,\n",
    "            multi_class=\"ovr\",\n",
    "            average=None,\n",
    "        )   \n",
    "        \n",
    "        for i,value in enumerate(per_label_auc):\n",
    "            aucs[f'{i}'] = value\n",
    "\n",
    "        return aucs\n",
    "    \n",
    "    def _fpr_tpr_calc(self):\n",
    "        fpr_grid = np.linspace(0.0, 1.0, 1000)\n",
    "        # store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "        self.fpr, self.tpr, self.roc_auc = dict(), dict(), dict()\n",
    "        # Compute micro-average ROC curve and ROC area for OvR strategy\n",
    "        self.fpr[\"micro\"], self.tpr[\"micro\"], _ = roc_curve(self.label_array_oh.ravel(), self.softmax_array.ravel(),drop_intermediate=True)\n",
    "        self.roc_auc[\"micro\"] = auc(self.fpr[\"micro\"], self.tpr[\"micro\"])\n",
    "        \n",
    "        interp_tpr = np.interp(fpr_grid,self.fpr['micro'],self.tpr['micro'])\n",
    "        interp_tpr[0] = 0.0\n",
    "        self.fpr['micro'] = fpr_grid\n",
    "        self.tpr['micro'] = interp_tpr\n",
    "        \n",
    "        \n",
    "        self.tresholds = dict()\n",
    "        for i in range(self.model.num_classes):\n",
    "            self.fpr[i], self.tpr[i], self.tresholds[i] = roc_curve(self.label_array_oh[:, i], self.softmax_array[:, i])\n",
    "            self.roc_auc[i] = auc(self.fpr[i], self.tpr[i])\n",
    "\n",
    "        # Interpolate all ROC curves at these points\n",
    "        mean_tpr = np.zeros_like(fpr_grid)\n",
    "\n",
    "        for i in range(self.model.num_classes):\n",
    "            mean_tpr += np.interp(fpr_grid, self.fpr[i], self.tpr[i])  # linear interpolation\n",
    "\n",
    "        # Average it and compute AUC\n",
    "        mean_tpr /= self.model.num_classes\n",
    "\n",
    "        self.fpr[\"macro\"] = fpr_grid\n",
    "        self.tpr[\"macro\"] = mean_tpr\n",
    "        self.roc_auc[\"macro\"] = auc(self.fpr[\"macro\"], self.tpr[\"macro\"])\n",
    "        \n",
    "        # Compute macro-average ROC curve and ROC area for OvO strategy\n",
    "        pair_list = list(combinations(self.class_ids,2))\n",
    "        \n",
    "        pair_scores = []\n",
    "        self.tpr['macro_ovo'] = np.zeros_like(fpr_grid)\n",
    "        mean_tpr = dict()\n",
    "        for ix, (label_a, label_b) in enumerate(pair_list):\n",
    "\n",
    "            a_mask = self.label_array == label_a\n",
    "            b_mask = self.label_array == label_b\n",
    "            ab_mask = np.logical_or(a_mask, b_mask)\n",
    "\n",
    "            a_true = a_mask[ab_mask]\n",
    "            b_true = b_mask[ab_mask]\n",
    "\n",
    "            idx_a = np.flatnonzero(np.array(self.class_ids) == label_a)[0]\n",
    "            idx_b = np.flatnonzero(np.array(self.class_ids) == label_b)[0]\n",
    "\n",
    "            fpr_a, tpr_a, _ = roc_curve(a_true, self.softmax_array[ab_mask, idx_a])\n",
    "            fpr_b, tpr_b, _ = roc_curve(b_true, self.softmax_array[ab_mask, idx_b])\n",
    "\n",
    "            mean_tpr[ix] = np.zeros_like(fpr_grid)\n",
    "            mean_tpr[ix] += np.interp(fpr_grid, fpr_a, tpr_a)\n",
    "            mean_tpr[ix] += np.interp(fpr_grid, fpr_b, tpr_b)\n",
    "            mean_tpr[ix] /= 2\n",
    "            mean_score = auc(fpr_grid, mean_tpr[ix])\n",
    "            pair_scores.append(mean_score)\n",
    "            self.tpr['macro_ovo'] += mean_tpr[ix]\n",
    "            \n",
    "        self.tpr['macro_ovo'] /= sum(1 for pair in enumerate(pair_list))\n",
    "        self.fpr['macro_ovo'] = fpr_grid\n",
    "        self.roc_auc['macro_ovo'] = np.average(pair_scores)\n",
    "    \n",
    "    def roc(self,contents=[]):\n",
    "        assert contents is not None\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        \n",
    "        colors = cycle([\"tab:blue\",\"tab:orange\",\"tab:green\",\"tab:red\",\"tab:purple\",\"tab:brown\"])\n",
    "        \n",
    "        for class_id, color in zip([x for x in contents if x not in ['micro','macro']], colors):\n",
    "            plt.plot(\n",
    "                self.fpr[class_id],\n",
    "                self.tpr[class_id],\n",
    "                label=f\"ROC curve for {class_id} (AUC = {self.roc_auc[class_id]:.2f})\",\n",
    "                color=color     \n",
    "            )\n",
    "        \n",
    "        if 'micro' in contents:\n",
    "            plt.plot(\n",
    "                self.fpr[\"micro\"],\n",
    "                self.tpr[\"micro\"],\n",
    "                label=f\"micro-average ROC curve (AUC = {self.roc_auc['micro']:.2f})\",\n",
    "                color=\"deeppink\",\n",
    "                linestyle=\":\",\n",
    "                linewidth=4,\n",
    "            )\n",
    "        \n",
    "        if 'macro' in contents:\n",
    "            plt.plot(\n",
    "                self.fpr[\"macro\"],\n",
    "                self.tpr[\"macro\"],\n",
    "                label=f\"macro-average ROC curve (AUC = {self.roc_auc['macro']:.2f})\",\n",
    "                color=\"navy\",\n",
    "                linestyle=\":\",\n",
    "                linewidth=4,\n",
    "            )\n",
    "            \n",
    "        plt.plot([0, 1], [0, 1], \"k--\")\n",
    "        plt.axis(\"square\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"Receiver Operating Characteristic\")\n",
    "        plt.legend()\n",
    "        return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_cls_report(ev_models,labels,folds,digits=4):\n",
    "    cv_cls_report = {}\n",
    "    labels.extend(['micro','macro', 'weighted'])\n",
    "    folds = range(folds)\n",
    "    accs = []\n",
    "    bal_accs = []\n",
    "    for fold in folds:\n",
    "        accs.append(ev_models[fold].cls_report['accuracy'])\n",
    "        bal_accs.append(ev_models[fold].cls_report['balanced_accuracy'])\n",
    "\n",
    "    cv_cls_report['accuracy'] = [round(np.mean(accs),digits),round(np.std(accs),digits)]\n",
    "    cv_cls_report['balanced_accuracy'] = [round(np.mean(bal_accs),digits),round(np.std(bal_accs),digits)]\n",
    "\n",
    "    avg_prec = {}\n",
    "    avg_rec = {}\n",
    "    avg_f1 = {}\n",
    "    for label in labels:\n",
    "        precs = []\n",
    "        recs = []\n",
    "        f1s = []\n",
    "        sups = []\n",
    "        for fold in folds:\n",
    "            precs.append(ev_models[fold].cls_report[label]['precision'])\n",
    "            recs.append(ev_models[fold].cls_report[label]['recall'])\n",
    "            f1s.append(ev_models[fold].cls_report[label]['f1-score'])\n",
    "            \n",
    "        avg_prec[label] = [round(np.mean(precs),digits),round(np.std(precs),digits)]\n",
    "        avg_rec[label] = [round(np.mean(recs),digits),round(np.std(recs),digits)]\n",
    "        avg_f1[label] = [round(np.mean(f1s),digits),round(np.std(f1s),digits)]\n",
    "\n",
    "        metric_dict = {}\n",
    "        metric_dict['precision'] = avg_prec[label]\n",
    "        metric_dict['recall'] = avg_rec[label]\n",
    "        metric_dict['f1-score'] = avg_f1[label]\n",
    "        cv_cls_report[label] = metric_dict\n",
    "        \n",
    "    return cv_cls_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_auc(ev_models,contents,n_folds,digits=4):\n",
    "    avg_auc = {}\n",
    "    for class_id in contents:\n",
    "        values = []\n",
    "        for fold in range(n_folds):\n",
    "            if class_id == 'weighted':\n",
    "                values.append(ev_models[fold].auc[class_id])\n",
    "            else:\n",
    "                values.append(ev_models[fold].roc_auc[class_id])\n",
    "        avg_auc[class_id] = [round(np.mean(values),digits),round(np.std(values),digits)]\n",
    "    return avg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_roc(ev_models,contents,folds,ax,title='Receiver Operating Characteristic',save=None):\n",
    "    avg_tpr = {}\n",
    "    avg_fpr = {}\n",
    "    avg_auc = {}\n",
    "    std_auc = {}\n",
    "\n",
    "    colors = cycle([\"tab:blue\",\"tab:orange\",\"tab:green\",\"tab:red\",\"tab:purple\",\"tab:brown\"])\n",
    "\n",
    "    for class_id, color in zip([x for x in contents if x not in ['micro','macro','macro_ovo']], colors):\n",
    "        fpr_grid = np.linspace(0.0, 1.0, 1000)\n",
    "        mean_tpr = np.zeros_like(fpr_grid)\n",
    "        aucs = []\n",
    "        for fold in range(folds):\n",
    "            mean_tpr += np.interp(fpr_grid, ev_models[fold].fpr[class_id], ev_models[fold].tpr[class_id])\n",
    "            aucs.append(ev_models[fold].roc_auc[class_id])\n",
    "\n",
    "        avg_tpr[class_id] = mean_tpr / folds\n",
    "        avg_fpr[class_id] = fpr_grid\n",
    "        avg_auc[class_id] = np.mean(aucs)\n",
    "        std_auc[class_id] = np.std(aucs)\n",
    "        \n",
    "        ax.plot(\n",
    "            avg_fpr[class_id],\n",
    "            avg_tpr[class_id],\n",
    "            label=f\"Severity {class_id} (AUC = {avg_auc[class_id]:.2f} $\\pm$ {std_auc[class_id]:.2f})\" if class_id != 0 else f\"Healthy (AUC = {avg_auc[class_id]:.2f} $\\pm$ {std_auc[class_id]:.2f})\",\n",
    "            color=color     \n",
    "        )\n",
    "        \n",
    "    if 'micro' in contents:\n",
    "        tprs = []\n",
    "        fprs = []\n",
    "        aucs = []\n",
    "        for fold in range(folds):\n",
    "            tprs.append(ev_models[fold].tpr['micro'])\n",
    "            fprs.append(ev_models[fold].fpr['micro'])\n",
    "            aucs.append(ev_models[fold].roc_auc['micro'])\n",
    "        avg_fpr[\"micro\"] = np.mean(fprs,axis=0)\n",
    "        avg_tpr[\"micro\"] = np.mean(tprs,axis=0)\n",
    "        avg_auc[\"micro\"] = np.mean(aucs)\n",
    "        std_auc[\"micro\"] = np.std(aucs)\n",
    "         \n",
    "        ax.plot(\n",
    "            avg_fpr[\"micro\"],\n",
    "            avg_tpr[\"micro\"],\n",
    "            label=f\"micro-average (AUC = {avg_auc['micro']:.2f} $\\pm$ {std_auc['micro']:.2f})\",\n",
    "            color=\"deeppink\",\n",
    "            linestyle=\":\",\n",
    "            linewidth=4,\n",
    "        )\n",
    "        \n",
    "    if 'macro' in contents:\n",
    "        tprs = []\n",
    "        fprs = []\n",
    "        aucs = []\n",
    "        for fold in range(folds):\n",
    "            tprs.append(ev_models[fold].tpr['macro'])\n",
    "            fprs.append(ev_models[fold].fpr['macro'])\n",
    "            aucs.append(ev_models[fold].roc_auc['macro'])\n",
    "        avg_fpr[\"macro\"] = np.mean(fprs,axis=0)\n",
    "        avg_tpr[\"macro\"] = np.mean(tprs,axis=0)\n",
    "        avg_auc[\"macro\"] = np.mean(aucs)\n",
    "        std_auc[\"macro\"] = np.std(aucs)\n",
    "            \n",
    "        ax.plot(\n",
    "            avg_fpr[\"macro\"],\n",
    "            avg_tpr[\"macro\"],\n",
    "            label=f\"macro-average (AUC = {avg_auc['macro']:.2f} $\\pm$ {std_auc['macro']:.2f})\",\n",
    "            color=\"navy\",\n",
    "            linestyle=\":\",\n",
    "            linewidth=4,\n",
    "        )\n",
    "        \n",
    "    if 'macro_ovo' in contents:\n",
    "        tprs = []\n",
    "        fprs = []\n",
    "        aucs = []\n",
    "        for fold in range(folds):\n",
    "            tprs.append(ev_models[fold].tpr['macro_ovo'])\n",
    "            fprs.append(ev_models[fold].fpr['macro_ovo'])\n",
    "            aucs.append(ev_models[fold].roc_auc['macro_ovo'])\n",
    "        avg_fpr[\"macro_ovo\"] = np.mean(fprs,axis=0)\n",
    "        avg_tpr[\"macro_ovo\"] = np.mean(tprs,axis=0)\n",
    "        avg_auc[\"macro_ovo\"] = np.mean(aucs)\n",
    "        std_auc[\"macro_ovo\"] = np.std(aucs)\n",
    "            \n",
    "        ax.plot(\n",
    "            avg_fpr[\"macro\"],\n",
    "            avg_tpr[\"macro\"],\n",
    "            label=f\"OvO macro-average (AUC = {avg_auc['macro_ovo']:.2f} $\\pm$ {std_auc['macro_ovo']:.2f})\",\n",
    "            color=\"cyan\",\n",
    "            linestyle=\":\",\n",
    "            linewidth=4,\n",
    "        )\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], \"k--\")\n",
    "    ax.axis(\"square\")\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment(name):\n",
    "    config_file = f'configs/{name}_config.txt'\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_file)\n",
    "\n",
    "    model_dir = config['settings']['model_dir']\n",
    "    repeated_runs = int(config['settings']['repeated_runs'])\n",
    "    additional_data_folder = config['settings']['additional_data_folder']\n",
    "    metadata_file = config['settings']['metadata_file']\n",
    "    num_images = eval(config['settings']['num_synth_images'])\n",
    "    resolution = int(config['model']['resolution'])\n",
    "\n",
    "    if 'model' in config:\n",
    "        dropout_percent = float(config['model']['dropout_percent'])\n",
    "        model_architecture = config['model']['model_architecture']\n",
    "    else:\n",
    "        dropout_percent = (float(config['teacher']['dropout_percent']),float(config['student']['dropout_percent']))\n",
    "        model_architecture = (config['teacher']['model_architecture'],config['student']['model_architecture'])\n",
    "\n",
    "    return model_dir, model_architecture, dropout_percent, repeated_runs, resolution, additional_data_folder, metadata_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(experiment_name,model_architecture,plot_type,repeated_runs,additional_images,ax,student_losses=[]):\n",
    "\n",
    "    logs = pd.read_csv(f'logs/{experiment_name}_{model_architecture}_{additional_images}_metrics.csv')\n",
    "\n",
    "    train_values = []\n",
    "    valid_values = []\n",
    "    for fold in range(repeated_runs):\n",
    "        train_values.append(logs[f'fold{fold}_train_{plot_type}'].values)\n",
    "        valid_values.append(logs[f'fold{fold}_val_{plot_type}'].values)\n",
    "    \n",
    "    mean_train_values = np.mean(train_values,axis=0)\n",
    "    mean_valid_values = np.mean(valid_values,axis=0)\n",
    "\n",
    "    \n",
    "    for values in train_values:\n",
    "        ax.plot(range(len(logs)),values,color=\"tab:blue\",linewidth=1,alpha=0.3)\n",
    "\n",
    "        \n",
    "    label = f'Train {plot_type}'\n",
    "        \n",
    "    ax.plot(range(len(logs)),mean_train_values,label=label,color=\"tab:blue\",linewidth=3)\n",
    "\n",
    "    for values in valid_values:\n",
    "        ax.plot(range(len(logs)),values,color=\"tab:orange\",linewidth=1,alpha=0.3)\n",
    "        \n",
    "    # Plot mean\n",
    "    ax.plot(range(len(logs)),mean_valid_values,label=f'Valid {plot_type}',color=\"tab:orange\",linewidth=3)\n",
    "\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy' if plot_type=='acc' else 'Loss')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(ev_models,repeated_runs):\n",
    "    metrics_list = []\n",
    "    rep = cv_cls_report(ev_models,[0,1,2,3,4],repeated_runs)\n",
    "    for label in [0,1,2,3,4]:\n",
    "        for metric in ['precision','recall','f1-score']:\n",
    "            for value in [0,1]:\n",
    "                metrics_list.append(rep[label][metric][value])\n",
    "\n",
    "    acc_mean = rep['accuracy'][0]\n",
    "    acc_std = rep['accuracy'][1]\n",
    "    bal_acc_mean = rep['balanced_accuracy'][0]\n",
    "    bal_acc_std = rep['balanced_accuracy'][1]\n",
    "\n",
    "    return metrics_list,acc_mean,acc_std,bal_acc_mean,bal_acc_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_save_metrics(experiment_names,additional_images,csv_name):\n",
    "    vm_list = []\n",
    "    ev_list = []\n",
    "    metrics_dict_all = {}\n",
    "    acc_mean_all = []\n",
    "    acc_std_all = []\n",
    "    bal_acc_mean_all = []\n",
    "    bal_acc_std_all = []\n",
    "\n",
    "    for experiment in experiment_names:\n",
    "        model_dir, model_architecture, dropout_percent, repeated_runs, resolution, additional_data_folder, metadata_file = load_experiment(experiment)\n",
    "\n",
    "        vision_models = {}\n",
    "        ev_models = {}\n",
    "\n",
    "        df_synth = create_additional_data_frame(additional_data_folder,num_images=additional_images)\n",
    "        df = create_final_dataframe(metadata_file,df_synth)\n",
    "\n",
    "        valid_dataset = Dataset(\n",
    "            df[df['split']=='valid'],\n",
    "            augmentation=get_valid_transforms(resolution,img_mean,img_std), \n",
    "        )\n",
    "\n",
    "        for fold in range(repeated_runs):\n",
    "            vision_models[fold] = VisionModel(model_architecture,\n",
    "                                        num_classes=5,\n",
    "                                        dropout_percent=dropout_percent,\n",
    "                                        checkpoint=f'./{model_dir}/{experiment}_{model_architecture}_images_{additional_images}_run_{fold}.pth')\n",
    "        \n",
    "            ev_models[fold] = Evaluate(vision_models[fold],valid_dataset)\n",
    "\n",
    "        vm_list.append(vision_models)\n",
    "        ev_list.append(ev_models)\n",
    "\n",
    "        metrics_list, acc_mean, acc_std, bal_acc_mean, bal_acc_std = get_metrics(ev_models,repeated_runs)\n",
    "        metrics_dict_all[experiment] = metrics_list\n",
    "        acc_mean_all.append(acc_mean)\n",
    "        acc_std_all.append(acc_std)\n",
    "        bal_acc_mean_all.append(bal_acc_mean)\n",
    "        bal_acc_std_all.append(bal_acc_std)\n",
    "\n",
    "        fig, axs = plt.subplots(1,2,figsize=(10,4),dpi=150)\n",
    "        plot_loss_curve(experiment,model_architecture,plot_type='acc',repeated_runs=repeated_runs,additional_images=additional_images,ax=axs[0])\n",
    "        plot_loss_curve(experiment,model_architecture,plot_type='loss',repeated_runs=repeated_runs,additional_images=additional_images,ax=axs[1])\n",
    "        plt.savefig(f'export/{experiment}_images_{additional_images}_acc_loss_curve.png')\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame.from_dict(metrics_dict_all,orient='index')\n",
    "    df.columns = pd.MultiIndex.from_product([[0,1,2,3,4],['Prec','Rec','F1'],['mean','std']])\n",
    "    df['acc_mean'] = acc_mean_all\n",
    "    df['acc_std'] = acc_std_all\n",
    "    df['bal_acc_mean'] = bal_acc_mean_all\n",
    "    df['bal_acc_std'] = bal_acc_std_all\n",
    "\n",
    "    df.to_csv(f'export/clf_metrics/{csv_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metric_for_latex(df,model_index,metric_index):\n",
    "    print(df.transpose().iloc[0,model_index])\n",
    "    f = ''\n",
    "    for i,value in enumerate(df.transpose().iloc[metric_index,model_index].values):\n",
    "        if (i % 2) == 0:\n",
    "            f = f+str(value)+' $\\\\pm$ '\n",
    "        else:\n",
    "            f = f+str(value)+' & '\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_table_latex(df,methods,models,metrics):\n",
    "    text = ''\n",
    "    for i,method in enumerate(methods):\n",
    "        text = text + method + ' & '\n",
    "        for k,(model,metric) in enumerate(itertools.product(models,metrics)):\n",
    "            if len(metrics) == 2:\n",
    "                if (k % 2) == 0:\n",
    "                    text = text + str(round(df.loc[df['method']==method,f'{model}_{metric}'].item()*100,2))+' $\\\\pm$ '\n",
    "                else:\n",
    "                    text = text + str(round(df.loc[df['method']==method,f'{model}_{metric}'].item()*100,2))+' & '\n",
    "            else:\n",
    "                text = text + str(round(df.loc[df['method']==method,f'{model}_{metric}'].item()*100,2))+' & '\n",
    "        text = text[:-2] + '\\\\\\\\' +'\\n'\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pivot_table(df,metric=['acc_mean','acc_std']):\n",
    "    df.loc[df['model'].str.contains('gan'),'method'] = 'gan'\n",
    "    df.loc[df['model'].str.contains('sd_finetuning'),'method'] = 'finetuning'\n",
    "    df.loc[df['model'].str.contains('sd_dreambooth'),'method'] = 'dreambooth'\n",
    "    df.loc[df['model'].str.contains('unconditional'),'method'] = 'unconditional'\n",
    "    df.loc[df['model'].str.contains('sd_lora_1e5_scale1'),'method'] = 'lora'\n",
    "\n",
    "    df.loc[df['model'].str.contains('ConvNeXt_small'),'model'] = 'ConvNeXt_small'\n",
    "    df.loc[df['model'].str.contains('ConvNeXt_tiny'),'model'] = 'ConvNeXt_tiny'\n",
    "    df.loc[df['model'].str.contains('EB0'),'model'] = 'EB0'\n",
    "    df.loc[df['model'].str.contains('EB1'),'model'] = 'EB1'\n",
    "    df.loc[df['model'].str.contains('ResNet50'),'model'] = 'ResNet50'\n",
    "\n",
    "    df_pivot = df[['model','method']+metric].pivot(columns='model',index='method')\n",
    "    df_pivot.columns = df[['model','method']+metric].pivot(columns='model',index='method').columns.swaplevel()\n",
    "\n",
    "    df_pivot.sort_index(axis=1, level=0, inplace=True)\n",
    "    df_pivot.columns = ['_'.join(col) for col in df_pivot.columns.values]\n",
    "    df_pivot.reset_index(inplace=True)\n",
    "\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_means_latex(df,metric='acc'):\n",
    "    mean_list = [round(x*100,2) for x in df[[f'ResNet50_{metric}_mean',f'EB0_{metric}_mean',f'EB1_{metric}_mean',f'ConvNeXt_tiny_{metric}_mean',f'ConvNeXt_small_{metric}_mean']].mean().to_list()]\n",
    "    total_mean = round(np.mean(df[[f'ResNet50_{metric}_mean',f'EB0_{metric}_mean',f'EB1_{metric}_mean',f'ConvNeXt_tiny_{metric}_mean',f'ConvNeXt_small_{metric}_mean']].values)*100,2)\n",
    "\n",
    "    text = ''\n",
    "    for value in mean_list+[total_mean]:\n",
    "        text = text + str(value) + ' & '\n",
    "\n",
    "    text = text[:-2] + '\\\\\\\\' +'\\n'\n",
    "\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_plain_values_to_latex(df,rounding=False,mean_std=False):\n",
    "    text = ''\n",
    "    \n",
    "    if mean_std:\n",
    "        for row in df.index:\n",
    "            text = text + str(row) + ' & '\n",
    "\n",
    "            for k,column in enumerate(df.columns):\n",
    "                if (k % 2) == 0:\n",
    "                    if rounding:\n",
    "                        text = text + str(round(df.loc[row,column]*100,2)) +' $\\\\pm$ '\n",
    "                    else:\n",
    "                        text = text + str(df.loc[row,column]) + ' $\\\\pm$ '\n",
    "                else:\n",
    "                    if rounding:\n",
    "                        text = text + str(round(df.loc[row,column]*100,2)) + ' & '\n",
    "                    else:\n",
    "                        text = text + str(df.loc[row,column]) + ' & '\n",
    "\n",
    "            text = text[:-2] + '\\\\\\\\' +'\\n'\n",
    "    else:\n",
    "        for row in df.index:\n",
    "            text = text + str(row) + ' & '\n",
    "\n",
    "            for column in df.columns:\n",
    "                if rounding:\n",
    "                    text = text + str(round(df.loc[row,column]*100,2)) + ' & '\n",
    "                else:\n",
    "                    text = text + str(df.loc[row,column]) + ' & '\n",
    "\n",
    "            text = text[:-2] + '\\\\\\\\' +'\\n'\n",
    "\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['ResNet50','EB0','EB1','ConvNeXt_tiny','ConvNeXt_small']\n",
    "metrics = ['acc_mean','acc_std']\n",
    "methods = ['dreambooth','finetuning','gan','lora','unconditional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_accs = {'ConvNeXt_small_acc_mean' : 0.7853,\n",
    "                 'ConvNeXt_tiny_acc_mean' : 0.7825, \n",
    "                 'EB0_acc_mean' : 0.7871,\n",
    "                 'EB1_acc_mean' : 0.7760, \n",
    "                 'ResNet50_acc_mean' : 0.7825}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_bal_accs = {'ConvNeXt_small_bal_acc_mean' : 0.5478,\n",
    "                 'ConvNeXt_tiny_bal_acc_mean' : 0.5635, \n",
    "                 'EB0_bal_acc_mean' : 0.5400,\n",
    "                 'EB1_bal_acc_mean' : 0.5522, \n",
    "                 'ResNet50_bal_acc_mean' : 0.5222}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {0 : 'B',\n",
    "                 1 : 'C',\n",
    "                 2 : 'H',\n",
    "                 3 : 'F',\n",
    "                 4 : 'V'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>0_Prec_mean</th>\n",
       "      <th>0_Prec_std</th>\n",
       "      <th>0_Rec_mean</th>\n",
       "      <th>0_Rec_std</th>\n",
       "      <th>0_F1_mean</th>\n",
       "      <th>0_F1_std</th>\n",
       "      <th>1_Prec_mean</th>\n",
       "      <th>1_Prec_std</th>\n",
       "      <th>1_Rec_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>4_Prec_mean</th>\n",
       "      <th>4_Prec_std</th>\n",
       "      <th>4_Rec_mean</th>\n",
       "      <th>4_Rec_std</th>\n",
       "      <th>4_F1_mean</th>\n",
       "      <th>4_F1_std</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>bal_acc_mean</th>\n",
       "      <th>bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ConvNeXt_small_Baseline</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.3474</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>0.3307</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>0.8292</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.7853</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.0091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvNeXt_tiny_Baseline</td>\n",
       "      <td>0.3534</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.3579</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.7218</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3369</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.1854</td>\n",
       "      <td>0.2903</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>0.0236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EB0_Baseline</td>\n",
       "      <td>0.2952</td>\n",
       "      <td>0.1805</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.1295</td>\n",
       "      <td>0.6999</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.7739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1152</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0935</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>0.7871</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.0246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EB1_Baseline</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>0.7652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3607</td>\n",
       "      <td>0.0746</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.3842</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.7760</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.5522</td>\n",
       "      <td>0.0294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ResNet50_Baseline</td>\n",
       "      <td>0.3107</td>\n",
       "      <td>0.2539</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.7188</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.1091</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>0.0136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model 0_Prec_mean 0_Prec_std 0_Rec_mean 0_Rec_std  \\\n",
       "2  ConvNeXt_small_Baseline       0.326     0.0498     0.3474    0.0976   \n",
       "3   ConvNeXt_tiny_Baseline      0.3534     0.0405     0.3579    0.1021   \n",
       "4             EB0_Baseline      0.2952     0.1805     0.1474    0.1021   \n",
       "5             EB1_Baseline      0.2273     0.1211     0.1158    0.0698   \n",
       "6        ResNet50_Baseline      0.3107     0.2539     0.0947    0.0614   \n",
       "\n",
       "  0_F1_mean 0_F1_std 1_Prec_mean 1_Prec_std 1_Rec_mean  ... 4_Prec_mean  \\\n",
       "2    0.3307   0.0579      0.8292     0.0573     0.7478  ...      0.1329   \n",
       "3    0.3515   0.0707      0.7218     0.0693        0.8  ...      0.3369   \n",
       "4    0.1959   0.1295      0.6999     0.0435     0.7739  ...      0.1152   \n",
       "5    0.1526   0.0878       0.665     0.0782     0.7652  ...      0.3607   \n",
       "6    0.1428    0.095      0.7188     0.1223     0.7043  ...      0.0545   \n",
       "\n",
       "  4_Prec_std 4_Rec_mean 4_Rec_std 4_F1_mean 4_F1_std acc_mean acc_std  \\\n",
       "2     0.1097        0.1    0.0848    0.1136   0.0949   0.7853  0.0037   \n",
       "3     0.0778     0.3125    0.1854    0.2903   0.0981   0.7825  0.0147   \n",
       "4     0.1029        0.1    0.0935    0.1069   0.0977   0.7871  0.0122   \n",
       "5     0.0746      0.425    0.1075    0.3842   0.0738   0.7760  0.0119   \n",
       "6     0.1091      0.075      0.15    0.0632   0.1263   0.7825  0.0114   \n",
       "\n",
       "  bal_acc_mean bal_acc_std  \n",
       "2       0.5478      0.0091  \n",
       "3       0.5635      0.0236  \n",
       "4       0.5400      0.0246  \n",
       "5       0.5522      0.0294  \n",
       "6       0.5222      0.0136  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../KD_Paper/Revision/export/model_metrics_do_balacc.csv')\n",
    "df.columns = ['model']+[f'{x}_{y}_{z}' for x,y,z in itertools.product([0,1,2,3,4],['Prec','Rec','F1'],['mean','std'])]+['acc_mean','acc_std','bal_acc_mean','bal_acc_std']\n",
    "df.drop(index=[0,1],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df,metric=['acc_mean','acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot['method'] = 'Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_pivot[['method','ResNet50_acc_mean','ResNet50_acc_std','EB0_acc_mean',\n",
    "                     'EB0_acc_std','EB1_acc_mean','EB1_acc_std','ConvNeXt_tiny_acc_mean',\n",
    "                     'ConvNeXt_tiny_acc_std','ConvNeXt_small_acc_mean','ConvNeXt_small_acc_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline & 78.25 $\\pm$ 1.14 & 78.71 $\\pm$ 1.22 & 77.6 $\\pm$ 1.19 & 78.25 $\\pm$ 1.47 & 78.53 $\\pm$ 0.37 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_plain_values_to_latex(df_pivot.set_index('method'),rounding=True,mean_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df,metric=['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot['method'] = 'Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_pivot[['method','ResNet50_bal_acc_mean','ResNet50_bal_acc_std','EB0_bal_acc_mean',\n",
    "                     'EB0_bal_acc_std','EB1_bal_acc_mean','EB1_bal_acc_std','ConvNeXt_tiny_bal_acc_mean',\n",
    "                     'ConvNeXt_tiny_bal_acc_std','ConvNeXt_small_bal_acc_mean','ConvNeXt_small_bal_acc_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline & 52.22 $\\pm$ 1.36 & 54.0 $\\pm$ 2.46 & 55.22 $\\pm$ 2.94 & 56.35 $\\pm$ 2.36 & 54.78 $\\pm$ 0.91 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_plain_values_to_latex(df_pivot.set_index('method'),rounding=True,mean_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_names = ['ConvNeXt_small_gan','ConvNeXt_tiny_gan','EB0_gan','EB1_gan','ResNet50_gan',\n",
    "#                    'ConvNeXt_small_sd_finetuning','ConvNeXt_tiny_sd_finetuning','EB0_sd_finetuning','EB1_sd_finetuning','ResNet50_sd_finetuning',\n",
    "#                    'ConvNeXt_small_sd_dreambooth','ConvNeXt_tiny_sd_dreambooth','EB0_sd_dreambooth','EB1_sd_dreambooth','ResNet50_sd_dreambooth',\n",
    "#                    'ConvNeXt_small_unconditional','ConvNeXt_tiny_unconditional','EB0_unconditional','EB1_unconditional','ResNet50_unconditional',\n",
    "#                    'ConvNeXt_small_sd_lora_1e5_scale1','ConvNeXt_tiny_sd_lora_1e5_scale1','EB0_sd_lora_1e5_scale1','EB1_sd_lora_1e5_scale1','ResNet50_sd_lora_1e5_scale1']\n",
    "# calc_save_metrics(experiment_names,additional_images=100,csv_name='model_metrics_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>0_Prec_mean</th>\n",
       "      <th>0_Prec_std</th>\n",
       "      <th>0_Rec_mean</th>\n",
       "      <th>0_Rec_std</th>\n",
       "      <th>0_F1_mean</th>\n",
       "      <th>0_F1_std</th>\n",
       "      <th>1_Prec_mean</th>\n",
       "      <th>1_Prec_std</th>\n",
       "      <th>1_Rec_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>4_Prec_mean</th>\n",
       "      <th>4_Prec_std</th>\n",
       "      <th>4_Rec_mean</th>\n",
       "      <th>4_Rec_std</th>\n",
       "      <th>4_F1_mean</th>\n",
       "      <th>4_F1_std</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>bal_acc_mean</th>\n",
       "      <th>bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ConvNeXt_small_gan</td>\n",
       "      <td>0.3228</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0559</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.7696</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.5151</td>\n",
       "      <td>0.0336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvNeXt_tiny_gan</td>\n",
       "      <td>0.3699</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.3895</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.3758</td>\n",
       "      <td>0.0777</td>\n",
       "      <td>0.7699</td>\n",
       "      <td>0.0934</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.2561</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.1088</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.5558</td>\n",
       "      <td>0.0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EB0_gan</td>\n",
       "      <td>0.3967</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.1838</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.0648</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.5332</td>\n",
       "      <td>0.0183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EB1_gan</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1944</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>0.7072</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.7913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.7843</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>0.0243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ResNet50_gan</td>\n",
       "      <td>0.4168</td>\n",
       "      <td>0.0676</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.2714</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.7719</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.7714</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.5316</td>\n",
       "      <td>0.0363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ConvNeXt_small_sd_finetuning</td>\n",
       "      <td>0.2955</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.3474</td>\n",
       "      <td>0.2297</td>\n",
       "      <td>0.3071</td>\n",
       "      <td>0.1677</td>\n",
       "      <td>0.7164</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5112</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.3164</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.8037</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.5899</td>\n",
       "      <td>0.0263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ConvNeXt_tiny_sd_finetuning</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.2526</td>\n",
       "      <td>0.1073</td>\n",
       "      <td>0.2548</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.6609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2976</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.2726</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.7742</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.0181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EB0_sd_finetuning</td>\n",
       "      <td>0.4814</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.1684</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.2448</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.7602</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2639</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.2864</td>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.7705</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>0.0337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EB1_sd_finetuning</td>\n",
       "      <td>0.3622</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.3062</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3082</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.7733</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.5486</td>\n",
       "      <td>0.0170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ResNet50_sd_finetuning</td>\n",
       "      <td>0.2808</td>\n",
       "      <td>0.1624</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.7385</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.6957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2931</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.3101</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.7622</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.0339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ConvNeXt_small_sd_dreambooth</td>\n",
       "      <td>0.4326</td>\n",
       "      <td>0.0754</td>\n",
       "      <td>0.2316</td>\n",
       "      <td>0.1084</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.0914</td>\n",
       "      <td>0.6992</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.7652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2412</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.1795</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>0.7926</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.0355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ConvNeXt_tiny_sd_dreambooth</td>\n",
       "      <td>0.3361</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.3036</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.7515</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3178</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.2967</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.0287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EB0_sd_dreambooth</td>\n",
       "      <td>0.4179</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.7124</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.0935</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1908</td>\n",
       "      <td>0.0574</td>\n",
       "      <td>0.7954</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.5602</td>\n",
       "      <td>0.0162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EB1_sd_dreambooth</td>\n",
       "      <td>0.4578</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.2632</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>0.6872</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>0.7913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3671</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.1046</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.7935</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>0.0316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ResNet50_sd_dreambooth</td>\n",
       "      <td>0.4333</td>\n",
       "      <td>0.3887</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0754</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.5545</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.1828</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.7594</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.4806</td>\n",
       "      <td>0.0261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ConvNeXt_small_unconditional</td>\n",
       "      <td>0.4453</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.3895</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.4075</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.8189</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3278</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0935</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.0236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ConvNeXt_tiny_unconditional</td>\n",
       "      <td>0.3838</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.3106</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>0.0826</td>\n",
       "      <td>0.8348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1693</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.1561</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.0184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EB0_unconditional</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.1758</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.1108</td>\n",
       "      <td>0.6438</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2269</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.0837</td>\n",
       "      <td>0.7567</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.5145</td>\n",
       "      <td>0.0177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EB1_unconditional</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.7398</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2921</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.7853</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.5481</td>\n",
       "      <td>0.0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ResNet50_unconditional</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2205</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.6933</td>\n",
       "      <td>0.0514</td>\n",
       "      <td>0.7913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2327</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.7567</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.5120</td>\n",
       "      <td>0.0251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ConvNeXt_small_sd_lora_1e5_scale1</td>\n",
       "      <td>0.2956</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.7677</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.5363</td>\n",
       "      <td>0.0274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ConvNeXt_tiny_sd_lora_1e5_scale1</td>\n",
       "      <td>0.3618</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.4105</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>0.7739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2724</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.7843</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.5663</td>\n",
       "      <td>0.0342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EB0_sd_lora_1e5_scale1</td>\n",
       "      <td>0.3703</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.7014</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.7613</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.0172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EB1_sd_lora_1e5_scale1</td>\n",
       "      <td>0.4492</td>\n",
       "      <td>0.1568</td>\n",
       "      <td>0.2316</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.2891</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.3252</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.7760</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.5532</td>\n",
       "      <td>0.0191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ResNet50_sd_lora_1e5_scale1</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1704</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7484</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>0.0342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                model 0_Prec_mean 0_Prec_std 0_Rec_mean  \\\n",
       "2                  ConvNeXt_small_gan      0.3228     0.0242     0.2737   \n",
       "3                   ConvNeXt_tiny_gan      0.3699     0.0445     0.3895   \n",
       "4                             EB0_gan      0.3967     0.1431     0.1263   \n",
       "5                             EB1_gan         0.2     0.1944     0.1158   \n",
       "6                        ResNet50_gan      0.4168     0.0676     0.2105   \n",
       "7        ConvNeXt_small_sd_finetuning      0.2955      0.151     0.3474   \n",
       "8         ConvNeXt_tiny_sd_finetuning       0.279     0.0235     0.2526   \n",
       "9                   EB0_sd_finetuning      0.4814     0.1371     0.1684   \n",
       "10                  EB1_sd_finetuning      0.3622     0.0472     0.2737   \n",
       "11             ResNet50_sd_finetuning      0.2808     0.1624     0.1474   \n",
       "12       ConvNeXt_small_sd_dreambooth      0.4326     0.0754     0.2316   \n",
       "13        ConvNeXt_tiny_sd_dreambooth      0.3361     0.0302     0.2842   \n",
       "14                  EB0_sd_dreambooth      0.4179     0.0936     0.1895   \n",
       "15                  EB1_sd_dreambooth      0.4578     0.0381        0.2   \n",
       "16             ResNet50_sd_dreambooth      0.4333     0.3887     0.0421   \n",
       "17       ConvNeXt_small_unconditional      0.4453     0.0764     0.3895   \n",
       "18        ConvNeXt_tiny_unconditional      0.3838     0.0532     0.2737   \n",
       "19                  EB0_unconditional      0.1289     0.1758     0.0526   \n",
       "20                  EB1_unconditional      0.2667      0.152     0.0842   \n",
       "21             ResNet50_unconditional        0.22     0.2205     0.0632   \n",
       "22  ConvNeXt_small_sd_lora_1e5_scale1      0.2956     0.0523     0.3368   \n",
       "23   ConvNeXt_tiny_sd_lora_1e5_scale1      0.3618     0.0424     0.4105   \n",
       "24             EB0_sd_lora_1e5_scale1      0.3703     0.0307     0.1895   \n",
       "25             EB1_sd_lora_1e5_scale1      0.4492     0.1568     0.2316   \n",
       "26        ResNet50_sd_lora_1e5_scale1      0.2143     0.2857     0.1053   \n",
       "\n",
       "   0_Rec_std 0_F1_mean 0_F1_std 1_Prec_mean 1_Prec_std 1_Rec_mean  ...  \\\n",
       "2     0.0774     0.289   0.0338      0.8708     0.1249     0.6435  ...   \n",
       "3     0.1134    0.3758   0.0777      0.7699     0.0934     0.8087  ...   \n",
       "4     0.0537    0.1838   0.0622       0.687     0.0648        0.8  ...   \n",
       "5     0.1389    0.1437   0.1607      0.7072     0.0626     0.7913  ...   \n",
       "6     0.0471    0.2714   0.0332      0.7719     0.0318     0.7565  ...   \n",
       "7     0.2297    0.3071   0.1677      0.7164     0.0696     0.7478  ...   \n",
       "8     0.1073    0.2548   0.0701       0.788     0.0924     0.6609  ...   \n",
       "9     0.0614    0.2448   0.0747      0.7602     0.1138     0.7565  ...   \n",
       "10    0.0774    0.3062   0.0639      0.7943     0.0429     0.7565  ...   \n",
       "11    0.0906    0.1917   0.1131      0.7385     0.1478     0.6957  ...   \n",
       "12    0.1084    0.2842   0.0914      0.6992     0.0599     0.7652  ...   \n",
       "13    0.0788    0.3036   0.0529      0.7515      0.103        0.8  ...   \n",
       "14    0.1182    0.2398   0.0869      0.7124     0.0809     0.8087  ...   \n",
       "15    0.0842    0.2632   0.0876      0.6872     0.0536     0.7913  ...   \n",
       "16    0.0394    0.0754   0.0688      0.5545     0.0473     0.7217  ...   \n",
       "17    0.0537    0.4075   0.0287      0.8189     0.0775     0.7565  ...   \n",
       "18    0.0774    0.3106   0.0409      0.7232     0.0826     0.8348  ...   \n",
       "19    0.0815    0.0738   0.1108      0.6438     0.0408     0.8174  ...   \n",
       "20    0.0714    0.1234   0.0927      0.7398     0.0451     0.8696  ...   \n",
       "21    0.0614     0.097   0.0948      0.6933     0.0514     0.7913  ...   \n",
       "22    0.0537     0.314   0.0505      0.7943     0.1226     0.7217  ...   \n",
       "23     0.154    0.3765   0.0843       0.808     0.1274     0.7739  ...   \n",
       "24    0.0537    0.2455   0.0505      0.7014     0.0344     0.7478  ...   \n",
       "25    0.0632    0.2891   0.0475      0.6752     0.0385     0.7565  ...   \n",
       "26    0.1289    0.1375   0.1704       0.712     0.0747     0.3217  ...   \n",
       "\n",
       "   4_Prec_mean 4_Prec_std 4_Rec_mean 4_Rec_std 4_F1_mean 4_F1_std acc_mean  \\\n",
       "2       0.1895     0.0772      0.125    0.0559     0.145   0.0636   0.7696   \n",
       "3       0.2467     0.2561      0.075    0.0612    0.1088   0.0915   0.7899   \n",
       "4       0.1646     0.1017     0.1625     0.151    0.1486   0.1134   0.7797   \n",
       "5        0.251     0.0576     0.1625    0.0848     0.192   0.0831   0.7843   \n",
       "6       0.2286     0.0795      0.275    0.0637     0.243   0.0556   0.7714   \n",
       "7       0.5112     0.1291     0.2375    0.0468    0.3164   0.0465   0.8037   \n",
       "8       0.2976     0.0613     0.2875    0.1225    0.2726   0.0891   0.7742   \n",
       "9       0.2639      0.089      0.325    0.1447    0.2864   0.1164   0.7705   \n",
       "10      0.3082     0.0612      0.325     0.025    0.3135   0.0343   0.7733   \n",
       "11      0.2931     0.0936     0.3375    0.0848    0.3101   0.0841   0.7622   \n",
       "12      0.2412     0.1597       0.15     0.109    0.1795   0.1271   0.7926   \n",
       "13      0.3178     0.0974        0.3    0.1075    0.2967   0.0774   0.7806   \n",
       "14      0.2768     0.0935       0.15      0.05    0.1908   0.0574   0.7954   \n",
       "15      0.3671     0.0495     0.3125    0.1046    0.3257   0.0597   0.7935   \n",
       "16      0.1739     0.1828      0.075    0.0729    0.0894   0.0769   0.7594   \n",
       "17      0.3278     0.0776       0.35    0.0935    0.3322   0.0678   0.7945   \n",
       "18      0.1693     0.1412       0.15    0.1403    0.1561   0.1355   0.7788   \n",
       "19      0.2269     0.0528        0.4     0.151    0.2862   0.0837   0.7567   \n",
       "20      0.2921     0.0728      0.225    0.0848    0.2455   0.0697   0.7853   \n",
       "21      0.2327     0.0457     0.3875    0.0919    0.2892   0.0583   0.7567   \n",
       "22       0.182     0.1184     0.1875     0.163    0.1799   0.1364   0.7677   \n",
       "23      0.2724     0.1456      0.225    0.1705    0.2226   0.1252   0.7843   \n",
       "24      0.1711     0.0819      0.175    0.1075     0.163   0.0753   0.7613   \n",
       "25      0.2972     0.0578      0.375    0.1425    0.3252   0.0771   0.7760   \n",
       "26         0.0        0.0        0.0       0.0       0.0      0.0   0.7484   \n",
       "\n",
       "   acc_std bal_acc_mean bal_acc_std  \n",
       "2   0.0200       0.5151      0.0336  \n",
       "3   0.0159       0.5558      0.0283  \n",
       "4   0.0168       0.5332      0.0183  \n",
       "5   0.0128       0.5368      0.0243  \n",
       "6   0.0219       0.5316      0.0363  \n",
       "7   0.0107       0.5899      0.0263  \n",
       "8   0.0157       0.5401      0.0181  \n",
       "9   0.0176       0.5340      0.0337  \n",
       "10  0.0147       0.5486      0.0170  \n",
       "11  0.0188       0.5176      0.0339  \n",
       "12  0.0177       0.5550      0.0355  \n",
       "13  0.0139       0.5556      0.0287  \n",
       "14  0.0075       0.5602      0.0162  \n",
       "15  0.0150       0.5720      0.0316  \n",
       "16  0.0144       0.4806      0.0261  \n",
       "17  0.0161       0.5873      0.0236  \n",
       "18  0.0130       0.5423      0.0184  \n",
       "19  0.0084       0.5145      0.0177  \n",
       "20  0.0135       0.5481      0.0195  \n",
       "21  0.0118       0.5120      0.0251  \n",
       "22  0.0171       0.5363      0.0274  \n",
       "23  0.0219       0.5663      0.0342  \n",
       "24  0.0098       0.5067      0.0172  \n",
       "25  0.0063       0.5532      0.0191  \n",
       "26  0.0156       0.4472      0.0342  \n",
       "\n",
       "[25 rows x 35 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('export/clf_metrics/model_metrics_100.csv')\n",
    "df.columns = ['model']+[f'{x}_{y}_{z}' for x,y,z in itertools.product([0,1,2,3,4],['Prec','Rec','F1'],['mean','std'])]+['acc_mean','acc_std','bal_acc_mean','bal_acc_std']\n",
    "df.drop(index=[0,1],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 75.94 $\\pm$ 1.44 & 79.54 $\\pm$ 0.75 & 79.35 $\\pm$ 1.5 & 78.06 $\\pm$ 1.39 & 79.26 $\\pm$ 1.77 \\\\\n",
      "finetuning & 76.22 $\\pm$ 1.88 & 77.05 $\\pm$ 1.76 & 77.33 $\\pm$ 1.47 & 77.42 $\\pm$ 1.57 & 80.37 $\\pm$ 1.07 \\\\\n",
      "gan & 77.14 $\\pm$ 2.19 & 77.97 $\\pm$ 1.68 & 78.43 $\\pm$ 1.28 & 78.99 $\\pm$ 1.59 & 76.96 $\\pm$ 2.0 \\\\\n",
      "lora & 74.84 $\\pm$ 1.56 & 76.13 $\\pm$ 0.98 & 77.6 $\\pm$ 0.63 & 78.43 $\\pm$ 2.19 & 76.77 $\\pm$ 1.71 \\\\\n",
      "unconditional & 75.67 $\\pm$ 1.18 & 75.67 $\\pm$ 0.84 & 78.53 $\\pm$ 1.35 & 77.88 $\\pm$ 1.3 & 79.45 $\\pm$ 1.61 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,['acc_mean','acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_acc_mean','EB0_acc_mean','EB1_acc_mean','ConvNeXt_tiny_acc_mean','ConvNeXt_small_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_acc_mean</th>\n",
       "      <th>EB0_acc_mean</th>\n",
       "      <th>EB1_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_acc_mean</th>\n",
       "      <th>ConvNeXt_small_acc_mean</th>\n",
       "      <th>mean_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>-0.0231</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.00162</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0203</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>-0.00590</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0111</td>\n",
       "      <td>-0.0074</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>-0.0157</td>\n",
       "      <td>-0.00370</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0341</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0176</td>\n",
       "      <td>-0.01514</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>-0.0304</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>-0.00828</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ResNet50_acc_mean  EB0_acc_mean  EB1_acc_mean  \\\n",
       "0     dreambooth            -0.0231        0.0083        0.0175   \n",
       "1     finetuning            -0.0203       -0.0166       -0.0027   \n",
       "2            gan            -0.0111       -0.0074        0.0083   \n",
       "3           lora            -0.0341       -0.0258        0.0000   \n",
       "4  unconditional            -0.0258       -0.0304        0.0093   \n",
       "\n",
       "   ConvNeXt_tiny_acc_mean  ConvNeXt_small_acc_mean  mean_acc_mean  \\\n",
       "0                 -0.0019                   0.0073        0.00162   \n",
       "1                 -0.0083                   0.0184       -0.00590   \n",
       "2                  0.0074                  -0.0157       -0.00370   \n",
       "3                  0.0018                  -0.0176       -0.01514   \n",
       "4                 -0.0037                   0.0092       -0.00828   \n",
       "\n",
       "   additional_images  \n",
       "0                100  \n",
       "1                100  \n",
       "2                100  \n",
       "3                100  \n",
       "4                100  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & -2.31 & 0.83 & 1.75 & -0.19 & 0.73 & 0.16 \\\\\n",
      "finetuning & -2.03 & -1.66 & -0.27 & -0.83 & 1.84 & -0.59 \\\\\n",
      "gan & -1.11 & -0.74 & 0.83 & 0.74 & -1.57 & -0.37 \\\\\n",
      "lora & -3.41 & -2.58 & 0.0 & 0.18 & -1.76 & -1.51 \\\\\n",
      "unconditional & -2.58 & -3.04 & 0.93 & -0.37 & 0.92 & -0.83 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.29 & -1.44 & 0.65 & -0.09 & 0.03 & -0.63 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot = df_pivot_delta.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df,metric=['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_std</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_std</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_std</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_std</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>ResNet50_bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.5602</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.4806</td>\n",
       "      <td>0.0261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>0.5899</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.5486</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>0.0339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>0.5151</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.5558</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.5332</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.5316</td>\n",
       "      <td>0.0363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>0.5363</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.5663</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.5532</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>0.0342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.5145</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.5481</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.5120</td>\n",
       "      <td>0.0251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ConvNeXt_small_bal_acc_mean  ConvNeXt_small_bal_acc_std  \\\n",
       "0     dreambooth                       0.5550                      0.0355   \n",
       "1     finetuning                       0.5899                      0.0263   \n",
       "2            gan                       0.5151                      0.0336   \n",
       "3           lora                       0.5363                      0.0274   \n",
       "4  unconditional                       0.5873                      0.0236   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_tiny_bal_acc_std  EB0_bal_acc_mean  \\\n",
       "0                      0.5556                     0.0287            0.5602   \n",
       "1                      0.5401                     0.0181            0.5340   \n",
       "2                      0.5558                     0.0283            0.5332   \n",
       "3                      0.5663                     0.0342            0.5067   \n",
       "4                      0.5423                     0.0184            0.5145   \n",
       "\n",
       "   EB0_bal_acc_std  EB1_bal_acc_mean  EB1_bal_acc_std  ResNet50_bal_acc_mean  \\\n",
       "0           0.0162            0.5720           0.0316                 0.4806   \n",
       "1           0.0337            0.5486           0.0170                 0.5176   \n",
       "2           0.0183            0.5368           0.0243                 0.5316   \n",
       "3           0.0172            0.5532           0.0191                 0.4472   \n",
       "4           0.0177            0.5481           0.0195                 0.5120   \n",
       "\n",
       "   ResNet50_bal_acc_std  \n",
       "0                0.0261  \n",
       "1                0.0339  \n",
       "2                0.0363  \n",
       "3                0.0342  \n",
       "4                0.0251  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 48.06 $\\pm$ 2.61 & 56.02 $\\pm$ 1.62 & 57.2 $\\pm$ 3.16 & 55.56 $\\pm$ 2.87 & 55.5 $\\pm$ 3.55 \\\\\n",
      "finetuning & 51.76 $\\pm$ 3.39 & 53.4 $\\pm$ 3.37 & 54.86 $\\pm$ 1.7 & 54.01 $\\pm$ 1.81 & 58.99 $\\pm$ 2.63 \\\\\n",
      "gan & 53.16 $\\pm$ 3.63 & 53.32 $\\pm$ 1.83 & 53.68 $\\pm$ 2.43 & 55.58 $\\pm$ 2.83 & 51.51 $\\pm$ 3.36 \\\\\n",
      "lora & 44.72 $\\pm$ 3.42 & 50.67 $\\pm$ 1.72 & 55.32 $\\pm$ 1.91 & 56.63 $\\pm$ 3.42 & 53.63 $\\pm$ 2.74 \\\\\n",
      "unconditional & 51.2 $\\pm$ 2.51 & 51.45 $\\pm$ 1.77 & 54.81 $\\pm$ 1.95 & 54.23 $\\pm$ 1.84 & 58.73 $\\pm$ 2.36 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_bal_acc_mean','EB0_bal_acc_mean','EB1_bal_acc_mean','ConvNeXt_tiny_bal_acc_mean','ConvNeXt_small_bal_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_bal_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_bal_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>mean_bal_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>-0.0416</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>-0.00046</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>-0.0036</td>\n",
       "      <td>-0.0234</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.00090</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>-0.0068</td>\n",
       "      <td>-0.0154</td>\n",
       "      <td>-0.0077</td>\n",
       "      <td>-0.0327</td>\n",
       "      <td>-0.01064</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.0115</td>\n",
       "      <td>-0.02320</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>-0.0102</td>\n",
       "      <td>-0.0255</td>\n",
       "      <td>-0.0041</td>\n",
       "      <td>-0.0212</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>-0.00430</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ResNet50_bal_acc_mean  EB0_bal_acc_mean  EB1_bal_acc_mean  \\\n",
       "0     dreambooth                -0.0416            0.0202            0.0198   \n",
       "1     finetuning                -0.0046           -0.0060           -0.0036   \n",
       "2            gan                 0.0094           -0.0068           -0.0154   \n",
       "3           lora                -0.0750           -0.0333            0.0010   \n",
       "4  unconditional                -0.0102           -0.0255           -0.0041   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_small_bal_acc_mean  mean_bal_acc_mean  \\\n",
       "0                     -0.0079                       0.0072           -0.00046   \n",
       "1                     -0.0234                       0.0421            0.00090   \n",
       "2                     -0.0077                      -0.0327           -0.01064   \n",
       "3                      0.0028                      -0.0115           -0.02320   \n",
       "4                     -0.0212                       0.0395           -0.00430   \n",
       "\n",
       "   additional_images  \n",
       "0                100  \n",
       "1                100  \n",
       "2                100  \n",
       "3                100  \n",
       "4                100  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & -4.16 & 2.02 & 1.98 & -0.79 & 0.72 & -0.05 \\\\\n",
      "finetuning & -0.46 & -0.6 & -0.36 & -2.34 & 4.21 & 0.09 \\\\\n",
      "gan & 0.94 & -0.68 & -1.54 & -0.77 & -3.27 & -1.06 \\\\\n",
      "lora & -7.5 & -3.33 & 0.1 & 0.28 & -1.15 & -2.32 \\\\\n",
      "unconditional & -1.02 & -2.55 & -0.41 & -2.12 & 3.95 & -0.43 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['bal_acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.44 & -1.03 & -0.05 & -1.15 & 0.89 & -0.75 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta,metric='bal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot_balacc = df_pivot_delta.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_names = ['ConvNeXt_small_gan','ConvNeXt_tiny_gan','EB0_gan','EB1_gan','ResNet50_gan',\n",
    "#                   'ConvNeXt_small_sd_finetuning','ConvNeXt_tiny_sd_finetuning','EB0_sd_finetuning','EB1_sd_finetuning','ResNet50_sd_finetuning',\n",
    "#                   'ConvNeXt_small_sd_dreambooth','ConvNeXt_tiny_sd_dreambooth','EB0_sd_dreambooth','EB1_sd_dreambooth','ResNet50_sd_dreambooth',\n",
    "#                   'ConvNeXt_small_unconditional','ConvNeXt_tiny_unconditional','EB0_unconditional','EB1_unconditional','ResNet50_unconditional',\n",
    "#                   'ConvNeXt_small_sd_lora_1e5_scale1','ConvNeXt_tiny_sd_lora_1e5_scale1','EB0_sd_lora_1e5_scale1','EB1_sd_lora_1e5_scale1','ResNet50_sd_lora_1e5_scale1']\n",
    "# calc_save_metrics(experiment_names,additional_images=250,csv_name='model_metrics_250.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>0_Prec_mean</th>\n",
       "      <th>0_Prec_std</th>\n",
       "      <th>0_Rec_mean</th>\n",
       "      <th>0_Rec_std</th>\n",
       "      <th>0_F1_mean</th>\n",
       "      <th>0_F1_std</th>\n",
       "      <th>1_Prec_mean</th>\n",
       "      <th>1_Prec_std</th>\n",
       "      <th>1_Rec_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>4_Prec_mean</th>\n",
       "      <th>4_Prec_std</th>\n",
       "      <th>4_Rec_mean</th>\n",
       "      <th>4_Rec_std</th>\n",
       "      <th>4_F1_mean</th>\n",
       "      <th>4_F1_std</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>bal_acc_mean</th>\n",
       "      <th>bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ConvNeXt_small_gan</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.3023</td>\n",
       "      <td>0.0673</td>\n",
       "      <td>0.7829</td>\n",
       "      <td>0.0791</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1912</td>\n",
       "      <td>0.1119</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.1663</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.7816</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.0353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvNeXt_tiny_gan</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.3263</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.3352</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.8669</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>0.2248</td>\n",
       "      <td>0.0923</td>\n",
       "      <td>0.7677</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.5326</td>\n",
       "      <td>0.0243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EB0_gan</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.2261</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.7253</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1966</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.2379</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.7465</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.4945</td>\n",
       "      <td>0.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EB1_gan</td>\n",
       "      <td>0.3657</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>0.2316</td>\n",
       "      <td>0.1084</td>\n",
       "      <td>0.2785</td>\n",
       "      <td>0.1127</td>\n",
       "      <td>0.7492</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>0.0517</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.1795</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.7687</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>0.0331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ResNet50_gan</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.1233</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>0.7325</td>\n",
       "      <td>0.0514</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.2571</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.5164</td>\n",
       "      <td>0.0298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ConvNeXt_small_sd_finetuning</td>\n",
       "      <td>0.3256</td>\n",
       "      <td>0.0796</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.3102</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.7732</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.3028</td>\n",
       "      <td>0.0718</td>\n",
       "      <td>0.7954</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.5743</td>\n",
       "      <td>0.0314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ConvNeXt_tiny_sd_finetuning</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.2421</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>0.1207</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.5826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3437</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>0.7668</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.0293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EB0_sd_finetuning</td>\n",
       "      <td>0.4079</td>\n",
       "      <td>0.0914</td>\n",
       "      <td>0.2421</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.2921</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.7763</td>\n",
       "      <td>0.1092</td>\n",
       "      <td>0.6783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.0935</td>\n",
       "      <td>0.1719</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>0.7696</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.5188</td>\n",
       "      <td>0.0194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EB1_sd_finetuning</td>\n",
       "      <td>0.3509</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.6829</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.7739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2384</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.0330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ResNet50_sd_finetuning</td>\n",
       "      <td>0.4354</td>\n",
       "      <td>0.3005</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.1356</td>\n",
       "      <td>0.2123</td>\n",
       "      <td>0.1317</td>\n",
       "      <td>0.8218</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3442</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.1046</td>\n",
       "      <td>0.3157</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>0.0165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ConvNeXt_small_sd_dreambooth</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.2421</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.7718</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2113</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1611</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.7862</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.5481</td>\n",
       "      <td>0.0391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ConvNeXt_tiny_sd_dreambooth</td>\n",
       "      <td>0.3838</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.2632</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>0.3023</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.6873</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3471</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.2577</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.7954</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.5724</td>\n",
       "      <td>0.0176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EB0_sd_dreambooth</td>\n",
       "      <td>0.6044</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.3698</td>\n",
       "      <td>0.1091</td>\n",
       "      <td>0.6957</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0559</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>0.7871</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.5386</td>\n",
       "      <td>0.0374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EB1_sd_dreambooth</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>0.1759</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.0577</td>\n",
       "      <td>0.3073</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.7057</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4261</td>\n",
       "      <td>0.1499</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.5744</td>\n",
       "      <td>0.0294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ResNet50_sd_dreambooth</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.0682</td>\n",
       "      <td>0.7739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2778</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.5274</td>\n",
       "      <td>0.0278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ConvNeXt_small_unconditional</td>\n",
       "      <td>0.4254</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.3321</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.7038</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4383</td>\n",
       "      <td>0.1233</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.3266</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.5981</td>\n",
       "      <td>0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ConvNeXt_tiny_unconditional</td>\n",
       "      <td>0.3517</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.2989</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>0.1153</td>\n",
       "      <td>0.7391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4269</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1118</td>\n",
       "      <td>0.3023</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.5644</td>\n",
       "      <td>0.0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EB0_unconditional</td>\n",
       "      <td>0.2824</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.0469</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>0.7622</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>0.0174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EB1_unconditional</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1124</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>0.7213</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.8609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.1977</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.7889</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.5568</td>\n",
       "      <td>0.0249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ResNet50_unconditional</td>\n",
       "      <td>0.1167</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.7498</td>\n",
       "      <td>0.1543</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1696</td>\n",
       "      <td>0.2639</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.7594</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.5036</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ConvNeXt_small_sd_lora_1e5_scale1</td>\n",
       "      <td>0.3778</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.3053</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.3272</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.1297</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.3546</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.0261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ConvNeXt_tiny_sd_lora_1e5_scale1</td>\n",
       "      <td>0.3443</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.3269</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.7599</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3006</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.7853</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.5648</td>\n",
       "      <td>0.0113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EB0_sd_lora_1e5_scale1</td>\n",
       "      <td>0.3826</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.2294</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.6772</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.7391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1549</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EB1_sd_lora_1e5_scale1</td>\n",
       "      <td>0.3421</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.6991</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.8261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1723</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.7687</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>0.0173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ResNet50_sd_lora_1e5_scale1</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.6143</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.4522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.1288</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.1476</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.7382</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.4484</td>\n",
       "      <td>0.0345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                model 0_Prec_mean 0_Prec_std 0_Rec_mean  \\\n",
       "2                  ConvNeXt_small_gan       0.325     0.0578     0.2947   \n",
       "3                   ConvNeXt_tiny_gan      0.3475     0.0468     0.3263   \n",
       "4                             EB0_gan        0.35     0.2261     0.1368   \n",
       "5                             EB1_gan      0.3657     0.0936     0.2316   \n",
       "6                        ResNet50_gan      0.2883     0.1233     0.1263   \n",
       "7        ConvNeXt_small_sd_finetuning      0.3256     0.0796     0.3158   \n",
       "8         ConvNeXt_tiny_sd_finetuning      0.1995     0.1031     0.2421   \n",
       "9                   EB0_sd_finetuning      0.4079     0.0914     0.2421   \n",
       "10                  EB1_sd_finetuning      0.3509     0.1794     0.2211   \n",
       "11             ResNet50_sd_finetuning      0.4354     0.3005     0.1789   \n",
       "12       ConvNeXt_small_sd_dreambooth      0.4719     0.1085     0.2421   \n",
       "13        ConvNeXt_tiny_sd_dreambooth      0.3838      0.099     0.2632   \n",
       "14                  EB0_sd_dreambooth      0.6044     0.1506     0.2737   \n",
       "15                  EB1_sd_dreambooth      0.6377     0.1759     0.2105   \n",
       "16             ResNet50_sd_dreambooth      0.9667     0.0667     0.0947   \n",
       "17       ConvNeXt_small_unconditional      0.4254     0.1318     0.2842   \n",
       "18        ConvNeXt_tiny_unconditional      0.3517     0.0783     0.2737   \n",
       "19                  EB0_unconditional      0.2824      0.154     0.0737   \n",
       "20                  EB1_unconditional      0.4786     0.0474        0.2   \n",
       "21             ResNet50_unconditional      0.1167     0.1453     0.0211   \n",
       "22  ConvNeXt_small_sd_lora_1e5_scale1      0.3778     0.0697     0.3053   \n",
       "23   ConvNeXt_tiny_sd_lora_1e5_scale1      0.3443      0.031     0.3158   \n",
       "24             EB0_sd_lora_1e5_scale1      0.3826     0.0696     0.1789   \n",
       "25             EB1_sd_lora_1e5_scale1      0.3421     0.1593     0.1368   \n",
       "26        ResNet50_sd_lora_1e5_scale1      0.4167     0.3333     0.0526   \n",
       "\n",
       "   0_Rec_std 0_F1_mean 0_F1_std 1_Prec_mean 1_Prec_std 1_Rec_mean  ...  \\\n",
       "2     0.1031    0.3023   0.0673      0.7829     0.0791        0.8  ...   \n",
       "3     0.0394    0.3352   0.0374      0.8669      0.077     0.7217  ...   \n",
       "4     0.0788    0.1842   0.0994      0.7253     0.0506     0.7217  ...   \n",
       "5     0.1084    0.2785   0.1127      0.7492     0.0309     0.7478  ...   \n",
       "6     0.0714     0.174   0.0917      0.7325     0.0514     0.7478  ...   \n",
       "7     0.1761    0.3102   0.1312      0.7732     0.0739     0.7217  ...   \n",
       "8     0.1511    0.2154   0.1207       0.873     0.0605     0.5826  ...   \n",
       "9     0.0714    0.2921   0.0443      0.7763     0.1092     0.6783  ...   \n",
       "10    0.1172    0.2698   0.1397      0.6829     0.0641     0.7739  ...   \n",
       "11    0.1356    0.2123   0.1317      0.8218     0.0504     0.7043  ...   \n",
       "12    0.1031    0.2965   0.0703      0.7718     0.1033     0.7043  ...   \n",
       "13    0.1331    0.3023   0.1266      0.6873     0.0556     0.8174  ...   \n",
       "14    0.0906    0.3698   0.1091      0.6957     0.0882      0.687  ...   \n",
       "15    0.0577    0.3073   0.0822      0.7057     0.0945     0.8783  ...   \n",
       "16    0.0842      0.16     0.12       0.589     0.0682     0.7739  ...   \n",
       "17    0.0714    0.3321   0.0764      0.7038     0.0405     0.7826  ...   \n",
       "18    0.1389    0.2989   0.1042      0.7269     0.1153     0.7391  ...   \n",
       "19    0.0537    0.1151   0.0783       0.758     0.0649     0.7478  ...   \n",
       "20    0.1124    0.2658   0.1216      0.7213     0.0665     0.8609  ...   \n",
       "21    0.0258    0.0356   0.0436      0.7498     0.1543     0.7478  ...   \n",
       "22    0.0614    0.3272   0.0304       0.716     0.1297     0.8087  ...   \n",
       "23    0.0666    0.3269   0.0439      0.7599      0.049     0.8087  ...   \n",
       "24    0.0632    0.2294    0.068      0.6772     0.0488     0.7391  ...   \n",
       "25    0.0855    0.1933   0.1131      0.6991     0.0664     0.8261  ...   \n",
       "26    0.0333    0.0904   0.0552      0.6143      0.073     0.4522  ...   \n",
       "\n",
       "   4_Prec_mean 4_Prec_std 4_Rec_mean 4_Rec_std 4_F1_mean 4_F1_std acc_mean  \\\n",
       "2       0.1912     0.1119       0.15    0.0848    0.1663   0.0941   0.7816   \n",
       "3       0.2416     0.0297       0.25    0.1531    0.2248   0.0923   0.7677   \n",
       "4       0.1966     0.0423      0.325    0.1551    0.2379   0.0725   0.7465   \n",
       "5       0.1888     0.0517      0.175    0.0729    0.1795   0.0644   0.7687   \n",
       "6        0.234     0.0578     0.3125    0.1311    0.2571   0.0781   0.7631   \n",
       "7       0.4607     0.0813       0.25     0.125    0.3028   0.0718   0.7954   \n",
       "8       0.3437     0.0471     0.1875    0.0884    0.2324   0.0864   0.7668   \n",
       "9       0.1933     0.1181     0.1625    0.0935    0.1719   0.0976   0.7696   \n",
       "10      0.3044      0.149        0.2       0.1    0.2384   0.1169   0.7806   \n",
       "11      0.3442     0.0988     0.3125    0.1046    0.3157   0.0689   0.7797   \n",
       "12      0.2113     0.1175     0.2125    0.1611     0.204   0.1354   0.7862   \n",
       "13      0.3471     0.1045      0.225    0.0637    0.2577   0.0487   0.7954   \n",
       "14      0.0685     0.0565     0.0625    0.0559    0.0646   0.0554   0.7871   \n",
       "15      0.4261     0.1499     0.1625    0.0637    0.2139   0.0694   0.7991   \n",
       "16      0.2778     0.1648        0.1      0.05    0.1447   0.0735   0.7825   \n",
       "17      0.4383     0.1233     0.2625    0.0729    0.3266   0.0876   0.8111   \n",
       "18      0.4269     0.0598       0.25    0.1118    0.3023   0.0946   0.7917   \n",
       "19       0.184     0.0469      0.225    0.0637     0.202   0.0538   0.7622   \n",
       "20       0.227     0.0833     0.1875    0.0884    0.1977   0.0808   0.7889   \n",
       "21      0.2558     0.0397        0.3    0.1696    0.2639   0.0768   0.7594   \n",
       "22      0.3738     0.0928     0.3625    0.1075    0.3546    0.066   0.7908   \n",
       "23      0.3006      0.072     0.2375    0.0829    0.2508   0.0515   0.7853   \n",
       "24      0.1549     0.0552     0.1125    0.0468    0.1234   0.0388   0.7631   \n",
       "25       0.214     0.0765       0.25    0.1723    0.2156    0.105   0.7687   \n",
       "26       0.152     0.1288       0.15    0.1458    0.1476   0.1338   0.7382   \n",
       "\n",
       "   acc_std bal_acc_mean bal_acc_std  \n",
       "2   0.0205       0.5453      0.0353  \n",
       "3   0.0159       0.5326      0.0243  \n",
       "4   0.0134       0.4945      0.0112  \n",
       "5   0.0132       0.5218      0.0331  \n",
       "6   0.0245       0.5164      0.0298  \n",
       "7   0.0156       0.5743      0.0314  \n",
       "8   0.0075       0.5140      0.0293  \n",
       "9   0.0124       0.5188      0.0194  \n",
       "10  0.0164       0.5423      0.0330  \n",
       "11  0.0111       0.5431      0.0165  \n",
       "12  0.0227       0.5481      0.0391  \n",
       "13  0.0166       0.5724      0.0176  \n",
       "14  0.0241       0.5386      0.0374  \n",
       "15  0.0181       0.5744      0.0294  \n",
       "16  0.0114       0.5274      0.0278  \n",
       "17  0.0189       0.5981      0.0350  \n",
       "18  0.0150       0.5644      0.0283  \n",
       "19  0.0075       0.5068      0.0174  \n",
       "20  0.0128       0.5568      0.0249  \n",
       "21  0.0122       0.5036      0.0282  \n",
       "22  0.0186       0.5771      0.0261  \n",
       "23  0.0103       0.5648      0.0113  \n",
       "24  0.0139       0.5050      0.0185  \n",
       "25  0.0125       0.5273      0.0173  \n",
       "26  0.0147       0.4484      0.0345  \n",
       "\n",
       "[25 rows x 35 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('export/clf_metrics/model_metrics_250.csv')\n",
    "df.columns = ['model']+[f'{x}_{y}_{z}' for x,y,z in itertools.product([0,1,2,3,4],['Prec','Rec','F1'],['mean','std'])]+['acc_mean','acc_std','bal_acc_mean','bal_acc_std']\n",
    "df.drop(index=[0,1],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 78.25 $\\pm$ 1.14 & 78.71 $\\pm$ 2.41 & 79.91 $\\pm$ 1.81 & 79.54 $\\pm$ 1.66 & 78.62 $\\pm$ 2.27 \\\\\n",
      "finetuning & 77.97 $\\pm$ 1.11 & 76.96 $\\pm$ 1.24 & 78.06 $\\pm$ 1.64 & 76.68 $\\pm$ 0.75 & 79.54 $\\pm$ 1.56 \\\\\n",
      "gan & 76.31 $\\pm$ 2.45 & 74.65 $\\pm$ 1.34 & 76.87 $\\pm$ 1.32 & 76.77 $\\pm$ 1.59 & 78.16 $\\pm$ 2.05 \\\\\n",
      "lora & 73.82 $\\pm$ 1.47 & 76.31 $\\pm$ 1.39 & 76.87 $\\pm$ 1.25 & 78.53 $\\pm$ 1.03 & 79.08 $\\pm$ 1.86 \\\\\n",
      "unconditional & 75.94 $\\pm$ 1.22 & 76.22 $\\pm$ 0.75 & 78.89 $\\pm$ 1.28 & 79.17 $\\pm$ 1.5 & 81.11 $\\pm$ 1.89 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_acc_mean','EB0_acc_mean','EB1_acc_mean','ConvNeXt_tiny_acc_mean','ConvNeXt_small_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_acc_mean</th>\n",
       "      <th>EB0_acc_mean</th>\n",
       "      <th>EB1_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_acc_mean</th>\n",
       "      <th>ConvNeXt_small_acc_mean</th>\n",
       "      <th>mean_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.00738</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>-0.0175</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>-0.0157</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>-0.00426</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0406</td>\n",
       "      <td>-0.0073</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>-0.01716</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0443</td>\n",
       "      <td>-0.0240</td>\n",
       "      <td>-0.0073</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>-0.01346</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>-0.0231</td>\n",
       "      <td>-0.0249</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ResNet50_acc_mean  EB0_acc_mean  EB1_acc_mean  \\\n",
       "0     dreambooth             0.0000        0.0000        0.0231   \n",
       "1     finetuning            -0.0028       -0.0175        0.0046   \n",
       "2            gan            -0.0194       -0.0406       -0.0073   \n",
       "3           lora            -0.0443       -0.0240       -0.0073   \n",
       "4  unconditional            -0.0231       -0.0249        0.0129   \n",
       "\n",
       "   ConvNeXt_tiny_acc_mean  ConvNeXt_small_acc_mean  mean_acc_mean  \\\n",
       "0                  0.0129                   0.0009        0.00738   \n",
       "1                 -0.0157                   0.0101       -0.00426   \n",
       "2                 -0.0148                  -0.0037       -0.01716   \n",
       "3                  0.0028                   0.0055       -0.01346   \n",
       "4                  0.0092                   0.0258       -0.00002   \n",
       "\n",
       "   additional_images  \n",
       "0                250  \n",
       "1                250  \n",
       "2                250  \n",
       "3                250  \n",
       "4                250  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 0.0 & 0.0 & 2.31 & 1.29 & 0.09 & 0.74 \\\\\n",
      "finetuning & -0.28 & -1.75 & 0.46 & -1.57 & 1.01 & -0.43 \\\\\n",
      "gan & -1.94 & -4.06 & -0.73 & -1.48 & -0.37 & -1.72 \\\\\n",
      "lora & -4.43 & -2.4 & -0.73 & 0.28 & 0.55 & -1.35 \\\\\n",
      "unconditional & -2.31 & -2.49 & 1.29 & 0.92 & 2.58 & -0.0 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.79 & -2.14 & 0.52 & -0.11 & 0.77 & -0.55 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot = pd.concat([df_total_pivot,df_pivot_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df,metric=['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_std</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_std</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_std</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_std</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>ResNet50_bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.5481</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.5724</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.5386</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.5744</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.5274</td>\n",
       "      <td>0.0278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>0.5743</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.5188</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>0.0165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.5326</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.4945</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.5164</td>\n",
       "      <td>0.0298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.5648</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.4484</td>\n",
       "      <td>0.0345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.5981</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.5644</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.5568</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.5036</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ConvNeXt_small_bal_acc_mean  ConvNeXt_small_bal_acc_std  \\\n",
       "0     dreambooth                       0.5481                      0.0391   \n",
       "1     finetuning                       0.5743                      0.0314   \n",
       "2            gan                       0.5453                      0.0353   \n",
       "3           lora                       0.5771                      0.0261   \n",
       "4  unconditional                       0.5981                      0.0350   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_tiny_bal_acc_std  EB0_bal_acc_mean  \\\n",
       "0                      0.5724                     0.0176            0.5386   \n",
       "1                      0.5140                     0.0293            0.5188   \n",
       "2                      0.5326                     0.0243            0.4945   \n",
       "3                      0.5648                     0.0113            0.5050   \n",
       "4                      0.5644                     0.0283            0.5068   \n",
       "\n",
       "   EB0_bal_acc_std  EB1_bal_acc_mean  EB1_bal_acc_std  ResNet50_bal_acc_mean  \\\n",
       "0           0.0374            0.5744           0.0294                 0.5274   \n",
       "1           0.0194            0.5423           0.0330                 0.5431   \n",
       "2           0.0112            0.5218           0.0331                 0.5164   \n",
       "3           0.0185            0.5273           0.0173                 0.4484   \n",
       "4           0.0174            0.5568           0.0249                 0.5036   \n",
       "\n",
       "   ResNet50_bal_acc_std  \n",
       "0                0.0278  \n",
       "1                0.0165  \n",
       "2                0.0298  \n",
       "3                0.0345  \n",
       "4                0.0282  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 52.74 $\\pm$ 2.78 & 53.86 $\\pm$ 3.74 & 57.44 $\\pm$ 2.94 & 57.24 $\\pm$ 1.76 & 54.81 $\\pm$ 3.91 \\\\\n",
      "finetuning & 54.31 $\\pm$ 1.65 & 51.88 $\\pm$ 1.94 & 54.23 $\\pm$ 3.3 & 51.4 $\\pm$ 2.93 & 57.43 $\\pm$ 3.14 \\\\\n",
      "gan & 51.64 $\\pm$ 2.98 & 49.45 $\\pm$ 1.12 & 52.18 $\\pm$ 3.31 & 53.26 $\\pm$ 2.43 & 54.53 $\\pm$ 3.53 \\\\\n",
      "lora & 44.84 $\\pm$ 3.45 & 50.5 $\\pm$ 1.85 & 52.73 $\\pm$ 1.73 & 56.48 $\\pm$ 1.13 & 57.71 $\\pm$ 2.61 \\\\\n",
      "unconditional & 50.36 $\\pm$ 2.82 & 50.68 $\\pm$ 1.74 & 55.68 $\\pm$ 2.49 & 56.44 $\\pm$ 2.83 & 59.81 $\\pm$ 3.5 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_bal_acc_mean','EB0_bal_acc_mean','EB1_bal_acc_mean','ConvNeXt_tiny_bal_acc_mean','ConvNeXt_small_bal_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_bal_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_bal_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>mean_bal_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.00704</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>-0.0212</td>\n",
       "      <td>-0.0099</td>\n",
       "      <td>-0.0495</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>-0.00664</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0058</td>\n",
       "      <td>-0.0455</td>\n",
       "      <td>-0.0304</td>\n",
       "      <td>-0.0309</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>-0.02302</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0738</td>\n",
       "      <td>-0.0350</td>\n",
       "      <td>-0.0249</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>-0.02062</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>-0.0186</td>\n",
       "      <td>-0.0332</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.00080</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ResNet50_bal_acc_mean  EB0_bal_acc_mean  EB1_bal_acc_mean  \\\n",
       "0     dreambooth                 0.0052           -0.0014            0.0222   \n",
       "1     finetuning                 0.0209           -0.0212           -0.0099   \n",
       "2            gan                -0.0058           -0.0455           -0.0304   \n",
       "3           lora                -0.0738           -0.0350           -0.0249   \n",
       "4  unconditional                -0.0186           -0.0332            0.0046   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_small_bal_acc_mean  mean_bal_acc_mean  \\\n",
       "0                      0.0089                       0.0003            0.00704   \n",
       "1                     -0.0495                       0.0265           -0.00664   \n",
       "2                     -0.0309                      -0.0025           -0.02302   \n",
       "3                      0.0013                       0.0293           -0.02062   \n",
       "4                      0.0009                       0.0503            0.00080   \n",
       "\n",
       "   additional_images  \n",
       "0                250  \n",
       "1                250  \n",
       "2                250  \n",
       "3                250  \n",
       "4                250  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 0.52 & -0.14 & 2.22 & 0.89 & 0.03 & 0.7 \\\\\n",
      "finetuning & 2.09 & -2.12 & -0.99 & -4.95 & 2.65 & -0.66 \\\\\n",
      "gan & -0.58 & -4.55 & -3.04 & -3.09 & -0.25 & -2.3 \\\\\n",
      "lora & -7.38 & -3.5 & -2.49 & 0.13 & 2.93 & -2.06 \\\\\n",
      "unconditional & -1.86 & -3.32 & 0.46 & 0.09 & 5.03 & 0.08 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['bal_acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.44 & -2.73 & -0.77 & -1.39 & 2.08 & -0.85 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta,metric='bal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot_balacc = pd.concat([df_total_pivot_balacc,df_pivot_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_names = ['ConvNeXt_small_gan','ConvNeXt_tiny_gan','EB0_gan','EB1_gan','ResNet50_gan',\n",
    "#                   'ConvNeXt_small_sd_finetuning','ConvNeXt_tiny_sd_finetuning','EB0_sd_finetuning','EB1_sd_finetuning','ResNet50_sd_finetuning',\n",
    "#                   'ConvNeXt_small_sd_dreambooth','ConvNeXt_tiny_sd_dreambooth','EB0_sd_dreambooth','EB1_sd_dreambooth','ResNet50_sd_dreambooth',\n",
    "#                   'ConvNeXt_small_unconditional','ConvNeXt_tiny_unconditional','EB0_unconditional','EB1_unconditional','ResNet50_unconditional',\n",
    "#                   'ConvNeXt_small_sd_lora_1e5_scale1','ConvNeXt_tiny_sd_lora_1e5_scale1','EB0_sd_lora_1e5_scale1','EB1_sd_lora_1e5_scale1','ResNet50_sd_lora_1e5_scale1']\n",
    "# calc_save_metrics(experiment_names,additional_images=500,csv_name='model_metrics_500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>0_Prec_mean</th>\n",
       "      <th>0_Prec_std</th>\n",
       "      <th>0_Rec_mean</th>\n",
       "      <th>0_Rec_std</th>\n",
       "      <th>0_F1_mean</th>\n",
       "      <th>0_F1_std</th>\n",
       "      <th>1_Prec_mean</th>\n",
       "      <th>1_Prec_std</th>\n",
       "      <th>1_Rec_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>4_Prec_mean</th>\n",
       "      <th>4_Prec_std</th>\n",
       "      <th>4_Rec_mean</th>\n",
       "      <th>4_Rec_std</th>\n",
       "      <th>4_F1_mean</th>\n",
       "      <th>4_F1_std</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>bal_acc_mean</th>\n",
       "      <th>bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ConvNeXt_small_gan</td>\n",
       "      <td>0.4422</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>0.0923</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.7739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1167</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.2179</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.5528</td>\n",
       "      <td>0.0304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvNeXt_tiny_gan</td>\n",
       "      <td>0.4435</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>0.2526</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.3023</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.8151</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.7391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>0.1596</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.2215</td>\n",
       "      <td>0.2088</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.7760</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.5396</td>\n",
       "      <td>0.0501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EB0_gan</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.7739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1623</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1677</td>\n",
       "      <td>0.1882</td>\n",
       "      <td>0.0777</td>\n",
       "      <td>0.7429</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.4815</td>\n",
       "      <td>0.0417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EB1_gan</td>\n",
       "      <td>0.3548</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.1461</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.7228</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.0814</td>\n",
       "      <td>0.7677</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.5217</td>\n",
       "      <td>0.0326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ResNet50_gan</td>\n",
       "      <td>0.4417</td>\n",
       "      <td>0.0963</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.8016</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1819</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.0192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ConvNeXt_small_sd_finetuning</td>\n",
       "      <td>0.2563</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.2421</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.7672</td>\n",
       "      <td>0.0587</td>\n",
       "      <td>0.6783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4226</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.7705</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.5334</td>\n",
       "      <td>0.0225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ConvNeXt_tiny_sd_finetuning</td>\n",
       "      <td>0.2532</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.1489</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.7739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3358</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.3094</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.7742</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.5419</td>\n",
       "      <td>0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EB0_sd_finetuning</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2448</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1046</td>\n",
       "      <td>0.2418</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.4922</td>\n",
       "      <td>0.0349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EB1_sd_finetuning</td>\n",
       "      <td>0.5189</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.2632</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>0.7208</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3867</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.2706</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.0148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ResNet50_sd_finetuning</td>\n",
       "      <td>0.2042</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.1579</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.1744</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>0.5826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3211</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2824</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.4891</td>\n",
       "      <td>0.0390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ConvNeXt_small_sd_dreambooth</td>\n",
       "      <td>0.3872</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.3895</td>\n",
       "      <td>0.1901</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.6993</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.8261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.3132</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.5599</td>\n",
       "      <td>0.0493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ConvNeXt_tiny_sd_dreambooth</td>\n",
       "      <td>0.4781</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.3474</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.7913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2437</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.7843</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.5617</td>\n",
       "      <td>0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EB0_sd_dreambooth</td>\n",
       "      <td>0.5403</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.2421</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.6591</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.1382</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.7954</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.5605</td>\n",
       "      <td>0.0147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EB1_sd_dreambooth</td>\n",
       "      <td>0.5232</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.2632</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.1766</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.5549</td>\n",
       "      <td>0.0263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ResNet50_sd_dreambooth</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.6023</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.7677</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.5064</td>\n",
       "      <td>0.0212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ConvNeXt_small_unconditional</td>\n",
       "      <td>0.3438</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.3053</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.3107</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.8089</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.7652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.1088</td>\n",
       "      <td>0.8028</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.5886</td>\n",
       "      <td>0.0265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ConvNeXt_tiny_unconditional</td>\n",
       "      <td>0.4237</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0.7145</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.8348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3567</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>0.1144</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.5737</td>\n",
       "      <td>0.0298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EB0_unconditional</td>\n",
       "      <td>0.4867</td>\n",
       "      <td>0.2018</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.1295</td>\n",
       "      <td>0.8099</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>0.7913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1751</td>\n",
       "      <td>0.1112</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1768</td>\n",
       "      <td>0.1748</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>0.0238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EB1_unconditional</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>0.1013</td>\n",
       "      <td>0.2316</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.2898</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.0651</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1896</td>\n",
       "      <td>0.2342</td>\n",
       "      <td>0.1544</td>\n",
       "      <td>0.7853</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.5569</td>\n",
       "      <td>0.0374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ResNet50_unconditional</td>\n",
       "      <td>0.4556</td>\n",
       "      <td>0.1237</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.0577</td>\n",
       "      <td>0.1627</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.0572</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3527</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.3599</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.7816</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>0.0306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ConvNeXt_small_sd_lora_1e5_scale1</td>\n",
       "      <td>0.3424</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2794</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.0935</td>\n",
       "      <td>0.2401</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.5502</td>\n",
       "      <td>0.0323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ConvNeXt_tiny_sd_lora_1e5_scale1</td>\n",
       "      <td>0.4599</td>\n",
       "      <td>0.2801</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.2981</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>0.7637</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.7652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.0206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EB0_sd_lora_1e5_scale1</td>\n",
       "      <td>0.3633</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>0.1579</td>\n",
       "      <td>0.0577</td>\n",
       "      <td>0.2152</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.6926</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>0.7659</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.5054</td>\n",
       "      <td>0.0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EB1_sd_lora_1e5_scale1</td>\n",
       "      <td>0.3606</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>0.2632</td>\n",
       "      <td>0.1912</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>0.1631</td>\n",
       "      <td>0.7589</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.7913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2359</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>0.2547</td>\n",
       "      <td>0.1652</td>\n",
       "      <td>0.7816</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.0504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ResNet50_sd_lora_1e5_scale1</td>\n",
       "      <td>0.2567</td>\n",
       "      <td>0.1638</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.6018</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.1909</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.7373</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                model 0_Prec_mean 0_Prec_std 0_Rec_mean  \\\n",
       "2                  ConvNeXt_small_gan      0.4422     0.1308     0.2947   \n",
       "3                   ConvNeXt_tiny_gan      0.4435     0.0793     0.2526   \n",
       "4                             EB0_gan       0.315     0.2488     0.0947   \n",
       "5                             EB1_gan      0.3548     0.2214     0.0947   \n",
       "6                        ResNet50_gan      0.4417     0.0963     0.1474   \n",
       "7        ConvNeXt_small_sd_finetuning      0.2563     0.0816     0.2421   \n",
       "8         ConvNeXt_tiny_sd_finetuning      0.2532     0.1434     0.2105   \n",
       "9                   EB0_sd_finetuning      0.4444     0.2872     0.1789   \n",
       "10                  EB1_sd_finetuning      0.5189      0.137     0.1895   \n",
       "11             ResNet50_sd_finetuning      0.2042     0.0548     0.1579   \n",
       "12       ConvNeXt_small_sd_dreambooth      0.3872     0.1074     0.3895   \n",
       "13        ConvNeXt_tiny_sd_dreambooth      0.4781     0.0714     0.3474   \n",
       "14                  EB0_sd_dreambooth      0.5403     0.1266     0.2421   \n",
       "15                  EB1_sd_dreambooth      0.5232     0.0736     0.2632   \n",
       "16             ResNet50_sd_dreambooth      0.4444     0.3913     0.0947   \n",
       "17       ConvNeXt_small_unconditional      0.3438      0.059     0.3053   \n",
       "18        ConvNeXt_tiny_unconditional      0.4237     0.1665     0.2947   \n",
       "19                  EB0_unconditional      0.4867     0.2018     0.1789   \n",
       "20                  EB1_unconditional      0.4324     0.1013     0.2316   \n",
       "21             ResNet50_unconditional      0.4556     0.1237     0.1053   \n",
       "22  ConvNeXt_small_sd_lora_1e5_scale1      0.3424     0.0895     0.3684   \n",
       "23   ConvNeXt_tiny_sd_lora_1e5_scale1      0.4599     0.2801     0.2842   \n",
       "24             EB0_sd_lora_1e5_scale1      0.3633     0.1331     0.1579   \n",
       "25             EB1_sd_lora_1e5_scale1      0.3606     0.1324     0.2632   \n",
       "26        ResNet50_sd_lora_1e5_scale1      0.2567     0.1638     0.0526   \n",
       "\n",
       "   0_Rec_std 0_F1_mean 0_F1_std 1_Prec_mean 1_Prec_std 1_Rec_mean  ...  \\\n",
       "2     0.0918    0.3478   0.0923      0.7273     0.0994     0.7739  ...   \n",
       "3     0.1021    0.3023   0.0815      0.8151     0.1308     0.7391  ...   \n",
       "4     0.0614    0.1416   0.0936      0.6886     0.0436     0.7739  ...   \n",
       "5     0.0614    0.1461     0.09      0.7228     0.0666     0.8174  ...   \n",
       "6     0.0211    0.2186   0.0289      0.8016     0.0763      0.687  ...   \n",
       "7     0.0537    0.2431   0.0496      0.7672     0.0587     0.6783  ...   \n",
       "8     0.1489     0.223   0.1445      0.7041     0.0663     0.7739  ...   \n",
       "9     0.0918    0.2145   0.0899      0.7083     0.0833        0.6  ...   \n",
       "10    0.0714    0.2632   0.0601      0.7208     0.0573     0.7478  ...   \n",
       "11    0.0744    0.1744   0.0672      0.7729     0.0779     0.5826  ...   \n",
       "12    0.1901     0.372   0.1517      0.6993      0.085     0.8261  ...   \n",
       "13    0.0632    0.3982   0.0505      0.7703     0.0444     0.7913  ...   \n",
       "14    0.0714    0.3205   0.0544      0.6591     0.0338     0.7826  ...   \n",
       "15    0.0471    0.3485   0.0525      0.7339     0.0601     0.7304  ...   \n",
       "16    0.0965    0.1459   0.1345      0.6023     0.0831        0.8  ...   \n",
       "17    0.1021    0.3107     0.06      0.8089     0.0641     0.7652  ...   \n",
       "18    0.0976    0.3175   0.0573      0.7145     0.1134     0.8348  ...   \n",
       "19    0.0976    0.2558   0.1295      0.8099     0.0778     0.7913  ...   \n",
       "20    0.0788    0.2898   0.0606      0.7959     0.0651     0.8087  ...   \n",
       "21    0.0577    0.1627    0.071       0.747     0.0572     0.7478  ...   \n",
       "22      0.12    0.3451   0.0749       0.877     0.0595      0.687  ...   \n",
       "23    0.1134    0.2981   0.0872      0.7637     0.1326     0.7652  ...   \n",
       "24    0.0577    0.2152    0.066      0.6926     0.1063      0.713  ...   \n",
       "25    0.1912    0.2886   0.1631      0.7589     0.0715     0.7913  ...   \n",
       "26    0.0333    0.0835   0.0476      0.6018     0.0968     0.7304  ...   \n",
       "\n",
       "   4_Prec_mean 4_Prec_std 4_Rec_mean 4_Rec_std 4_F1_mean 4_F1_std acc_mean  \\\n",
       "2       0.1167     0.1453     0.1375    0.2179    0.1171    0.164   0.7880   \n",
       "3       0.2243     0.1596     0.2625    0.2215    0.2088    0.141   0.7760   \n",
       "4       0.1623      0.054       0.25    0.1677    0.1882   0.0777   0.7429   \n",
       "5       0.2667     0.0882     0.2625    0.1212    0.2521   0.0814   0.7677   \n",
       "6       0.1819     0.0549     0.2125    0.1403    0.1843   0.0869   0.7641   \n",
       "7       0.4226     0.1534     0.2625       0.1    0.3176   0.1125   0.7705   \n",
       "8       0.3358     0.0502        0.3    0.1275    0.3094   0.0954   0.7742   \n",
       "9       0.2448      0.049       0.25    0.1046    0.2418   0.0752   0.7502   \n",
       "10      0.3867     0.1867      0.225    0.1016    0.2706   0.1047   0.7751   \n",
       "11      0.3211     0.1559      0.275      0.05    0.2824   0.0707   0.7502   \n",
       "12        0.38     0.3132     0.1375    0.0468     0.165   0.0267   0.7834   \n",
       "13      0.2437     0.0602       0.25    0.1311    0.2372   0.0867   0.7843   \n",
       "14      0.1905      0.103     0.1125    0.0829    0.1382   0.0888   0.7954   \n",
       "15      0.2333     0.0624     0.1625    0.0637    0.1766   0.0459   0.7899   \n",
       "16      0.1804     0.1215        0.1     0.109    0.1137   0.0974   0.7677   \n",
       "17      0.5455     0.2422      0.275    0.1287     0.312   0.1088   0.8028   \n",
       "18      0.3567      0.256      0.125    0.0884    0.1762   0.1144   0.7982   \n",
       "19      0.1751     0.1112     0.1875    0.1768    0.1748   0.1378   0.7797   \n",
       "20      0.2268     0.1316       0.25    0.1896    0.2342   0.1544   0.7853   \n",
       "21      0.3527     0.0717      0.375    0.0884    0.3599    0.069   0.7816   \n",
       "22      0.2794     0.0891      0.225    0.0935    0.2401   0.0857   0.7779   \n",
       "23      0.2687     0.0938      0.175    0.0729    0.1992   0.0678   0.7834   \n",
       "24      0.0792     0.0781        0.1    0.1016    0.0883   0.0883   0.7659   \n",
       "25      0.2359      0.128        0.3    0.2318    0.2547   0.1652   0.7816   \n",
       "26      0.1603     0.0865     0.2375    0.1392    0.1909    0.106   0.7373   \n",
       "\n",
       "   acc_std bal_acc_mean bal_acc_std  \n",
       "2   0.0105       0.5528      0.0304  \n",
       "3   0.0386       0.5396      0.0501  \n",
       "4   0.0272       0.4815      0.0417  \n",
       "5   0.0171       0.5217      0.0326  \n",
       "6   0.0128       0.5067      0.0192  \n",
       "7   0.0181       0.5334      0.0225  \n",
       "8   0.0077       0.5419      0.0250  \n",
       "9   0.0232       0.4922      0.0349  \n",
       "10  0.0074       0.5351      0.0148  \n",
       "11  0.0225       0.4891      0.0390  \n",
       "12  0.0247       0.5599      0.0493  \n",
       "13  0.0150       0.5617      0.0160  \n",
       "14  0.0111       0.5605      0.0147  \n",
       "15  0.0211       0.5549      0.0263  \n",
       "16  0.0080       0.5064      0.0212  \n",
       "17  0.0183       0.5886      0.0265  \n",
       "18  0.0223       0.5737      0.0298  \n",
       "19  0.0079       0.5365      0.0238  \n",
       "20  0.0132       0.5569      0.0374  \n",
       "21  0.0195       0.5460      0.0306  \n",
       "22  0.0188       0.5502      0.0323  \n",
       "23  0.0041       0.5492      0.0206  \n",
       "24  0.0125       0.5054      0.0145  \n",
       "25  0.0126       0.5584      0.0504  \n",
       "26  0.0165       0.4674      0.0352  \n",
       "\n",
       "[25 rows x 35 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('export/clf_metrics/model_metrics_500.csv')\n",
    "df.columns = ['model']+[f'{x}_{y}_{z}' for x,y,z in itertools.product([0,1,2,3,4],['Prec','Rec','F1'],['mean','std'])]+['acc_mean','acc_std','bal_acc_mean','bal_acc_std']\n",
    "df.drop(index=[0,1],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 76.77 $\\pm$ 0.8 & 79.54 $\\pm$ 1.11 & 78.99 $\\pm$ 2.11 & 78.43 $\\pm$ 1.5 & 78.34 $\\pm$ 2.47 \\\\\n",
      "finetuning & 75.02 $\\pm$ 2.25 & 75.02 $\\pm$ 2.32 & 77.51 $\\pm$ 0.74 & 77.42 $\\pm$ 0.77 & 77.05 $\\pm$ 1.81 \\\\\n",
      "gan & 76.41 $\\pm$ 1.28 & 74.29 $\\pm$ 2.72 & 76.77 $\\pm$ 1.71 & 77.6 $\\pm$ 3.86 & 78.8 $\\pm$ 1.05 \\\\\n",
      "lora & 73.73 $\\pm$ 1.65 & 76.59 $\\pm$ 1.25 & 78.16 $\\pm$ 1.26 & 78.34 $\\pm$ 0.41 & 77.79 $\\pm$ 1.88 \\\\\n",
      "unconditional & 78.16 $\\pm$ 1.95 & 77.97 $\\pm$ 0.79 & 78.53 $\\pm$ 1.32 & 79.82 $\\pm$ 2.23 & 80.28 $\\pm$ 1.83 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_acc_mean','EB0_acc_mean','EB1_acc_mean','ConvNeXt_tiny_acc_mean','ConvNeXt_small_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_acc_mean</th>\n",
       "      <th>EB0_acc_mean</th>\n",
       "      <th>EB1_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_acc_mean</th>\n",
       "      <th>ConvNeXt_small_acc_mean</th>\n",
       "      <th>mean_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>-0.0369</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>-0.01864</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0184</td>\n",
       "      <td>-0.0442</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>-0.0065</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>-0.01494</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0452</td>\n",
       "      <td>-0.0212</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0074</td>\n",
       "      <td>-0.01346</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>-0.0074</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.00684</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ResNet50_acc_mean  EB0_acc_mean  EB1_acc_mean  \\\n",
       "0     dreambooth            -0.0148        0.0083        0.0139   \n",
       "1     finetuning            -0.0323       -0.0369       -0.0009   \n",
       "2            gan            -0.0184       -0.0442       -0.0083   \n",
       "3           lora            -0.0452       -0.0212        0.0056   \n",
       "4  unconditional            -0.0009       -0.0074        0.0093   \n",
       "\n",
       "   ConvNeXt_tiny_acc_mean  ConvNeXt_small_acc_mean  mean_acc_mean  \\\n",
       "0                  0.0018                  -0.0019        0.00146   \n",
       "1                 -0.0083                  -0.0148       -0.01864   \n",
       "2                 -0.0065                   0.0027       -0.01494   \n",
       "3                  0.0009                  -0.0074       -0.01346   \n",
       "4                  0.0157                   0.0175        0.00684   \n",
       "\n",
       "   additional_images  \n",
       "0                500  \n",
       "1                500  \n",
       "2                500  \n",
       "3                500  \n",
       "4                500  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & -1.48 & 0.83 & 1.39 & 0.18 & -0.19 & 0.15 \\\\\n",
      "finetuning & -3.23 & -3.69 & -0.09 & -0.83 & -1.48 & -1.86 \\\\\n",
      "gan & -1.84 & -4.42 & -0.83 & -0.65 & 0.27 & -1.49 \\\\\n",
      "lora & -4.52 & -2.12 & 0.56 & 0.09 & -0.74 & -1.35 \\\\\n",
      "unconditional & -0.09 & -0.74 & 0.93 & 1.57 & 1.75 & 0.68 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.23 & -2.03 & 0.39 & 0.07 & -0.08 & -0.77 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot = pd.concat([df_total_pivot,df_pivot_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df,metric=['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_std</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_std</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_std</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_std</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>ResNet50_bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.5599</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>0.5617</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.5605</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.5549</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.5064</td>\n",
       "      <td>0.0212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>0.5334</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.5419</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.4922</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.4891</td>\n",
       "      <td>0.0390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>0.5528</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.5396</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>0.4815</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.5217</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.0192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>0.5502</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.5054</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.5886</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.5737</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.5569</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>0.0306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ConvNeXt_small_bal_acc_mean  ConvNeXt_small_bal_acc_std  \\\n",
       "0     dreambooth                       0.5599                      0.0493   \n",
       "1     finetuning                       0.5334                      0.0225   \n",
       "2            gan                       0.5528                      0.0304   \n",
       "3           lora                       0.5502                      0.0323   \n",
       "4  unconditional                       0.5886                      0.0265   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_tiny_bal_acc_std  EB0_bal_acc_mean  \\\n",
       "0                      0.5617                     0.0160            0.5605   \n",
       "1                      0.5419                     0.0250            0.4922   \n",
       "2                      0.5396                     0.0501            0.4815   \n",
       "3                      0.5492                     0.0206            0.5054   \n",
       "4                      0.5737                     0.0298            0.5365   \n",
       "\n",
       "   EB0_bal_acc_std  EB1_bal_acc_mean  EB1_bal_acc_std  ResNet50_bal_acc_mean  \\\n",
       "0           0.0147            0.5549           0.0263                 0.5064   \n",
       "1           0.0349            0.5351           0.0148                 0.4891   \n",
       "2           0.0417            0.5217           0.0326                 0.5067   \n",
       "3           0.0145            0.5584           0.0504                 0.4674   \n",
       "4           0.0238            0.5569           0.0374                 0.5460   \n",
       "\n",
       "   ResNet50_bal_acc_std  \n",
       "0                0.0212  \n",
       "1                0.0390  \n",
       "2                0.0192  \n",
       "3                0.0352  \n",
       "4                0.0306  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 50.64 $\\pm$ 2.12 & 56.05 $\\pm$ 1.47 & 55.49 $\\pm$ 2.63 & 56.17 $\\pm$ 1.6 & 55.99 $\\pm$ 4.93 \\\\\n",
      "finetuning & 48.91 $\\pm$ 3.9 & 49.22 $\\pm$ 3.49 & 53.51 $\\pm$ 1.48 & 54.19 $\\pm$ 2.5 & 53.34 $\\pm$ 2.25 \\\\\n",
      "gan & 50.67 $\\pm$ 1.92 & 48.15 $\\pm$ 4.17 & 52.17 $\\pm$ 3.26 & 53.96 $\\pm$ 5.01 & 55.28 $\\pm$ 3.04 \\\\\n",
      "lora & 46.74 $\\pm$ 3.52 & 50.54 $\\pm$ 1.45 & 55.84 $\\pm$ 5.04 & 54.92 $\\pm$ 2.06 & 55.02 $\\pm$ 3.23 \\\\\n",
      "unconditional & 54.6 $\\pm$ 3.06 & 53.65 $\\pm$ 2.38 & 55.69 $\\pm$ 3.74 & 57.37 $\\pm$ 2.98 & 58.86 $\\pm$ 2.65 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_bal_acc_mean','EB0_bal_acc_mean','EB1_bal_acc_mean','ConvNeXt_tiny_bal_acc_mean','ConvNeXt_small_bal_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_bal_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_bal_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>mean_bal_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>-0.0158</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.00354</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0331</td>\n",
       "      <td>-0.0478</td>\n",
       "      <td>-0.0171</td>\n",
       "      <td>-0.0216</td>\n",
       "      <td>-0.0144</td>\n",
       "      <td>-0.02680</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0155</td>\n",
       "      <td>-0.0585</td>\n",
       "      <td>-0.0305</td>\n",
       "      <td>-0.0239</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>-0.02468</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.0346</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>-0.01902</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.01520</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ResNet50_bal_acc_mean  EB0_bal_acc_mean  EB1_bal_acc_mean  \\\n",
       "0     dreambooth                -0.0158            0.0205            0.0027   \n",
       "1     finetuning                -0.0331           -0.0478           -0.0171   \n",
       "2            gan                -0.0155           -0.0585           -0.0305   \n",
       "3           lora                -0.0548           -0.0346            0.0062   \n",
       "4  unconditional                 0.0238           -0.0035            0.0047   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_small_bal_acc_mean  mean_bal_acc_mean  \\\n",
       "0                     -0.0018                       0.0121            0.00354   \n",
       "1                     -0.0216                      -0.0144           -0.02680   \n",
       "2                     -0.0239                       0.0050           -0.02468   \n",
       "3                     -0.0143                       0.0024           -0.01902   \n",
       "4                      0.0102                       0.0408            0.01520   \n",
       "\n",
       "   additional_images  \n",
       "0                500  \n",
       "1                500  \n",
       "2                500  \n",
       "3                500  \n",
       "4                500  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & -1.58 & 2.05 & 0.27 & -0.18 & 1.21 & 0.35 \\\\\n",
      "finetuning & -3.31 & -4.78 & -1.71 & -2.16 & -1.44 & -2.68 \\\\\n",
      "gan & -1.55 & -5.85 & -3.05 & -2.39 & 0.5 & -2.47 \\\\\n",
      "lora & -5.48 & -3.46 & 0.62 & -1.43 & 0.24 & -1.9 \\\\\n",
      "unconditional & 2.38 & -0.35 & 0.47 & 1.02 & 4.08 & 1.52 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['bal_acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.91 & -2.48 & -0.68 & -1.03 & 0.92 & -1.04 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta,metric='bal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot_balacc = pd.concat([df_total_pivot_balacc,df_pivot_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_names = ['ConvNeXt_small_gan','ConvNeXt_tiny_gan','EB0_gan','EB1_gan','ResNet50_gan',\n",
    "#                   'ConvNeXt_small_sd_finetuning','ConvNeXt_tiny_sd_finetuning','EB0_sd_finetuning','EB1_sd_finetuning','ResNet50_sd_finetuning',\n",
    "#                   'ConvNeXt_small_sd_dreambooth','ConvNeXt_tiny_sd_dreambooth','EB0_sd_dreambooth','EB1_sd_dreambooth','ResNet50_sd_dreambooth',\n",
    "#                   'ConvNeXt_small_unconditional','ConvNeXt_tiny_unconditional','EB0_unconditional','EB1_unconditional','ResNet50_unconditional',\n",
    "#                   'ConvNeXt_small_sd_lora_1e5_scale1','ConvNeXt_tiny_sd_lora_1e5_scale1','EB0_sd_lora_1e5_scale1','EB1_sd_lora_1e5_scale1','ResNet50_sd_lora_1e5_scale1']\n",
    "# calc_save_metrics(experiment_names,additional_images=750,csv_name='model_metrics_750.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>0_Prec_mean</th>\n",
       "      <th>0_Prec_std</th>\n",
       "      <th>0_Rec_mean</th>\n",
       "      <th>0_Rec_std</th>\n",
       "      <th>0_F1_mean</th>\n",
       "      <th>0_F1_std</th>\n",
       "      <th>1_Prec_mean</th>\n",
       "      <th>1_Prec_std</th>\n",
       "      <th>1_Rec_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>4_Prec_mean</th>\n",
       "      <th>4_Prec_std</th>\n",
       "      <th>4_Rec_mean</th>\n",
       "      <th>4_Rec_std</th>\n",
       "      <th>4_F1_mean</th>\n",
       "      <th>4_F1_std</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>bal_acc_mean</th>\n",
       "      <th>bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ConvNeXt_small_gan</td>\n",
       "      <td>0.3786</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.3053</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.3259</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.7889</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1816</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.7770</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.5362</td>\n",
       "      <td>0.0305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvNeXt_tiny_gan</td>\n",
       "      <td>0.3986</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.8366</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.0355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EB0_gan</td>\n",
       "      <td>0.4159</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>0.3053</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.3091</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.8026</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>0.6087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.1177</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.0422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EB1_gan</td>\n",
       "      <td>0.2899</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0983</td>\n",
       "      <td>0.7591</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.7558</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.5089</td>\n",
       "      <td>0.0189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ResNet50_gan</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.7841</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.0957</td>\n",
       "      <td>0.0746</td>\n",
       "      <td>0.7558</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.4874</td>\n",
       "      <td>0.0299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ConvNeXt_small_sd_finetuning</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.2774</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.7558</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.2544</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1649</td>\n",
       "      <td>0.2396</td>\n",
       "      <td>0.1303</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.0264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ConvNeXt_tiny_sd_finetuning</td>\n",
       "      <td>0.2954</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.2316</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.2294</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.6634</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>0.7739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.3534</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.7687</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.5439</td>\n",
       "      <td>0.0279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EB0_sd_finetuning</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>0.0982</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.7353</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.0269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EB1_sd_finetuning</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>0.2316</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.2944</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.6957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4261</td>\n",
       "      <td>0.1476</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.3498</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.0201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ResNet50_sd_finetuning</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.1084</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.8042</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.5913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3592</td>\n",
       "      <td>0.1104</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>0.7622</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.0257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ConvNeXt_small_sd_dreambooth</td>\n",
       "      <td>0.4323</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.3458</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.6499</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3522</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.7889</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.5540</td>\n",
       "      <td>0.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ConvNeXt_tiny_sd_dreambooth</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.3507</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.7155</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2571</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.1887</td>\n",
       "      <td>0.1246</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.5623</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EB0_sd_dreambooth</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.0469</td>\n",
       "      <td>0.7638</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.7705</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.5116</td>\n",
       "      <td>0.0116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EB1_sd_dreambooth</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.6717</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.8261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2619</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.5497</td>\n",
       "      <td>0.0228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ResNet50_sd_dreambooth</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.2924</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1854</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.5387</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ConvNeXt_small_unconditional</td>\n",
       "      <td>0.3659</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.3224</td>\n",
       "      <td>0.1153</td>\n",
       "      <td>0.7152</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3131</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.2327</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.7853</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.5586</td>\n",
       "      <td>0.0416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ConvNeXt_tiny_unconditional</td>\n",
       "      <td>0.3609</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.3053</td>\n",
       "      <td>0.1742</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.8261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.1629</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.1659</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.5543</td>\n",
       "      <td>0.0119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EB0_unconditional</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.2037</td>\n",
       "      <td>0.2421</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.3159</td>\n",
       "      <td>0.1295</td>\n",
       "      <td>0.8109</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1591</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.1104</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.0442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EB1_unconditional</td>\n",
       "      <td>0.4355</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.2421</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.7764</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3004</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.7816</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.5488</td>\n",
       "      <td>0.0521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ResNet50_unconditional</td>\n",
       "      <td>0.4468</td>\n",
       "      <td>0.1113</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.6986</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3291</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.5486</td>\n",
       "      <td>0.0332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ConvNeXt_small_sd_lora_1e5_scale1</td>\n",
       "      <td>0.3219</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.3003</td>\n",
       "      <td>0.1078</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.8261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.1341</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.0307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ConvNeXt_tiny_sd_lora_1e5_scale1</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.3263</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.3425</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.7769</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.1956</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.7760</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.5444</td>\n",
       "      <td>0.0319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EB0_sd_lora_1e5_scale1</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.1142</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.6602</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1309</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.1284</td>\n",
       "      <td>0.0826</td>\n",
       "      <td>0.7594</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>0.0216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EB1_sd_lora_1e5_scale1</td>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.1684</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.7622</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.7391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.7668</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.0288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ResNet50_sd_lora_1e5_scale1</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.5292</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.1317</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>0.7465</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.4751</td>\n",
       "      <td>0.0226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                model 0_Prec_mean 0_Prec_std 0_Rec_mean  \\\n",
       "2                  ConvNeXt_small_gan      0.3786      0.112     0.3053   \n",
       "3                   ConvNeXt_tiny_gan      0.3986     0.0601     0.3368   \n",
       "4                             EB0_gan      0.4159     0.0547     0.3053   \n",
       "5                             EB1_gan      0.2899     0.1695     0.1263   \n",
       "6                        ResNet50_gan        0.29     0.1329     0.1368   \n",
       "7        ConvNeXt_small_sd_finetuning       0.278     0.0763     0.2842   \n",
       "8         ConvNeXt_tiny_sd_finetuning      0.2954      0.065     0.2316   \n",
       "9                   EB0_sd_finetuning      0.4856     0.0982     0.2105   \n",
       "10                  EB1_sd_finetuning       0.417     0.1235     0.2316   \n",
       "11             ResNet50_sd_finetuning      0.2482     0.0614     0.1789   \n",
       "12       ConvNeXt_small_sd_dreambooth      0.4323     0.0876     0.2947   \n",
       "13        ConvNeXt_tiny_sd_dreambooth      0.4857     0.1051     0.2842   \n",
       "14                  EB0_sd_dreambooth      0.4771     0.0928     0.2211   \n",
       "15                  EB1_sd_dreambooth      0.4857     0.0694     0.1158   \n",
       "16             ResNet50_sd_dreambooth        0.48     0.1451     0.2211   \n",
       "17       ConvNeXt_small_unconditional      0.3659     0.1201     0.3158   \n",
       "18        ConvNeXt_tiny_unconditional      0.3609     0.1209     0.3053   \n",
       "19                  EB0_unconditional      0.6077     0.2037     0.2421   \n",
       "20                  EB1_unconditional      0.4355      0.046     0.2421   \n",
       "21             ResNet50_unconditional      0.4468     0.1113     0.2211   \n",
       "22  ConvNeXt_small_sd_lora_1e5_scale1      0.3219     0.0696     0.2947   \n",
       "23   ConvNeXt_tiny_sd_lora_1e5_scale1       0.368     0.0519     0.3263   \n",
       "24             EB0_sd_lora_1e5_scale1      0.4588     0.1142        0.2   \n",
       "25             EB1_sd_lora_1e5_scale1      0.3331     0.0788     0.1684   \n",
       "26        ResNet50_sd_lora_1e5_scale1        0.42     0.3816     0.0632   \n",
       "\n",
       "   0_Rec_std 0_F1_mean 0_F1_std 1_Prec_mean 1_Prec_std 1_Rec_mean  ...  \\\n",
       "2     0.0842    0.3259   0.0707      0.7889      0.077     0.7565  ...   \n",
       "3     0.0714     0.355   0.0405      0.8366     0.0927     0.7478  ...   \n",
       "4      0.171    0.3091   0.1291      0.8026     0.1137     0.6087  ...   \n",
       "5     0.0788      0.17   0.0983      0.7591      0.057     0.7565  ...   \n",
       "6     0.0976    0.1764   0.1017      0.7841     0.0882     0.7304  ...   \n",
       "7     0.1134    0.2774   0.0903      0.7558     0.1252     0.7217  ...   \n",
       "8      0.178    0.2294   0.1213      0.6634     0.0904     0.7739  ...   \n",
       "9     0.0666     0.281   0.0616      0.7353     0.1455     0.6435  ...   \n",
       "10    0.0537    0.2944    0.068      0.7779     0.0706     0.6957  ...   \n",
       "11    0.1084    0.1992   0.0885      0.8042     0.0533     0.5913  ...   \n",
       "12    0.0714    0.3458     0.07      0.6499     0.0362        0.8  ...   \n",
       "13    0.0537    0.3507   0.0533      0.7155     0.0888     0.7826  ...   \n",
       "14    0.0614     0.291   0.0469      0.7638     0.0962     0.6435  ...   \n",
       "15    0.0394    0.1833   0.0544      0.6717     0.0909     0.8261  ...   \n",
       "16    0.0394    0.2924   0.0349      0.6571     0.0735     0.7565  ...   \n",
       "17    0.1412    0.3224   0.1153      0.7152     0.0822     0.8174  ...   \n",
       "18    0.1742    0.2842   0.0808       0.728     0.0932     0.8261  ...   \n",
       "19    0.1228    0.3159   0.1295      0.8109     0.0855      0.713  ...   \n",
       "20    0.1436    0.2837   0.1249      0.7764     0.1358     0.7565  ...   \n",
       "21    0.1219    0.2872   0.1366      0.6986     0.0684     0.7478  ...   \n",
       "22    0.1396    0.3003   0.1078       0.764     0.1055     0.8261  ...   \n",
       "23    0.1021    0.3425   0.0824      0.7769     0.0281     0.8174  ...   \n",
       "24    0.1021     0.252   0.1035      0.6602     0.0393     0.7217  ...   \n",
       "25    0.0774    0.2193   0.0783      0.7622     0.0598     0.7391  ...   \n",
       "26    0.0614    0.1071   0.1005      0.5292     0.0224     0.7304  ...   \n",
       "\n",
       "   4_Prec_mean 4_Prec_std 4_Rec_mean 4_Rec_std 4_F1_mean 4_F1_std acc_mean  \\\n",
       "2       0.1816     0.1122     0.1375       0.1     0.146    0.086   0.7770   \n",
       "3       0.2271     0.1313        0.1    0.0637    0.1348   0.0783   0.7945   \n",
       "4       0.1445     0.1138     0.1375    0.1275    0.1377   0.1177   0.7475   \n",
       "5       0.2458     0.0186        0.3    0.1447    0.2565   0.0701   0.7558   \n",
       "6       0.0874     0.0583     0.1125    0.1075    0.0957   0.0746   0.7558   \n",
       "7       0.5405     0.2544        0.2    0.1649    0.2396   0.1303   0.7779   \n",
       "8        0.426      0.097       0.35    0.1458    0.3534   0.0733   0.7687   \n",
       "9       0.2099     0.1221     0.1125    0.1075    0.1311   0.1018   0.7751   \n",
       "10      0.4261     0.1476        0.3    0.0829    0.3498   0.1051   0.7751   \n",
       "11      0.3592     0.1104     0.2625    0.0729    0.2998   0.0819   0.7622   \n",
       "12      0.3756     0.3522        0.1    0.0848    0.1209    0.077   0.7889   \n",
       "13      0.2571     0.1402     0.1625    0.1159    0.1887   0.1246   0.7917   \n",
       "14      0.0835     0.0687     0.0875     0.075    0.0842   0.0692   0.7705   \n",
       "15      0.2619      0.173     0.0625    0.0395    0.0995   0.0636   0.7972   \n",
       "16      0.1854     0.1389     0.1375    0.1335    0.1512   0.1257   0.7825   \n",
       "17      0.3131     0.0532     0.2125    0.1287    0.2327   0.1136   0.7853   \n",
       "18      0.1879     0.1629      0.175    0.1741     0.177   0.1659   0.7834   \n",
       "19      0.1591     0.0985      0.175    0.1275    0.1646   0.1104   0.7724   \n",
       "20      0.3004     0.0926      0.225     0.109    0.2394   0.0985   0.7816   \n",
       "21      0.3291     0.0909        0.3    0.1212     0.304   0.0841   0.7825   \n",
       "22      0.3039     0.1184     0.2875    0.1879    0.2743   0.1341   0.7806   \n",
       "23      0.2167     0.0782        0.2    0.1275    0.1956   0.1018   0.7760   \n",
       "24      0.1309     0.0968     0.1625    0.1346    0.1284   0.0826   0.7594   \n",
       "25        0.14       0.08     0.0875      0.05    0.1028   0.0564   0.7668   \n",
       "26      0.1266     0.0731       0.15    0.1159    0.1317   0.0894   0.7465   \n",
       "\n",
       "   acc_std bal_acc_mean bal_acc_std  \n",
       "2   0.0207       0.5362      0.0305  \n",
       "3   0.0192       0.5609      0.0355  \n",
       "4   0.0227       0.4828      0.0422  \n",
       "5   0.0127       0.5089      0.0189  \n",
       "6   0.0172       0.4874      0.0299  \n",
       "7   0.0183       0.5425      0.0264  \n",
       "8   0.0138       0.5439      0.0279  \n",
       "9   0.0153       0.5179      0.0269  \n",
       "10  0.0098       0.5405      0.0201  \n",
       "11  0.0135       0.5056      0.0257  \n",
       "12  0.0163       0.5540      0.0222  \n",
       "13  0.0253       0.5623      0.0258  \n",
       "14  0.0111       0.5116      0.0116  \n",
       "15  0.0137       0.5497      0.0228  \n",
       "16  0.0089       0.5387      0.0141  \n",
       "17  0.0231       0.5586      0.0416  \n",
       "18  0.0146       0.5543      0.0119  \n",
       "19  0.0161       0.5255      0.0442  \n",
       "20  0.0266       0.5488      0.0521  \n",
       "21  0.0132       0.5486      0.0332  \n",
       "22  0.0195       0.5584      0.0307  \n",
       "23  0.0147       0.5444      0.0319  \n",
       "24  0.0213       0.5068      0.0216  \n",
       "25  0.0145       0.5107      0.0288  \n",
       "26  0.0162       0.4751      0.0226  \n",
       "\n",
       "[25 rows x 35 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('export/clf_metrics/model_metrics_750.csv')\n",
    "df.columns = ['model']+[f'{x}_{y}_{z}' for x,y,z in itertools.product([0,1,2,3,4],['Prec','Rec','F1'],['mean','std'])]+['acc_mean','acc_std','bal_acc_mean','bal_acc_std']\n",
    "df.drop(index=[0,1],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 78.25 $\\pm$ 0.89 & 77.05 $\\pm$ 1.11 & 79.72 $\\pm$ 1.37 & 79.17 $\\pm$ 2.53 & 78.89 $\\pm$ 1.63 \\\\\n",
      "finetuning & 76.22 $\\pm$ 1.35 & 77.51 $\\pm$ 1.53 & 77.51 $\\pm$ 0.98 & 76.87 $\\pm$ 1.38 & 77.79 $\\pm$ 1.83 \\\\\n",
      "gan & 75.58 $\\pm$ 1.72 & 74.75 $\\pm$ 2.27 & 75.58 $\\pm$ 1.27 & 79.45 $\\pm$ 1.92 & 77.7 $\\pm$ 2.07 \\\\\n",
      "lora & 74.65 $\\pm$ 1.62 & 75.94 $\\pm$ 2.13 & 76.68 $\\pm$ 1.45 & 77.6 $\\pm$ 1.47 & 78.06 $\\pm$ 1.95 \\\\\n",
      "unconditional & 78.25 $\\pm$ 1.32 & 77.24 $\\pm$ 1.61 & 78.16 $\\pm$ 2.66 & 78.34 $\\pm$ 1.46 & 78.53 $\\pm$ 2.31 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_acc_mean','EB0_acc_mean','EB1_acc_mean','ConvNeXt_tiny_acc_mean','ConvNeXt_small_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_acc_mean</th>\n",
       "      <th>EB0_acc_mean</th>\n",
       "      <th>EB1_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_acc_mean</th>\n",
       "      <th>ConvNeXt_small_acc_mean</th>\n",
       "      <th>mean_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.00348</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0203</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>-0.0138</td>\n",
       "      <td>-0.0074</td>\n",
       "      <td>-0.01088</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0267</td>\n",
       "      <td>-0.0396</td>\n",
       "      <td>-0.0202</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>-0.01656</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0360</td>\n",
       "      <td>-0.0277</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>-0.0065</td>\n",
       "      <td>-0.0047</td>\n",
       "      <td>-0.01682</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0147</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.00164</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ResNet50_acc_mean  EB0_acc_mean  EB1_acc_mean  \\\n",
       "0     dreambooth             0.0000       -0.0166        0.0212   \n",
       "1     finetuning            -0.0203       -0.0120       -0.0009   \n",
       "2            gan            -0.0267       -0.0396       -0.0202   \n",
       "3           lora            -0.0360       -0.0277       -0.0092   \n",
       "4  unconditional             0.0000       -0.0147        0.0056   \n",
       "\n",
       "   ConvNeXt_tiny_acc_mean  ConvNeXt_small_acc_mean  mean_acc_mean  \\\n",
       "0                  0.0092                   0.0036        0.00348   \n",
       "1                 -0.0138                  -0.0074       -0.01088   \n",
       "2                  0.0120                  -0.0083       -0.01656   \n",
       "3                 -0.0065                  -0.0047       -0.01682   \n",
       "4                  0.0009                   0.0000       -0.00164   \n",
       "\n",
       "   additional_images  \n",
       "0                750  \n",
       "1                750  \n",
       "2                750  \n",
       "3                750  \n",
       "4                750  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 0.0 & -1.66 & 2.12 & 0.92 & 0.36 & 0.35 \\\\\n",
      "finetuning & -2.03 & -1.2 & -0.09 & -1.38 & -0.74 & -1.09 \\\\\n",
      "gan & -2.67 & -3.96 & -2.02 & 1.2 & -0.83 & -1.66 \\\\\n",
      "lora & -3.6 & -2.77 & -0.92 & -0.65 & -0.47 & -1.68 \\\\\n",
      "unconditional & 0.0 & -1.47 & 0.56 & 0.09 & 0.0 & -0.16 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.66 & -2.21 & -0.07 & 0.04 & -0.34 & -0.85 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot = pd.concat([df_total_pivot,df_pivot_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df,metric=['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_std</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_std</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_std</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_std</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>ResNet50_bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.5540</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.5623</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.5116</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.5497</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.5387</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.5439</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.0257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>0.5362</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.5089</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.4874</td>\n",
       "      <td>0.0299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.5444</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.4751</td>\n",
       "      <td>0.0226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.5586</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.5543</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.5488</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.5486</td>\n",
       "      <td>0.0332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ConvNeXt_small_bal_acc_mean  ConvNeXt_small_bal_acc_std  \\\n",
       "0     dreambooth                       0.5540                      0.0222   \n",
       "1     finetuning                       0.5425                      0.0264   \n",
       "2            gan                       0.5362                      0.0305   \n",
       "3           lora                       0.5584                      0.0307   \n",
       "4  unconditional                       0.5586                      0.0416   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_tiny_bal_acc_std  EB0_bal_acc_mean  \\\n",
       "0                      0.5623                     0.0258            0.5116   \n",
       "1                      0.5439                     0.0279            0.5179   \n",
       "2                      0.5609                     0.0355            0.4828   \n",
       "3                      0.5444                     0.0319            0.5068   \n",
       "4                      0.5543                     0.0119            0.5255   \n",
       "\n",
       "   EB0_bal_acc_std  EB1_bal_acc_mean  EB1_bal_acc_std  ResNet50_bal_acc_mean  \\\n",
       "0           0.0116            0.5497           0.0228                 0.5387   \n",
       "1           0.0269            0.5405           0.0201                 0.5056   \n",
       "2           0.0422            0.5089           0.0189                 0.4874   \n",
       "3           0.0216            0.5107           0.0288                 0.4751   \n",
       "4           0.0442            0.5488           0.0521                 0.5486   \n",
       "\n",
       "   ResNet50_bal_acc_std  \n",
       "0                0.0141  \n",
       "1                0.0257  \n",
       "2                0.0299  \n",
       "3                0.0226  \n",
       "4                0.0332  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 53.87 $\\pm$ 1.41 & 51.16 $\\pm$ 1.16 & 54.97 $\\pm$ 2.28 & 56.23 $\\pm$ 2.58 & 55.4 $\\pm$ 2.22 \\\\\n",
      "finetuning & 50.56 $\\pm$ 2.57 & 51.79 $\\pm$ 2.69 & 54.05 $\\pm$ 2.01 & 54.39 $\\pm$ 2.79 & 54.25 $\\pm$ 2.64 \\\\\n",
      "gan & 48.74 $\\pm$ 2.99 & 48.28 $\\pm$ 4.22 & 50.89 $\\pm$ 1.89 & 56.09 $\\pm$ 3.55 & 53.62 $\\pm$ 3.05 \\\\\n",
      "lora & 47.51 $\\pm$ 2.26 & 50.68 $\\pm$ 2.16 & 51.07 $\\pm$ 2.88 & 54.44 $\\pm$ 3.19 & 55.84 $\\pm$ 3.07 \\\\\n",
      "unconditional & 54.86 $\\pm$ 3.32 & 52.55 $\\pm$ 4.42 & 54.88 $\\pm$ 5.21 & 55.43 $\\pm$ 1.19 & 55.86 $\\pm$ 4.16 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_bal_acc_mean','EB0_bal_acc_mean','EB1_bal_acc_mean','ConvNeXt_tiny_bal_acc_mean','ConvNeXt_small_bal_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_bal_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_bal_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>mean_bal_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>-0.0284</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>-0.00188</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>-0.0221</td>\n",
       "      <td>-0.0117</td>\n",
       "      <td>-0.0196</td>\n",
       "      <td>-0.0053</td>\n",
       "      <td>-0.01506</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0348</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>-0.0433</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>-0.0116</td>\n",
       "      <td>-0.02990</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0471</td>\n",
       "      <td>-0.0332</td>\n",
       "      <td>-0.0415</td>\n",
       "      <td>-0.0191</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>-0.02606</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>-0.0145</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ResNet50_bal_acc_mean  EB0_bal_acc_mean  EB1_bal_acc_mean  \\\n",
       "0     dreambooth                 0.0165           -0.0284           -0.0025   \n",
       "1     finetuning                -0.0166           -0.0221           -0.0117   \n",
       "2            gan                -0.0348           -0.0572           -0.0433   \n",
       "3           lora                -0.0471           -0.0332           -0.0415   \n",
       "4  unconditional                 0.0264           -0.0145           -0.0034   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_small_bal_acc_mean  mean_bal_acc_mean  \\\n",
       "0                     -0.0012                       0.0062           -0.00188   \n",
       "1                     -0.0196                      -0.0053           -0.01506   \n",
       "2                     -0.0026                      -0.0116           -0.02990   \n",
       "3                     -0.0191                       0.0106           -0.02606   \n",
       "4                     -0.0092                       0.0108            0.00202   \n",
       "\n",
       "   additional_images  \n",
       "0                750  \n",
       "1                750  \n",
       "2                750  \n",
       "3                750  \n",
       "4                750  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 1.65 & -2.84 & -0.25 & -0.12 & 0.62 & -0.19 \\\\\n",
      "finetuning & -1.66 & -2.21 & -1.17 & -1.96 & -0.53 & -1.51 \\\\\n",
      "gan & -3.48 & -5.72 & -4.33 & -0.26 & -1.16 & -2.99 \\\\\n",
      "lora & -4.71 & -3.32 & -4.15 & -1.91 & 1.06 & -2.61 \\\\\n",
      "unconditional & 2.64 & -1.45 & -0.34 & -0.92 & 1.08 & 0.2 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['bal_acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.11 & -3.11 & -2.05 & -1.03 & 0.21 & -1.42 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta,metric='bal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot_balacc = pd.concat([df_total_pivot_balacc,df_pivot_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_names = ['ConvNeXt_small_gan','ConvNeXt_tiny_gan','EB0_gan','EB1_gan','ResNet50_gan',\n",
    "#                   'ConvNeXt_small_sd_finetuning','ConvNeXt_tiny_sd_finetuning','EB0_sd_finetuning','EB1_sd_finetuning','ResNet50_sd_finetuning',\n",
    "#                   'ConvNeXt_small_sd_dreambooth','ConvNeXt_tiny_sd_dreambooth','EB0_sd_dreambooth','EB1_sd_dreambooth','ResNet50_sd_dreambooth',\n",
    "#                   'ConvNeXt_small_unconditional','ConvNeXt_tiny_unconditional','EB0_unconditional','EB1_unconditional','ResNet50_unconditional',\n",
    "#                   'ConvNeXt_small_sd_lora_1e5_scale1','ConvNeXt_tiny_sd_lora_1e5_scale1','EB0_sd_lora_1e5_scale1','EB1_sd_lora_1e5_scale1','ResNet50_sd_lora_1e5_scale1']\n",
    "# calc_save_metrics(experiment_names,additional_images=1000,csv_name='model_metrics_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>0_Prec_mean</th>\n",
       "      <th>0_Prec_std</th>\n",
       "      <th>0_Rec_mean</th>\n",
       "      <th>0_Rec_std</th>\n",
       "      <th>0_F1_mean</th>\n",
       "      <th>0_F1_std</th>\n",
       "      <th>1_Prec_mean</th>\n",
       "      <th>1_Prec_std</th>\n",
       "      <th>1_Rec_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>4_Prec_mean</th>\n",
       "      <th>4_Prec_std</th>\n",
       "      <th>4_Rec_mean</th>\n",
       "      <th>4_Rec_std</th>\n",
       "      <th>4_F1_mean</th>\n",
       "      <th>4_F1_std</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>bal_acc_mean</th>\n",
       "      <th>bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ConvNeXt_small_gan</td>\n",
       "      <td>0.3444</td>\n",
       "      <td>0.0572</td>\n",
       "      <td>0.2421</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.2812</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>0.6857</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.7391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>0.1254</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0935</td>\n",
       "      <td>0.1168</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.5344</td>\n",
       "      <td>0.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvNeXt_tiny_gan</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.4105</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.4224</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.8677</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.6348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2683</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.1713</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.5606</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EB0_gan</td>\n",
       "      <td>0.4651</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.2634</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.7531</td>\n",
       "      <td>0.0517</td>\n",
       "      <td>0.687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1768</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.2247</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.7373</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.4843</td>\n",
       "      <td>0.0214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EB1_gan</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.6967</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.1837</td>\n",
       "      <td>0.2723</td>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.4946</td>\n",
       "      <td>0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ResNet50_gan</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.2192</td>\n",
       "      <td>0.0759</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.7391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.7659</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.5103</td>\n",
       "      <td>0.0182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ConvNeXt_small_sd_finetuning</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.3263</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.8069</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.1501</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.1279</td>\n",
       "      <td>0.7871</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>0.0176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ConvNeXt_tiny_sd_finetuning</td>\n",
       "      <td>0.3094</td>\n",
       "      <td>0.1162</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.2298</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.6407</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4687</td>\n",
       "      <td>0.1398</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.7696</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>0.0207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EB0_sd_finetuning</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3232</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.1889</td>\n",
       "      <td>0.1003</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.6783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.0836</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.7539</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.0181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EB1_sd_finetuning</td>\n",
       "      <td>0.3841</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.1579</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.2153</td>\n",
       "      <td>0.0651</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.6174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.1091</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.0935</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.7613</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.5047</td>\n",
       "      <td>0.0371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ResNet50_sd_finetuning</td>\n",
       "      <td>0.2866</td>\n",
       "      <td>0.0676</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.2312</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4368</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.3537</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.5459</td>\n",
       "      <td>0.0193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ConvNeXt_small_sd_dreambooth</td>\n",
       "      <td>0.4618</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.1104</td>\n",
       "      <td>0.3943</td>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.7466</td>\n",
       "      <td>0.0933</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1826</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.1452</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.7926</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.5644</td>\n",
       "      <td>0.0167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ConvNeXt_tiny_sd_dreambooth</td>\n",
       "      <td>0.4111</td>\n",
       "      <td>0.0814</td>\n",
       "      <td>0.3895</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.3748</td>\n",
       "      <td>0.1143</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>0.1595</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.7871</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.5640</td>\n",
       "      <td>0.0263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EB0_sd_dreambooth</td>\n",
       "      <td>0.6324</td>\n",
       "      <td>0.1942</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.3369</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>0.8046</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.5632</td>\n",
       "      <td>0.0363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EB1_sd_dreambooth</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.1404</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>0.3734</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0559</td>\n",
       "      <td>0.0911</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.5558</td>\n",
       "      <td>0.0169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ResNet50_sd_dreambooth</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.3309</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.2035</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.6779</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.1655</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0967</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.5382</td>\n",
       "      <td>0.0239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ConvNeXt_small_unconditional</td>\n",
       "      <td>0.5447</td>\n",
       "      <td>0.2343</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.2661</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.6926</td>\n",
       "      <td>0.0676</td>\n",
       "      <td>0.7913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3249</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.5558</td>\n",
       "      <td>0.0281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ConvNeXt_tiny_unconditional</td>\n",
       "      <td>0.3178</td>\n",
       "      <td>0.1706</td>\n",
       "      <td>0.2316</td>\n",
       "      <td>0.1272</td>\n",
       "      <td>0.2618</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.7219</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.1239</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.5442</td>\n",
       "      <td>0.0276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EB0_unconditional</td>\n",
       "      <td>0.5681</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.2421</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1808</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.1093</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.5031</td>\n",
       "      <td>0.0201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EB1_unconditional</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.1736</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.6783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3194</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.1829</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.5182</td>\n",
       "      <td>0.0366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ResNet50_unconditional</td>\n",
       "      <td>0.5154</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.3562</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3306</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0791</td>\n",
       "      <td>0.2777</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.7871</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.0253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ConvNeXt_small_sd_lora_1e5_scale1</td>\n",
       "      <td>0.4108</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.2689</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>0.8261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2438</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.1611</td>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.5499</td>\n",
       "      <td>0.0107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ConvNeXt_tiny_sd_lora_1e5_scale1</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2421</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.2655</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.7124</td>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3536</td>\n",
       "      <td>0.1279</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.3106</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.7760</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.5526</td>\n",
       "      <td>0.0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EB0_sd_lora_1e5_scale1</td>\n",
       "      <td>0.3326</td>\n",
       "      <td>0.1281</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.6563</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>0.713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.5117</td>\n",
       "      <td>0.0131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EB1_sd_lora_1e5_scale1</td>\n",
       "      <td>0.2762</td>\n",
       "      <td>0.1798</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.1193</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0777</td>\n",
       "      <td>0.0955</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.5239</td>\n",
       "      <td>0.0239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ResNet50_sd_lora_1e5_scale1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.3709</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>0.0643</td>\n",
       "      <td>0.5767</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1569</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.4993</td>\n",
       "      <td>0.0233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                model 0_Prec_mean 0_Prec_std 0_Rec_mean  \\\n",
       "2                  ConvNeXt_small_gan      0.3444     0.0572     0.2421   \n",
       "3                   ConvNeXt_tiny_gan      0.4535     0.0256     0.4105   \n",
       "4                             EB0_gan      0.4651     0.1474     0.2105   \n",
       "5                             EB1_gan      0.1833     0.1528     0.0316   \n",
       "6                        ResNet50_gan       0.327     0.0979     0.1789   \n",
       "7        ConvNeXt_small_sd_finetuning      0.3497     0.0476     0.3263   \n",
       "8         ConvNeXt_tiny_sd_finetuning      0.3094     0.1162     0.1895   \n",
       "9                   EB0_sd_finetuning      0.4667     0.3232     0.1263   \n",
       "10                  EB1_sd_finetuning      0.3841     0.0775     0.1579   \n",
       "11             ResNet50_sd_finetuning      0.2866     0.0676        0.2   \n",
       "12       ConvNeXt_small_sd_dreambooth      0.4618      0.055     0.3684   \n",
       "13        ConvNeXt_tiny_sd_dreambooth      0.4111     0.0814     0.3895   \n",
       "14                  EB0_sd_dreambooth      0.6324     0.1942     0.2842   \n",
       "15                  EB1_sd_dreambooth       0.456     0.0881     0.2105   \n",
       "16             ResNet50_sd_dreambooth        0.64     0.3309     0.1263   \n",
       "17       ConvNeXt_small_unconditional      0.5447     0.2343        0.2   \n",
       "18        ConvNeXt_tiny_unconditional      0.3178     0.1706     0.2316   \n",
       "19                  EB0_unconditional      0.5681     0.2375     0.2421   \n",
       "20                  EB1_unconditional       0.426     0.1454     0.1263   \n",
       "21             ResNet50_unconditional      0.5154     0.1365     0.2842   \n",
       "22  ConvNeXt_small_sd_lora_1e5_scale1      0.4108     0.0646     0.2211   \n",
       "23   ConvNeXt_tiny_sd_lora_1e5_scale1      0.3039     0.0418     0.2421   \n",
       "24             EB0_sd_lora_1e5_scale1      0.3326     0.1281     0.1789   \n",
       "25             EB1_sd_lora_1e5_scale1      0.2762     0.1798     0.1158   \n",
       "26        ResNet50_sd_lora_1e5_scale1        0.38     0.3709     0.0421   \n",
       "\n",
       "   0_Rec_std 0_F1_mean 0_F1_std 1_Prec_mean 1_Prec_std 1_Rec_mean  ...  \\\n",
       "2     0.0788    0.2812   0.0751      0.6857     0.0672     0.7391  ...   \n",
       "3     0.1021    0.4224   0.0464      0.8677     0.0404     0.6348  ...   \n",
       "4     0.1451    0.2634   0.1296      0.7531     0.0517      0.687  ...   \n",
       "5     0.0258    0.0538   0.0439      0.6967     0.0761      0.713  ...   \n",
       "6     0.0855    0.2192   0.0759      0.7625     0.0386     0.7391  ...   \n",
       "7     0.1389     0.321   0.0928      0.8069     0.1197     0.6522  ...   \n",
       "8     0.0537    0.2298   0.0697      0.6407     0.0831     0.7565  ...   \n",
       "9     0.0714    0.1889   0.1003      0.7144     0.1019     0.6783  ...   \n",
       "10    0.0666    0.2153   0.0651      0.8017     0.1002     0.6174  ...   \n",
       "11    0.0774    0.2312    0.069      0.7121      0.085     0.7304  ...   \n",
       "12    0.1104    0.3943   0.0486      0.7466     0.0933     0.8174  ...   \n",
       "13    0.1582    0.3748   0.1143       0.773     0.0881     0.8174  ...   \n",
       "14    0.1582    0.3369   0.1416      0.7959     0.0647      0.713  ...   \n",
       "15    0.1451    0.2507    0.111       0.743     0.1404     0.7304  ...   \n",
       "16    0.0537    0.2035   0.0849      0.6779      0.079     0.8174  ...   \n",
       "17    0.0774    0.2661   0.0637      0.6926     0.0676     0.7913  ...   \n",
       "18    0.1272    0.2618   0.1357      0.7219     0.0996     0.7565  ...   \n",
       "19    0.1228    0.2983   0.1251      0.7576     0.0511     0.6435  ...   \n",
       "20    0.0714    0.1736   0.0566      0.7526     0.0625     0.6783  ...   \n",
       "21    0.0788    0.3562   0.0723      0.7483     0.0594      0.713  ...   \n",
       "22    0.0906    0.2689   0.0647       0.669     0.1007     0.8261  ...   \n",
       "23    0.0788    0.2655   0.0686      0.7124     0.1109     0.7565  ...   \n",
       "24    0.1182    0.2186   0.1145      0.6563     0.0996      0.713  ...   \n",
       "25    0.0906    0.1619   0.1193      0.7096     0.0333     0.8174  ...   \n",
       "26    0.0394    0.0724   0.0643      0.5767     0.0881     0.7478  ...   \n",
       "\n",
       "   4_Prec_mean 4_Prec_std 4_Rec_mean 4_Rec_std 4_F1_mean 4_F1_std acc_mean  \\\n",
       "2       0.1516     0.1254        0.1    0.0935    0.1168   0.1002   0.7806   \n",
       "3       0.2683     0.0383       0.15    0.1159    0.1713   0.0813   0.7917   \n",
       "4       0.1768      0.032      0.325    0.1447    0.2247    0.062   0.7373   \n",
       "5       0.2587     0.0815     0.3375    0.1837    0.2723   0.1164   0.7502   \n",
       "6       0.1051     0.0863     0.1375    0.1212    0.1182   0.0991   0.7659   \n",
       "7        0.403     0.1501      0.275    0.1159    0.3207   0.1279   0.7871   \n",
       "8       0.4687     0.1398        0.3    0.0729      0.36   0.0895   0.7696   \n",
       "9        0.187     0.0836        0.1     0.075    0.1147   0.0518   0.7539   \n",
       "10       0.315     0.1091     0.2125    0.0935     0.242   0.0916   0.7613   \n",
       "11      0.4368     0.0671        0.3     0.025    0.3537   0.0315   0.7806   \n",
       "12      0.1826     0.1581     0.1375    0.1275    0.1452   0.1224   0.7926   \n",
       "13      0.2335     0.1595     0.1375    0.1075    0.1471   0.0888   0.7871   \n",
       "14      0.0667     0.1333      0.025      0.05    0.0364   0.0727   0.8046   \n",
       "15      0.2708     0.3734     0.0625    0.0559    0.0911   0.0849   0.7982   \n",
       "16      0.2467     0.1655     0.0625    0.0395    0.0967    0.058   0.7908   \n",
       "17      0.3249       0.06     0.3125    0.1311    0.3024   0.0541   0.7834   \n",
       "18      0.2917     0.1667      0.175       0.1    0.2178   0.1239   0.7834   \n",
       "19      0.1808     0.0961        0.2    0.1392    0.1866   0.1093   0.7585   \n",
       "20      0.3194     0.0694      0.325    0.1829    0.2892   0.1212   0.7641   \n",
       "21      0.3306     0.0711       0.25    0.0791    0.2777   0.0616   0.7871   \n",
       "22      0.2438     0.1324      0.225    0.1611    0.2236   0.1357   0.7806   \n",
       "23      0.3536     0.1279        0.3    0.1075    0.3106    0.086   0.7760   \n",
       "24      0.1292     0.0795      0.125    0.0884     0.125   0.0812   0.7641   \n",
       "25      0.0777     0.0955        0.1    0.1458     0.083   0.1083   0.7751   \n",
       "26      0.1569     0.0889     0.1625    0.1287    0.1528   0.0991   0.7631   \n",
       "\n",
       "   acc_std bal_acc_mean bal_acc_std  \n",
       "2   0.0139       0.5344      0.0136  \n",
       "3   0.0135       0.5606      0.0258  \n",
       "4   0.0151       0.4843      0.0214  \n",
       "5   0.0230       0.4946      0.0320  \n",
       "6   0.0122       0.5103      0.0182  \n",
       "7   0.0084       0.5620      0.0176  \n",
       "8   0.0117       0.5339      0.0207  \n",
       "9   0.0181       0.4828      0.0181  \n",
       "10  0.0168       0.5047      0.0371  \n",
       "11  0.0095       0.5459      0.0193  \n",
       "12  0.0154       0.5644      0.0167  \n",
       "13  0.0230       0.5640      0.0263  \n",
       "14  0.0171       0.5632      0.0363  \n",
       "15  0.0147       0.5558      0.0169  \n",
       "16  0.0139       0.5382      0.0239  \n",
       "17  0.0167       0.5558      0.0281  \n",
       "18  0.0170       0.5442      0.0276  \n",
       "19  0.0126       0.5031      0.0201  \n",
       "20  0.0221       0.5182      0.0366  \n",
       "21  0.0122       0.5550      0.0253  \n",
       "22  0.0150       0.5499      0.0107  \n",
       "23  0.0197       0.5526      0.0283  \n",
       "24  0.0098       0.5117      0.0131  \n",
       "25  0.0173       0.5239      0.0239  \n",
       "26  0.0150       0.4993      0.0233  \n",
       "\n",
       "[25 rows x 35 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('export/clf_metrics/model_metrics_1000.csv')\n",
    "df.columns = ['model']+[f'{x}_{y}_{z}' for x,y,z in itertools.product([0,1,2,3,4],['Prec','Rec','F1'],['mean','std'])]+['acc_mean','acc_std','bal_acc_mean','bal_acc_std']\n",
    "df.drop(index=[0,1],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 79.08 $\\pm$ 1.39 & 80.46 $\\pm$ 1.71 & 79.82 $\\pm$ 1.47 & 78.71 $\\pm$ 2.3 & 79.26 $\\pm$ 1.54 \\\\\n",
      "finetuning & 78.06 $\\pm$ 0.95 & 75.39 $\\pm$ 1.81 & 76.13 $\\pm$ 1.68 & 76.96 $\\pm$ 1.17 & 78.71 $\\pm$ 0.84 \\\\\n",
      "gan & 76.59 $\\pm$ 1.22 & 73.73 $\\pm$ 1.51 & 75.02 $\\pm$ 2.3 & 79.17 $\\pm$ 1.35 & 78.06 $\\pm$ 1.39 \\\\\n",
      "lora & 76.31 $\\pm$ 1.5 & 76.41 $\\pm$ 0.98 & 77.51 $\\pm$ 1.73 & 77.6 $\\pm$ 1.97 & 78.06 $\\pm$ 1.5 \\\\\n",
      "unconditional & 78.71 $\\pm$ 1.22 & 75.85 $\\pm$ 1.26 & 76.41 $\\pm$ 2.21 & 78.34 $\\pm$ 1.7 & 78.34 $\\pm$ 1.67 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_acc_mean','EB0_acc_mean','EB1_acc_mean','ConvNeXt_tiny_acc_mean','ConvNeXt_small_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_acc_mean</th>\n",
       "      <th>EB0_acc_mean</th>\n",
       "      <th>EB1_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_acc_mean</th>\n",
       "      <th>ConvNeXt_small_acc_mean</th>\n",
       "      <th>mean_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0332</td>\n",
       "      <td>-0.0147</td>\n",
       "      <td>-0.0129</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.01218</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>-0.0498</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>-0.0047</td>\n",
       "      <td>-0.01754</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0230</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>-0.0065</td>\n",
       "      <td>-0.0047</td>\n",
       "      <td>-0.01090</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>-0.0286</td>\n",
       "      <td>-0.0119</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.00738</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ResNet50_acc_mean  EB0_acc_mean  EB1_acc_mean  \\\n",
       "0     dreambooth             0.0083        0.0175        0.0222   \n",
       "1     finetuning            -0.0019       -0.0332       -0.0147   \n",
       "2            gan            -0.0166       -0.0498       -0.0258   \n",
       "3           lora            -0.0194       -0.0230       -0.0009   \n",
       "4  unconditional             0.0046       -0.0286       -0.0119   \n",
       "\n",
       "   ConvNeXt_tiny_acc_mean  ConvNeXt_small_acc_mean  mean_acc_mean  \\\n",
       "0                  0.0046                   0.0073        0.01198   \n",
       "1                 -0.0129                   0.0018       -0.01218   \n",
       "2                  0.0092                  -0.0047       -0.01754   \n",
       "3                 -0.0065                  -0.0047       -0.01090   \n",
       "4                  0.0009                  -0.0019       -0.00738   \n",
       "\n",
       "   additional_images  \n",
       "0               1000  \n",
       "1               1000  \n",
       "2               1000  \n",
       "3               1000  \n",
       "4               1000  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 0.83 & 1.75 & 2.22 & 0.46 & 0.73 & 1.2 \\\\\n",
      "finetuning & -0.19 & -3.32 & -1.47 & -1.29 & 0.18 & -1.22 \\\\\n",
      "gan & -1.66 & -4.98 & -2.58 & 0.92 & -0.47 & -1.75 \\\\\n",
      "lora & -1.94 & -2.3 & -0.09 & -0.65 & -0.47 & -1.09 \\\\\n",
      "unconditional & 0.46 & -2.86 & -1.19 & 0.09 & -0.19 & -0.74 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5 & -2.34 & -0.62 & -0.09 & -0.04 & -0.72 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot = pd.concat([df_total_pivot,df_pivot_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df,metric=['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_std</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_std</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_std</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_std</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>ResNet50_bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.5644</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.5640</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.5632</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.5558</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.5382</td>\n",
       "      <td>0.0239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.5047</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.5459</td>\n",
       "      <td>0.0193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>0.5344</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.5606</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.4843</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.4946</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.5103</td>\n",
       "      <td>0.0182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>0.5499</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.5526</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.5117</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.5239</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.4993</td>\n",
       "      <td>0.0233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.5558</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.5442</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.5031</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.5182</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.0253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ConvNeXt_small_bal_acc_mean  ConvNeXt_small_bal_acc_std  \\\n",
       "0     dreambooth                       0.5644                      0.0167   \n",
       "1     finetuning                       0.5620                      0.0176   \n",
       "2            gan                       0.5344                      0.0136   \n",
       "3           lora                       0.5499                      0.0107   \n",
       "4  unconditional                       0.5558                      0.0281   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_tiny_bal_acc_std  EB0_bal_acc_mean  \\\n",
       "0                      0.5640                     0.0263            0.5632   \n",
       "1                      0.5339                     0.0207            0.4828   \n",
       "2                      0.5606                     0.0258            0.4843   \n",
       "3                      0.5526                     0.0283            0.5117   \n",
       "4                      0.5442                     0.0276            0.5031   \n",
       "\n",
       "   EB0_bal_acc_std  EB1_bal_acc_mean  EB1_bal_acc_std  ResNet50_bal_acc_mean  \\\n",
       "0           0.0363            0.5558           0.0169                 0.5382   \n",
       "1           0.0181            0.5047           0.0371                 0.5459   \n",
       "2           0.0214            0.4946           0.0320                 0.5103   \n",
       "3           0.0131            0.5239           0.0239                 0.4993   \n",
       "4           0.0201            0.5182           0.0366                 0.5550   \n",
       "\n",
       "   ResNet50_bal_acc_std  \n",
       "0                0.0239  \n",
       "1                0.0193  \n",
       "2                0.0182  \n",
       "3                0.0233  \n",
       "4                0.0253  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 53.82 $\\pm$ 2.39 & 56.32 $\\pm$ 3.63 & 55.58 $\\pm$ 1.69 & 56.4 $\\pm$ 2.63 & 56.44 $\\pm$ 1.67 \\\\\n",
      "finetuning & 54.59 $\\pm$ 1.93 & 48.28 $\\pm$ 1.81 & 50.47 $\\pm$ 3.71 & 53.39 $\\pm$ 2.07 & 56.2 $\\pm$ 1.76 \\\\\n",
      "gan & 51.03 $\\pm$ 1.82 & 48.43 $\\pm$ 2.14 & 49.46 $\\pm$ 3.2 & 56.06 $\\pm$ 2.58 & 53.44 $\\pm$ 1.36 \\\\\n",
      "lora & 49.93 $\\pm$ 2.33 & 51.17 $\\pm$ 1.31 & 52.39 $\\pm$ 2.39 & 55.26 $\\pm$ 2.83 & 54.99 $\\pm$ 1.07 \\\\\n",
      "unconditional & 55.5 $\\pm$ 2.53 & 50.31 $\\pm$ 2.01 & 51.82 $\\pm$ 3.66 & 54.42 $\\pm$ 2.76 & 55.58 $\\pm$ 2.81 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_bal_acc_mean','EB0_bal_acc_mean','EB1_bal_acc_mean','ConvNeXt_tiny_bal_acc_mean','ConvNeXt_small_bal_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_bal_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_bal_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>mean_bal_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>-0.0475</td>\n",
       "      <td>-0.0296</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0119</td>\n",
       "      <td>-0.0557</td>\n",
       "      <td>-0.0576</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>-0.0134</td>\n",
       "      <td>-0.02830</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0229</td>\n",
       "      <td>-0.0283</td>\n",
       "      <td>-0.0283</td>\n",
       "      <td>-0.0109</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>-0.01766</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>-0.0369</td>\n",
       "      <td>-0.0340</td>\n",
       "      <td>-0.0193</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>-0.00988</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ResNet50_bal_acc_mean  EB0_bal_acc_mean  EB1_bal_acc_mean  \\\n",
       "0     dreambooth                 0.0160            0.0232            0.0036   \n",
       "1     finetuning                 0.0237           -0.0572           -0.0475   \n",
       "2            gan                -0.0119           -0.0557           -0.0576   \n",
       "3           lora                -0.0229           -0.0283           -0.0283   \n",
       "4  unconditional                 0.0328           -0.0369           -0.0340   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_small_bal_acc_mean  mean_bal_acc_mean  \\\n",
       "0                      0.0005                       0.0166            0.01198   \n",
       "1                     -0.0296                       0.0142           -0.01928   \n",
       "2                     -0.0029                      -0.0134           -0.02830   \n",
       "3                     -0.0109                       0.0021           -0.01766   \n",
       "4                     -0.0193                       0.0080           -0.00988   \n",
       "\n",
       "   additional_images  \n",
       "0               1000  \n",
       "1               1000  \n",
       "2               1000  \n",
       "3               1000  \n",
       "4               1000  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 1.6 & 2.32 & 0.36 & 0.05 & 1.66 & 1.2 \\\\\n",
      "finetuning & 2.37 & -5.72 & -4.75 & -2.96 & 1.42 & -1.93 \\\\\n",
      "gan & -1.19 & -5.57 & -5.76 & -0.29 & -1.34 & -2.83 \\\\\n",
      "lora & -2.29 & -2.83 & -2.83 & -1.09 & 0.21 & -1.77 \\\\\n",
      "unconditional & 3.28 & -3.69 & -3.4 & -1.93 & 0.8 & -0.99 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['bal_acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 & -3.1 & -3.28 & -1.24 & 0.55 & -1.26 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta,metric='bal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot_balacc = pd.concat([df_total_pivot_balacc,df_pivot_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_names = ['ConvNeXt_small_gan','ConvNeXt_tiny_gan','EB0_gan','EB1_gan','ResNet50_gan']\n",
    "# calc_save_metrics(experiment_names,additional_images=5000,csv_name='model_metrics_5000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>0_Prec_mean</th>\n",
       "      <th>0_Prec_std</th>\n",
       "      <th>0_Rec_mean</th>\n",
       "      <th>0_Rec_std</th>\n",
       "      <th>0_F1_mean</th>\n",
       "      <th>0_F1_std</th>\n",
       "      <th>1_Prec_mean</th>\n",
       "      <th>1_Prec_std</th>\n",
       "      <th>1_Rec_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>4_Prec_mean</th>\n",
       "      <th>4_Prec_std</th>\n",
       "      <th>4_Rec_mean</th>\n",
       "      <th>4_Rec_std</th>\n",
       "      <th>4_F1_mean</th>\n",
       "      <th>4_F1_std</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>bal_acc_mean</th>\n",
       "      <th>bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ConvNeXt_small_gan</td>\n",
       "      <td>0.4161</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>0.3565</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.8191</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.6696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1605</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.5498</td>\n",
       "      <td>0.0241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvNeXt_tiny_gan</td>\n",
       "      <td>0.3867</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.3144</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.8353</td>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.5913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0935</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.7613</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.5038</td>\n",
       "      <td>0.0230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EB0_gan</td>\n",
       "      <td>0.4589</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.2675</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.0785</td>\n",
       "      <td>0.6087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0972</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.7521</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.4797</td>\n",
       "      <td>0.0194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EB1_gan</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>0.2906</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.2643</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.6909</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.6261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.7613</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.0177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ResNet50_gan</td>\n",
       "      <td>0.4722</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.5217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1908</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.7364</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.4827</td>\n",
       "      <td>0.0201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                model 0_Prec_mean 0_Prec_std 0_Rec_mean 0_Rec_std 0_F1_mean  \\\n",
       "2  ConvNeXt_small_gan      0.4161     0.1387     0.3158    0.1331    0.3565   \n",
       "3   ConvNeXt_tiny_gan      0.3867      0.116     0.2737    0.0842    0.3144   \n",
       "4             EB0_gan      0.4589     0.0585     0.2105    0.0999    0.2675   \n",
       "5             EB1_gan      0.5516     0.2906        0.2    0.0774    0.2643   \n",
       "6        ResNet50_gan      0.4722     0.1338     0.1789    0.0855    0.2488   \n",
       "\n",
       "  0_F1_std 1_Prec_mean 1_Prec_std 1_Rec_mean  ... 4_Prec_mean 4_Prec_std  \\\n",
       "2    0.141      0.8191      0.051     0.6696  ...      0.1605     0.1031   \n",
       "3   0.0886      0.8353     0.1159     0.5913  ...      0.1614     0.0507   \n",
       "4   0.0802       0.757     0.0785     0.6087  ...      0.0972     0.0879   \n",
       "5   0.0672      0.6909     0.0769     0.6261  ...      0.1232      0.147   \n",
       "6   0.1005      0.8444     0.0556     0.5217  ...      0.1908     0.0627   \n",
       "\n",
       "  4_Rec_mean 4_Rec_std 4_F1_mean 4_F1_std acc_mean acc_std bal_acc_mean  \\\n",
       "2        0.1    0.0637    0.1216   0.0756   0.7880  0.0154       0.5498   \n",
       "3       0.15    0.0935    0.1481   0.0641   0.7613  0.0163       0.5038   \n",
       "4     0.0875    0.0848    0.0888   0.0824   0.7521  0.0147       0.4797   \n",
       "5       0.05    0.0468    0.0696     0.07   0.7613  0.0118       0.4944   \n",
       "6      0.375     0.163    0.2482   0.0932   0.7364  0.0125       0.4827   \n",
       "\n",
       "  bal_acc_std  \n",
       "2      0.0241  \n",
       "3      0.0230  \n",
       "4      0.0194  \n",
       "5      0.0177  \n",
       "6      0.0201  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('export/clf_metrics/model_metrics_5000.csv')\n",
    "df.columns = ['model']+[f'{x}_{y}_{z}' for x,y,z in itertools.product([0,1,2,3,4],['Prec','Rec','F1'],['mean','std'])]+['acc_mean','acc_std','bal_acc_mean','bal_acc_std']\n",
    "df.drop(index=[0,1],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['gan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gan & 73.64 $\\pm$ 1.25 & 75.21 $\\pm$ 1.47 & 76.13 $\\pm$ 1.18 & 76.13 $\\pm$ 1.63 & 78.8 $\\pm$ 1.54 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_acc_mean','EB0_acc_mean','EB1_acc_mean','ConvNeXt_tiny_acc_mean','ConvNeXt_small_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_acc_mean</th>\n",
       "      <th>EB0_acc_mean</th>\n",
       "      <th>EB1_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_acc_mean</th>\n",
       "      <th>ConvNeXt_small_acc_mean</th>\n",
       "      <th>mean_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0461</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.0147</td>\n",
       "      <td>-0.0212</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>-0.02286</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  ResNet50_acc_mean  EB0_acc_mean  EB1_acc_mean  \\\n",
       "0    gan            -0.0461        -0.035       -0.0147   \n",
       "\n",
       "   ConvNeXt_tiny_acc_mean  ConvNeXt_small_acc_mean  mean_acc_mean  \\\n",
       "0                 -0.0212                   0.0027       -0.02286   \n",
       "\n",
       "   additional_images  \n",
       "0               5000  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gan & -4.61 & -3.5 & -1.47 & -2.12 & 0.27 & -2.29 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.61 & -3.5 & -1.47 & -2.12 & 0.27 & -2.29 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot = pd.concat([df_total_pivot,df_pivot_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df,metric=['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_std</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_std</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_std</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_std</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>ResNet50_bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gan</td>\n",
       "      <td>0.5498</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.5038</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.4797</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.4827</td>\n",
       "      <td>0.0201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  ConvNeXt_small_bal_acc_mean  ConvNeXt_small_bal_acc_std  \\\n",
       "0    gan                       0.5498                      0.0241   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_tiny_bal_acc_std  EB0_bal_acc_mean  \\\n",
       "0                      0.5038                      0.023            0.4797   \n",
       "\n",
       "   EB0_bal_acc_std  EB1_bal_acc_mean  EB1_bal_acc_std  ResNet50_bal_acc_mean  \\\n",
       "0           0.0194            0.4944           0.0177                 0.4827   \n",
       "\n",
       "   ResNet50_bal_acc_std  \n",
       "0                0.0201  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gan & 48.27 $\\pm$ 2.01 & 47.97 $\\pm$ 1.94 & 49.44 $\\pm$ 1.77 & 50.38 $\\pm$ 2.3 & 54.98 $\\pm$ 2.41 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_bal_acc_mean','EB0_bal_acc_mean','EB1_bal_acc_mean','ConvNeXt_tiny_bal_acc_mean','ConvNeXt_small_bal_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_bal_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_bal_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>mean_bal_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0395</td>\n",
       "      <td>-0.0603</td>\n",
       "      <td>-0.0578</td>\n",
       "      <td>-0.0597</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.04306</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  ResNet50_bal_acc_mean  EB0_bal_acc_mean  EB1_bal_acc_mean  \\\n",
       "0    gan                -0.0395           -0.0603           -0.0578   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_small_bal_acc_mean  mean_bal_acc_mean  \\\n",
       "0                     -0.0597                        0.002           -0.04306   \n",
       "\n",
       "   additional_images  \n",
       "0               5000  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gan & -3.95 & -6.03 & -5.78 & -5.97 & 0.2 & -4.31 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['bal_acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.95 & -6.03 & -5.78 & -5.97 & 0.2 & -4.31 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta,metric='bal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot_balacc = pd.concat([df_total_pivot_balacc,df_pivot_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_names = ['ConvNeXt_small_gan','ConvNeXt_tiny_gan','EB0_gan','EB1_gan','ResNet50_gan']\n",
    "# calc_save_metrics(experiment_names,additional_images=10000,csv_name='model_metrics_10000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>0_Prec_mean</th>\n",
       "      <th>0_Prec_std</th>\n",
       "      <th>0_Rec_mean</th>\n",
       "      <th>0_Rec_std</th>\n",
       "      <th>0_F1_mean</th>\n",
       "      <th>0_F1_std</th>\n",
       "      <th>1_Prec_mean</th>\n",
       "      <th>1_Prec_std</th>\n",
       "      <th>1_Rec_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>4_Prec_mean</th>\n",
       "      <th>4_Prec_std</th>\n",
       "      <th>4_Rec_mean</th>\n",
       "      <th>4_Rec_std</th>\n",
       "      <th>4_F1_mean</th>\n",
       "      <th>4_F1_std</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>bal_acc_mean</th>\n",
       "      <th>bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ConvNeXt_small_gan</td>\n",
       "      <td>0.4569</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.8144</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.5737</td>\n",
       "      <td>0.0306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvNeXt_tiny_gan</td>\n",
       "      <td>0.4381</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.1073</td>\n",
       "      <td>0.2816</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.0469</td>\n",
       "      <td>0.687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1941</td>\n",
       "      <td>0.1279</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0791</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.0975</td>\n",
       "      <td>0.7871</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.0228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EB0_gan</td>\n",
       "      <td>0.4765</td>\n",
       "      <td>0.1174</td>\n",
       "      <td>0.2316</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.6695</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.5826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EB1_gan</td>\n",
       "      <td>0.5822</td>\n",
       "      <td>0.2396</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.2078</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.7706</td>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.6174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.4886</td>\n",
       "      <td>0.0246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ResNet50_gan</td>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>0.2316</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.2707</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.8159</td>\n",
       "      <td>0.1101</td>\n",
       "      <td>0.5913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.7447</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.4825</td>\n",
       "      <td>0.0247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                model 0_Prec_mean 0_Prec_std 0_Rec_mean 0_Rec_std 0_F1_mean  \\\n",
       "2  ConvNeXt_small_gan      0.4569     0.0595        0.4    0.1511    0.4054   \n",
       "3   ConvNeXt_tiny_gan      0.4381     0.0926     0.2211    0.1073    0.2816   \n",
       "4             EB0_gan      0.4765     0.1174     0.2316    0.0976    0.2933   \n",
       "5             EB1_gan      0.5822     0.2396     0.1368    0.0421    0.2078   \n",
       "6        ResNet50_gan      0.3643     0.1204     0.2316    0.0788    0.2707   \n",
       "\n",
       "  0_F1_std 1_Prec_mean 1_Prec_std 1_Rec_mean  ... 4_Prec_mean 4_Prec_std  \\\n",
       "2    0.055      0.8144     0.1343        0.8  ...      0.0848     0.1291   \n",
       "3   0.1176      0.7785     0.0469      0.687  ...      0.1941     0.1279   \n",
       "4   0.0863      0.6695     0.1225     0.5826  ...         0.0        0.0   \n",
       "5   0.0405      0.7706     0.1159     0.6174  ...       0.174     0.0375   \n",
       "6   0.0725      0.8159     0.1101     0.5913  ...      0.0722     0.0887   \n",
       "\n",
       "  4_Rec_mean 4_Rec_std 4_F1_mean 4_F1_std acc_mean acc_std bal_acc_mean  \\\n",
       "2     0.0875    0.1458    0.0854   0.1368   0.7972  0.0204       0.5737   \n",
       "3      0.125    0.0791    0.1517   0.0975   0.7871  0.0098       0.5405   \n",
       "4        0.0       0.0       0.0      0.0   0.7650  0.0105       0.4959   \n",
       "5     0.1875    0.0395     0.179   0.0333   0.7530  0.0156       0.4886   \n",
       "6     0.1375    0.1785    0.0924   0.1135   0.7447  0.0195       0.4825   \n",
       "\n",
       "  bal_acc_std  \n",
       "2      0.0306  \n",
       "3      0.0228  \n",
       "4      0.0160  \n",
       "5      0.0246  \n",
       "6      0.0247  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('export/clf_metrics/model_metrics_10000.csv')\n",
    "df.columns = ['model']+[f'{x}_{y}_{z}' for x,y,z in itertools.product([0,1,2,3,4],['Prec','Rec','F1'],['mean','std'])]+['acc_mean','acc_std','bal_acc_mean','bal_acc_std']\n",
    "df.drop(index=[0,1],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gan & 74.47 $\\pm$ 1.95 & 76.5 $\\pm$ 1.05 & 75.3 $\\pm$ 1.56 & 78.71 $\\pm$ 0.98 & 79.72 $\\pm$ 2.04 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_acc_mean','EB0_acc_mean','EB1_acc_mean','ConvNeXt_tiny_acc_mean','ConvNeXt_small_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_acc_mean</th>\n",
       "      <th>EB0_acc_mean</th>\n",
       "      <th>EB1_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_acc_mean</th>\n",
       "      <th>ConvNeXt_small_acc_mean</th>\n",
       "      <th>mean_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0378</td>\n",
       "      <td>-0.0221</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>-0.01328</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  ResNet50_acc_mean  EB0_acc_mean  EB1_acc_mean  \\\n",
       "0    gan            -0.0378       -0.0221        -0.023   \n",
       "\n",
       "   ConvNeXt_tiny_acc_mean  ConvNeXt_small_acc_mean  mean_acc_mean  \\\n",
       "0                  0.0046                   0.0119       -0.01328   \n",
       "\n",
       "   additional_images  \n",
       "0              10000  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gan & -3.78 & -2.21 & -2.3 & 0.46 & 1.19 & -1.33 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.78 & -2.21 & -2.3 & 0.46 & 1.19 & -1.33 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot = pd.concat([df_total_pivot,df_pivot_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = create_pivot_table(df,metric=['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_std</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_std</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_std</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_std</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>ResNet50_bal_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gan</td>\n",
       "      <td>0.5737</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.4886</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.4825</td>\n",
       "      <td>0.0247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  ConvNeXt_small_bal_acc_mean  ConvNeXt_small_bal_acc_std  \\\n",
       "0    gan                       0.5737                      0.0306   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_tiny_bal_acc_std  EB0_bal_acc_mean  \\\n",
       "0                      0.5405                     0.0228            0.4959   \n",
       "\n",
       "   EB0_bal_acc_std  EB1_bal_acc_mean  EB1_bal_acc_std  ResNet50_bal_acc_mean  \\\n",
       "0            0.016            0.4886           0.0246                 0.4825   \n",
       "\n",
       "   ResNet50_bal_acc_std  \n",
       "0                0.0247  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gan & 48.25 $\\pm$ 2.47 & 49.59 $\\pm$ 1.6 & 48.86 $\\pm$ 2.46 & 54.05 $\\pm$ 2.28 & 57.37 $\\pm$ 3.06 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot,methods,models,['bal_acc_mean','bal_acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta = df_pivot[['method','ResNet50_bal_acc_mean','EB0_bal_acc_mean','EB1_bal_acc_mean','ConvNeXt_tiny_bal_acc_mean','ConvNeXt_small_bal_acc_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,value in baseline_bal_accs.items():\n",
    "    df_pivot_delta[model] = df_pivot_delta[model] - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_delta['mean_bal_acc_mean'] = df_pivot_delta.mean(numeric_only=True,axis=1)\n",
    "df_pivot_delta['additional_images'] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>mean_bal_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0397</td>\n",
       "      <td>-0.0441</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>-0.0289</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  ResNet50_bal_acc_mean  EB0_bal_acc_mean  EB1_bal_acc_mean  \\\n",
       "0    gan                -0.0397           -0.0441           -0.0636   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_small_bal_acc_mean  mean_bal_acc_mean  \\\n",
       "0                      -0.023                       0.0259            -0.0289   \n",
       "\n",
       "   additional_images  \n",
       "0              10000  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gan & -3.97 & -4.41 & -6.36 & -2.3 & 2.59 & -2.89 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval_table_latex(df_pivot_delta,methods,models+['mean'],['bal_acc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.97 & -4.41 & -6.36 & -2.3 & 2.59 & -2.89 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_means_latex(df_pivot_delta,metric='bal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_pivot_balacc = pd.concat([df_total_pivot_balacc,df_pivot_delta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_acc_mean</th>\n",
       "      <th>EB0_acc_mean</th>\n",
       "      <th>EB1_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_acc_mean</th>\n",
       "      <th>ConvNeXt_small_acc_mean</th>\n",
       "      <th>mean_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>-0.0231</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.00162</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0203</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>-0.00590</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0111</td>\n",
       "      <td>-0.0074</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>-0.0157</td>\n",
       "      <td>-0.00370</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0341</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0176</td>\n",
       "      <td>-0.01514</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>-0.0304</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>-0.00828</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.00738</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>-0.0175</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>-0.0157</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>-0.00426</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0406</td>\n",
       "      <td>-0.0073</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>-0.01716</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0443</td>\n",
       "      <td>-0.0240</td>\n",
       "      <td>-0.0073</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>-0.01346</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>-0.0231</td>\n",
       "      <td>-0.0249</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>-0.0369</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>-0.01864</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0184</td>\n",
       "      <td>-0.0442</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>-0.0065</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>-0.01494</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0452</td>\n",
       "      <td>-0.0212</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0074</td>\n",
       "      <td>-0.01346</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>-0.0074</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.00684</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.00348</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0203</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>-0.0138</td>\n",
       "      <td>-0.0074</td>\n",
       "      <td>-0.01088</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0267</td>\n",
       "      <td>-0.0396</td>\n",
       "      <td>-0.0202</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>-0.01656</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0360</td>\n",
       "      <td>-0.0277</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>-0.0065</td>\n",
       "      <td>-0.0047</td>\n",
       "      <td>-0.01682</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0147</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.00164</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0332</td>\n",
       "      <td>-0.0147</td>\n",
       "      <td>-0.0129</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.01218</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>-0.0498</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>-0.0047</td>\n",
       "      <td>-0.01754</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0230</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>-0.0065</td>\n",
       "      <td>-0.0047</td>\n",
       "      <td>-0.01090</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>-0.0286</td>\n",
       "      <td>-0.0119</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.00738</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0461</td>\n",
       "      <td>-0.0350</td>\n",
       "      <td>-0.0147</td>\n",
       "      <td>-0.0212</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>-0.02286</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0378</td>\n",
       "      <td>-0.0221</td>\n",
       "      <td>-0.0230</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>-0.01328</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ResNet50_acc_mean  EB0_acc_mean  EB1_acc_mean  \\\n",
       "0     dreambooth            -0.0231        0.0083        0.0175   \n",
       "1     finetuning            -0.0203       -0.0166       -0.0027   \n",
       "2            gan            -0.0111       -0.0074        0.0083   \n",
       "3           lora            -0.0341       -0.0258        0.0000   \n",
       "4  unconditional            -0.0258       -0.0304        0.0093   \n",
       "0     dreambooth             0.0000        0.0000        0.0231   \n",
       "1     finetuning            -0.0028       -0.0175        0.0046   \n",
       "2            gan            -0.0194       -0.0406       -0.0073   \n",
       "3           lora            -0.0443       -0.0240       -0.0073   \n",
       "4  unconditional            -0.0231       -0.0249        0.0129   \n",
       "0     dreambooth            -0.0148        0.0083        0.0139   \n",
       "1     finetuning            -0.0323       -0.0369       -0.0009   \n",
       "2            gan            -0.0184       -0.0442       -0.0083   \n",
       "3           lora            -0.0452       -0.0212        0.0056   \n",
       "4  unconditional            -0.0009       -0.0074        0.0093   \n",
       "0     dreambooth             0.0000       -0.0166        0.0212   \n",
       "1     finetuning            -0.0203       -0.0120       -0.0009   \n",
       "2            gan            -0.0267       -0.0396       -0.0202   \n",
       "3           lora            -0.0360       -0.0277       -0.0092   \n",
       "4  unconditional             0.0000       -0.0147        0.0056   \n",
       "0     dreambooth             0.0083        0.0175        0.0222   \n",
       "1     finetuning            -0.0019       -0.0332       -0.0147   \n",
       "2            gan            -0.0166       -0.0498       -0.0258   \n",
       "3           lora            -0.0194       -0.0230       -0.0009   \n",
       "4  unconditional             0.0046       -0.0286       -0.0119   \n",
       "0            gan            -0.0461       -0.0350       -0.0147   \n",
       "0            gan            -0.0378       -0.0221       -0.0230   \n",
       "\n",
       "   ConvNeXt_tiny_acc_mean  ConvNeXt_small_acc_mean  mean_acc_mean  \\\n",
       "0                 -0.0019                   0.0073        0.00162   \n",
       "1                 -0.0083                   0.0184       -0.00590   \n",
       "2                  0.0074                  -0.0157       -0.00370   \n",
       "3                  0.0018                  -0.0176       -0.01514   \n",
       "4                 -0.0037                   0.0092       -0.00828   \n",
       "0                  0.0129                   0.0009        0.00738   \n",
       "1                 -0.0157                   0.0101       -0.00426   \n",
       "2                 -0.0148                  -0.0037       -0.01716   \n",
       "3                  0.0028                   0.0055       -0.01346   \n",
       "4                  0.0092                   0.0258       -0.00002   \n",
       "0                  0.0018                  -0.0019        0.00146   \n",
       "1                 -0.0083                  -0.0148       -0.01864   \n",
       "2                 -0.0065                   0.0027       -0.01494   \n",
       "3                  0.0009                  -0.0074       -0.01346   \n",
       "4                  0.0157                   0.0175        0.00684   \n",
       "0                  0.0092                   0.0036        0.00348   \n",
       "1                 -0.0138                  -0.0074       -0.01088   \n",
       "2                  0.0120                  -0.0083       -0.01656   \n",
       "3                 -0.0065                  -0.0047       -0.01682   \n",
       "4                  0.0009                   0.0000       -0.00164   \n",
       "0                  0.0046                   0.0073        0.01198   \n",
       "1                 -0.0129                   0.0018       -0.01218   \n",
       "2                  0.0092                  -0.0047       -0.01754   \n",
       "3                 -0.0065                  -0.0047       -0.01090   \n",
       "4                  0.0009                  -0.0019       -0.00738   \n",
       "0                 -0.0212                   0.0027       -0.02286   \n",
       "0                  0.0046                   0.0119       -0.01328   \n",
       "\n",
       "   additional_images  \n",
       "0                100  \n",
       "1                100  \n",
       "2                100  \n",
       "3                100  \n",
       "4                100  \n",
       "0                250  \n",
       "1                250  \n",
       "2                250  \n",
       "3                250  \n",
       "4                250  \n",
       "0                500  \n",
       "1                500  \n",
       "2                500  \n",
       "3                500  \n",
       "4                500  \n",
       "0                750  \n",
       "1                750  \n",
       "2                750  \n",
       "3                750  \n",
       "4                750  \n",
       "0               1000  \n",
       "1               1000  \n",
       "2               1000  \n",
       "3               1000  \n",
       "4               1000  \n",
       "0               5000  \n",
       "0              10000  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean per model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['dreambooth','finetuning','gan','lora','unconditional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_means = np.mean(df_total_pivot[['ResNet50_acc_mean','EB0_acc_mean','EB1_acc_mean','ConvNeXt_tiny_acc_mean','ConvNeXt_small_acc_mean']].values,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "\n",
    "for method in methods:\n",
    "    text = text + method + ' & '\n",
    "    mean_list = np.mean(df_total_pivot.loc[df_total_pivot['method']==method,['ResNet50_acc_mean','EB0_acc_mean','EB1_acc_mean','ConvNeXt_tiny_acc_mean','ConvNeXt_small_acc_mean']].values,axis=0)\n",
    "    total_mean = np.mean(df_total_pivot.loc[df_total_pivot['method']==method,['ResNet50_acc_mean','EB0_acc_mean','EB1_acc_mean','ConvNeXt_tiny_acc_mean','ConvNeXt_small_acc_mean']].values)\n",
    "\n",
    "    for value in np.append(mean_list,total_mean):\n",
    "        text = text + str(round(value*100,2)) + ' & '\n",
    "\n",
    "    text = text[:-2] + '\\\\\\\\' +'\\n'\n",
    "\n",
    "text = text + 'mean' + ' & '\n",
    "for mean in model_means:\n",
    "    text = text + str(round(mean*100,2)) + ' & '\n",
    "text = text[:-2] + '\\\\\\\\' +'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & -0.59 & 0.35 & 1.96 & 0.53 & 0.34 & 0.52 \\\\\n",
      "finetuning & -1.55 & -2.32 & -0.29 & -1.18 & 0.16 & -1.04 \\\\\n",
      "gan & -2.52 & -3.41 & -1.3 & -0.13 & -0.22 & -1.51 \\\\\n",
      "lora & -3.58 & -2.43 & -0.24 & -0.15 & -0.58 & -1.4 \\\\\n",
      "unconditional & -0.9 & -2.12 & 0.5 & 0.46 & 1.01 & -0.21 \\\\\n",
      "mean & -1.88 & -2.09 & 0.02 & -0.1 & 0.12 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean per additional image bracket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "means= np.nanmean(df_total_pivot.pivot(columns='additional_images',index='method',values='mean_acc_mean').values,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'mean & '\n",
    "for value in means:\n",
    "    text = text + str(round(value*100,2)) + ' & '\n",
    "text = text[:-2] + '\\\\\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & 0.16 & 0.74 & 0.15 & 0.35 & 1.2 & nan & nan \\\\\n",
      "finetuning & -0.59 & -0.43 & -1.86 & -1.09 & -1.22 & nan & nan \\\\\n",
      "gan & -0.37 & -1.72 & -1.49 & -1.66 & -1.75 & -2.29 & -1.33 \\\\\n",
      "lora & -1.51 & -1.35 & -1.35 & -1.68 & -1.09 & nan & nan \\\\\n",
      "unconditional & -0.83 & -0.0 & 0.68 & -0.16 & -0.74 & nan & nan \\\\\n",
      "\n",
      "mean & -0.63 & -0.55 & -0.77 & -0.85 & -0.72 & -2.29 & -1.33 \\\\\n"
     ]
    }
   ],
   "source": [
    "print_plain_values_to_latex(df_total_pivot.pivot(columns='additional_images',index='method',values='mean_acc_mean'),rounding=True)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_mapping = {'gan' : 'GAN',\n",
    "                      'dreambooth' : 'DreamBooth',\n",
    "                      'finetuning' : 'Fine-tuning',\n",
    "                      'unconditional' : 'Unconditional',\n",
    "                      'lora' : 'LoRA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_plot = df_total_pivot.pivot(columns='additional_images',index='method',values='mean_acc_mean').reset_index().melt(id_vars='method',value_vars=[100,250,500,750,1000,5000,10000])\n",
    "df_plot['value'] = round(df_plot['value']*100,2)\n",
    "df_plot.rename(columns={'method':'model'},inplace=True)\n",
    "df_plot['model'] = df_plot['model'].map(model_name_mapping)\n",
    "sns.set_context('paper',font_scale=1.25)\n",
    "sns.catplot(data=df_plot,\n",
    "            x='additional_images',y='value',hue='model',\n",
    "            kind='point',palette=None,markers='^',linestyles='--',legend_out=False,aspect=1.2,scale=1)\n",
    "#plt.xlabel('additional images',fontsize=14)\n",
    "#plt.ylabel('value',fontsize=14)\n",
    "plt.savefig('export/clf_metrics/plots/additional_images_acc.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ResNet50_bal_acc_mean</th>\n",
       "      <th>EB0_bal_acc_mean</th>\n",
       "      <th>EB1_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_tiny_bal_acc_mean</th>\n",
       "      <th>ConvNeXt_small_bal_acc_mean</th>\n",
       "      <th>mean_bal_acc_mean</th>\n",
       "      <th>additional_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>-0.0416</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>-0.00046</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>-0.0036</td>\n",
       "      <td>-0.0234</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.00090</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>-0.0068</td>\n",
       "      <td>-0.0154</td>\n",
       "      <td>-0.0077</td>\n",
       "      <td>-0.0327</td>\n",
       "      <td>-0.01064</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.0115</td>\n",
       "      <td>-0.02320</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>-0.0102</td>\n",
       "      <td>-0.0255</td>\n",
       "      <td>-0.0041</td>\n",
       "      <td>-0.0212</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>-0.00430</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.00704</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>-0.0212</td>\n",
       "      <td>-0.0099</td>\n",
       "      <td>-0.0495</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>-0.00664</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0058</td>\n",
       "      <td>-0.0455</td>\n",
       "      <td>-0.0304</td>\n",
       "      <td>-0.0309</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>-0.02302</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0738</td>\n",
       "      <td>-0.0350</td>\n",
       "      <td>-0.0249</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>-0.02062</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>-0.0186</td>\n",
       "      <td>-0.0332</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.00080</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>-0.0158</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.00354</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0331</td>\n",
       "      <td>-0.0478</td>\n",
       "      <td>-0.0171</td>\n",
       "      <td>-0.0216</td>\n",
       "      <td>-0.0144</td>\n",
       "      <td>-0.02680</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0155</td>\n",
       "      <td>-0.0585</td>\n",
       "      <td>-0.0305</td>\n",
       "      <td>-0.0239</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>-0.02468</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.0346</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>-0.01902</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.01520</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>-0.0284</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>-0.00188</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>-0.0221</td>\n",
       "      <td>-0.0117</td>\n",
       "      <td>-0.0196</td>\n",
       "      <td>-0.0053</td>\n",
       "      <td>-0.01506</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0348</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>-0.0433</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>-0.0116</td>\n",
       "      <td>-0.02990</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0471</td>\n",
       "      <td>-0.0332</td>\n",
       "      <td>-0.0415</td>\n",
       "      <td>-0.0191</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>-0.02606</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>-0.0145</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dreambooth</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>-0.0475</td>\n",
       "      <td>-0.0296</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0119</td>\n",
       "      <td>-0.0557</td>\n",
       "      <td>-0.0576</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>-0.0134</td>\n",
       "      <td>-0.02830</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora</td>\n",
       "      <td>-0.0229</td>\n",
       "      <td>-0.0283</td>\n",
       "      <td>-0.0283</td>\n",
       "      <td>-0.0109</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>-0.01766</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unconditional</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>-0.0369</td>\n",
       "      <td>-0.0340</td>\n",
       "      <td>-0.0193</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>-0.00988</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0395</td>\n",
       "      <td>-0.0603</td>\n",
       "      <td>-0.0578</td>\n",
       "      <td>-0.0597</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>-0.04306</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gan</td>\n",
       "      <td>-0.0397</td>\n",
       "      <td>-0.0441</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.0230</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>-0.02890</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  ResNet50_bal_acc_mean  EB0_bal_acc_mean  EB1_bal_acc_mean  \\\n",
       "0     dreambooth                -0.0416            0.0202            0.0198   \n",
       "1     finetuning                -0.0046           -0.0060           -0.0036   \n",
       "2            gan                 0.0094           -0.0068           -0.0154   \n",
       "3           lora                -0.0750           -0.0333            0.0010   \n",
       "4  unconditional                -0.0102           -0.0255           -0.0041   \n",
       "0     dreambooth                 0.0052           -0.0014            0.0222   \n",
       "1     finetuning                 0.0209           -0.0212           -0.0099   \n",
       "2            gan                -0.0058           -0.0455           -0.0304   \n",
       "3           lora                -0.0738           -0.0350           -0.0249   \n",
       "4  unconditional                -0.0186           -0.0332            0.0046   \n",
       "0     dreambooth                -0.0158            0.0205            0.0027   \n",
       "1     finetuning                -0.0331           -0.0478           -0.0171   \n",
       "2            gan                -0.0155           -0.0585           -0.0305   \n",
       "3           lora                -0.0548           -0.0346            0.0062   \n",
       "4  unconditional                 0.0238           -0.0035            0.0047   \n",
       "0     dreambooth                 0.0165           -0.0284           -0.0025   \n",
       "1     finetuning                -0.0166           -0.0221           -0.0117   \n",
       "2            gan                -0.0348           -0.0572           -0.0433   \n",
       "3           lora                -0.0471           -0.0332           -0.0415   \n",
       "4  unconditional                 0.0264           -0.0145           -0.0034   \n",
       "0     dreambooth                 0.0160            0.0232            0.0036   \n",
       "1     finetuning                 0.0237           -0.0572           -0.0475   \n",
       "2            gan                -0.0119           -0.0557           -0.0576   \n",
       "3           lora                -0.0229           -0.0283           -0.0283   \n",
       "4  unconditional                 0.0328           -0.0369           -0.0340   \n",
       "0            gan                -0.0395           -0.0603           -0.0578   \n",
       "0            gan                -0.0397           -0.0441           -0.0636   \n",
       "\n",
       "   ConvNeXt_tiny_bal_acc_mean  ConvNeXt_small_bal_acc_mean  mean_bal_acc_mean  \\\n",
       "0                     -0.0079                       0.0072           -0.00046   \n",
       "1                     -0.0234                       0.0421            0.00090   \n",
       "2                     -0.0077                      -0.0327           -0.01064   \n",
       "3                      0.0028                      -0.0115           -0.02320   \n",
       "4                     -0.0212                       0.0395           -0.00430   \n",
       "0                      0.0089                       0.0003            0.00704   \n",
       "1                     -0.0495                       0.0265           -0.00664   \n",
       "2                     -0.0309                      -0.0025           -0.02302   \n",
       "3                      0.0013                       0.0293           -0.02062   \n",
       "4                      0.0009                       0.0503            0.00080   \n",
       "0                     -0.0018                       0.0121            0.00354   \n",
       "1                     -0.0216                      -0.0144           -0.02680   \n",
       "2                     -0.0239                       0.0050           -0.02468   \n",
       "3                     -0.0143                       0.0024           -0.01902   \n",
       "4                      0.0102                       0.0408            0.01520   \n",
       "0                     -0.0012                       0.0062           -0.00188   \n",
       "1                     -0.0196                      -0.0053           -0.01506   \n",
       "2                     -0.0026                      -0.0116           -0.02990   \n",
       "3                     -0.0191                       0.0106           -0.02606   \n",
       "4                     -0.0092                       0.0108            0.00202   \n",
       "0                      0.0005                       0.0166            0.01198   \n",
       "1                     -0.0296                       0.0142           -0.01928   \n",
       "2                     -0.0029                      -0.0134           -0.02830   \n",
       "3                     -0.0109                       0.0021           -0.01766   \n",
       "4                     -0.0193                       0.0080           -0.00988   \n",
       "0                     -0.0597                       0.0020           -0.04306   \n",
       "0                     -0.0230                       0.0259           -0.02890   \n",
       "\n",
       "   additional_images  \n",
       "0                100  \n",
       "1                100  \n",
       "2                100  \n",
       "3                100  \n",
       "4                100  \n",
       "0                250  \n",
       "1                250  \n",
       "2                250  \n",
       "3                250  \n",
       "4                250  \n",
       "0                500  \n",
       "1                500  \n",
       "2                500  \n",
       "3                500  \n",
       "4                500  \n",
       "0                750  \n",
       "1                750  \n",
       "2                750  \n",
       "3                750  \n",
       "4                750  \n",
       "0               1000  \n",
       "1               1000  \n",
       "2               1000  \n",
       "3               1000  \n",
       "4               1000  \n",
       "0               5000  \n",
       "0              10000  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_pivot_balacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean per model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['dreambooth','finetuning','gan','lora','unconditional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_means = np.mean(df_total_pivot_balacc[['ResNet50_bal_acc_mean','EB0_bal_acc_mean','EB1_bal_acc_mean','ConvNeXt_tiny_bal_acc_mean','ConvNeXt_small_bal_acc_mean']].values,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "\n",
    "for method in methods:\n",
    "    text = text + method + ' & '\n",
    "    mean_list = np.mean(df_total_pivot_balacc.loc[df_total_pivot_balacc['method']==method,['ResNet50_bal_acc_mean','EB0_bal_acc_mean','EB1_bal_acc_mean','ConvNeXt_tiny_bal_acc_mean','ConvNeXt_small_bal_acc_mean']].values,axis=0)\n",
    "    total_mean = np.mean(df_total_pivot_balacc.loc[df_total_pivot_balacc['method']==method,['ResNet50_bal_acc_mean','EB0_bal_acc_mean','EB1_bal_acc_mean','ConvNeXt_tiny_bal_acc_mean','ConvNeXt_small_bal_acc_mean']].values)\n",
    "\n",
    "    for value in np.append(mean_list,total_mean):\n",
    "        text = text + str(round(value*100,2)) + ' & '\n",
    "\n",
    "    text = text[:-2] + '\\\\\\\\' +'\\n'\n",
    "\n",
    "text = text + 'mean' + ' & '\n",
    "for mean in model_means:\n",
    "    text = text + str(round(mean*100,2)) + ' & '\n",
    "text = text[:-2] + '\\\\\\\\' +'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & -0.39 & 0.68 & 0.92 & -0.03 & 0.85 & 0.4 \\\\\n",
      "finetuning & -0.19 & -3.09 & -1.8 & -2.87 & 1.26 & -1.34 \\\\\n",
      "gan & -1.97 & -4.69 & -4.27 & -2.15 & -0.39 & -2.69 \\\\\n",
      "lora & -5.47 & -3.29 & -1.75 & -0.8 & 0.66 & -2.13 \\\\\n",
      "unconditional & 1.08 & -2.27 & -0.64 & -0.77 & 2.99 & 0.08 \\\\\n",
      "mean & -1.43 & -2.69 & -1.71 & -1.39 & 0.96 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean per additional image bracket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>additional_images</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>5000</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dreambooth</th>\n",
       "      <td>-0.00046</td>\n",
       "      <td>0.00704</td>\n",
       "      <td>0.00354</td>\n",
       "      <td>-0.00188</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finetuning</th>\n",
       "      <td>0.00090</td>\n",
       "      <td>-0.00664</td>\n",
       "      <td>-0.02680</td>\n",
       "      <td>-0.01506</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan</th>\n",
       "      <td>-0.01064</td>\n",
       "      <td>-0.02302</td>\n",
       "      <td>-0.02468</td>\n",
       "      <td>-0.02990</td>\n",
       "      <td>-0.02830</td>\n",
       "      <td>-0.04306</td>\n",
       "      <td>-0.0289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lora</th>\n",
       "      <td>-0.02320</td>\n",
       "      <td>-0.02062</td>\n",
       "      <td>-0.01902</td>\n",
       "      <td>-0.02606</td>\n",
       "      <td>-0.01766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unconditional</th>\n",
       "      <td>-0.00430</td>\n",
       "      <td>0.00080</td>\n",
       "      <td>0.01520</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>-0.00988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "additional_images    100      250      500      750      1000     5000   \\\n",
       "method                                                                    \n",
       "dreambooth        -0.00046  0.00704  0.00354 -0.00188  0.01198      NaN   \n",
       "finetuning         0.00090 -0.00664 -0.02680 -0.01506 -0.01928      NaN   \n",
       "gan               -0.01064 -0.02302 -0.02468 -0.02990 -0.02830 -0.04306   \n",
       "lora              -0.02320 -0.02062 -0.01902 -0.02606 -0.01766      NaN   \n",
       "unconditional     -0.00430  0.00080  0.01520  0.00202 -0.00988      NaN   \n",
       "\n",
       "additional_images   10000  \n",
       "method                     \n",
       "dreambooth            NaN  \n",
       "finetuning            NaN  \n",
       "gan               -0.0289  \n",
       "lora                  NaN  \n",
       "unconditional         NaN  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_pivot_balacc.pivot(columns='additional_images',index='method',values='mean_bal_acc_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "means= np.nanmean(df_total_pivot_balacc.pivot(columns='additional_images',index='method',values='mean_bal_acc_mean').values,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'mean & '\n",
    "for value in means:\n",
    "    text = text + str(round(value*100,2)) + ' & '\n",
    "text = text[:-2] + '\\\\\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreambooth & -0.05 & 0.7 & 0.35 & -0.19 & 1.2 & nan & nan \\\\\n",
      "finetuning & 0.09 & -0.66 & -2.68 & -1.51 & -1.93 & nan & nan \\\\\n",
      "gan & -1.06 & -2.3 & -2.47 & -2.99 & -2.83 & -4.31 & -2.89 \\\\\n",
      "lora & -2.32 & -2.06 & -1.9 & -2.61 & -1.77 & nan & nan \\\\\n",
      "unconditional & -0.43 & 0.08 & 1.52 & 0.2 & -0.99 & nan & nan \\\\\n",
      "\n",
      "mean & -0.75 & -0.85 & -1.04 & -1.42 & -1.26 & -4.31 & -2.89 \\\\\n"
     ]
    }
   ],
   "source": [
    "print_plain_values_to_latex(df_total_pivot_balacc.pivot(columns='additional_images',index='method',values='mean_bal_acc_mean'),rounding=True)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_plot = df_total_pivot_balacc.pivot(columns='additional_images',index='method',values='mean_bal_acc_mean').reset_index().melt(id_vars='method',value_vars=[100,250,500,750,1000,5000,10000])\n",
    "df_plot['value'] = round(df_plot['value']*100,2)\n",
    "sns.catplot(data=df_plot,\n",
    "            x='additional_images',y='value',hue='method',\n",
    "            kind='point',palette=None,markers='^',linestyles='--',legend_out=False,aspect=1.2,scale=1)\n",
    "plt.xlabel('additional images',fontsize=14)\n",
    "plt.ylabel('value',fontsize=14)\n",
    "plt.savefig('export/clf_metrics/plots/additional_images_balacc.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_latex(lst,two_elements=False,rounding=None):\n",
    "    string = ''\n",
    "    if rounding:\n",
    "        lst = [round(x,rounding) for x in lst]\n",
    "\n",
    "    if two_elements:\n",
    "        lst1 = lst[0::2]\n",
    "        lst2 = lst[1::2]\n",
    "\n",
    "        for element1,element2 in zip(lst1,lst2):\n",
    "            string = string + f'{str(element1)[1:]} $\\pm$ {str(element2)[1:]} & '\n",
    "\n",
    "    else:\n",
    "        for element in lst:\n",
    "            string = string + str(element) + ' & '\n",
    "\n",
    "    string = string[:-3]\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_mapping = {'Prec' : 'precision',\n",
    "                  'Rec' : 'recall',\n",
    "                  'F1' : 'f1'}\n",
    "\n",
    "df_long = pd.DataFrame()\n",
    "\n",
    "for images in ['100','250','500','750','1000','5000','10000','baseline']:\n",
    "    df = pd.read_csv('../KD_Paper/Revision/export/model_metrics_do_balacc.csv') if images=='baseline' else pd.read_csv(f'export/clf_metrics/model_metrics_{images}.csv')\n",
    "    df.columns = ['model']+[f'{x}_{y}_{z}' for x,y,z in itertools.product([0,1,2,3,4],['Prec','Rec','F1'],['mean','std'])]+['acc_mean','acc_std','bal_acc_mean','bal_acc_std']\n",
    "    df.drop(index=[0,1],inplace=True)\n",
    "\n",
    "    for label,label_name in label_mapping.items():\n",
    "        for metric,metric_name in metric_mapping.items():\n",
    "            for aggfunc in ['mean','std']:\n",
    "                df_temp = pd.DataFrame()\n",
    "                df_temp['value'] = df[f'{label}_{metric}_{aggfunc}']\n",
    "                df_temp['model'] = df['model']\n",
    "                df_temp['var'] = metric_name\n",
    "                df_temp['class'] = label_name\n",
    "                df_temp['aggfunc'] = aggfunc\n",
    "                df_temp['images'] = images\n",
    "\n",
    "                df_long = pd.concat([df_long,df_temp])\n",
    "\n",
    "df_long.reset_index(inplace=True,drop=True)\n",
    "df_long.loc[df_long['model'].str.contains('EB1'),'architecture'] = 'EB1'\n",
    "df_long.loc[df_long['model'].str.contains('EB0'),'architecture'] = 'EB0'\n",
    "df_long.loc[df_long['model'].str.contains('ConvNeXt_small'),'architecture'] = 'ConvNeXt_small'\n",
    "df_long.loc[df_long['model'].str.contains('ConvNeXt_tiny'),'architecture'] = 'ConvNeXt_tiny'\n",
    "df_long.loc[df_long['model'].str.contains('ResNet50'),'architecture'] = 'ResNet50'\n",
    "\n",
    "df_long.loc[df_long['model'].str.contains('gan'),'method'] = 'gan'\n",
    "df_long.loc[df_long['model'].str.contains('sd_finetuning'),'method'] = 'finetuning'\n",
    "df_long.loc[df_long['model'].str.contains('sd_dreambooth'),'method'] = 'dreambooth'\n",
    "df_long.loc[df_long['model'].str.contains('unconditional'),'method'] = 'unconditional'\n",
    "df_long.loc[df_long['model'].str.contains('sd_lora_1e5_scale1'),'method'] = 'lora'\n",
    "df_long.loc[df_long['model'].str.contains('Baseline'),'method'] = 'baseline'\n",
    "df_long = df_long.drop('model',axis=1)\n",
    "\n",
    "# swap F and H due to different naming in df between baseline and synthetic\n",
    "df_long.loc[df_long['method'] != 'baseline','class'] = df_long.loc[df_long['method'] != 'baseline','class'].map({'B' : 'B','C' : 'C', 'H' : 'F', 'F' : 'H', 'V' : 'V'})\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beste Image brackets pro Methode für ConvNeXt-S, gemessen an Accuracy:\n",
    "* dreambooth: +100 oder +1000, sind identisch, aber +1000 deutlich besser über alle Architekturen\n",
    "* finetuning: +100\n",
    "* gan: +10000\n",
    "* lora: +250\n",
    "* unconditional: +250 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_method_image_brackets = {'baseline' : 'baseline',\n",
    "                              'dreambooth' : '1000',\n",
    "                              'finetuning' : '100',\n",
    "                              'gan' : '10000',\n",
    "                              'lora' : '250',\n",
    "                              'unconditional' : '250'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model & B & C & F & H & V \\\\ \\midrule\n",
      "Precision \\\\\n",
      "baseline & .326 $\\pm$ .0498 & .8292 $\\pm$ .0573 & .4946 $\\pm$ .0141 & .9641 $\\pm$ .0028 & .1329 $\\pm$ .1097 \\\\\n",
      "dreambooth & .4618 $\\pm$ .055 & .7466 $\\pm$ .0933 & .5085 $\\pm$ .0592 & .9368 $\\pm$ .0209 & .1826 $\\pm$ .1581 \\\\\n",
      "finetuning & .2955 $\\pm$ .151 & .7164 $\\pm$ .0696 & .6073 $\\pm$ .0537 & .9503 $\\pm$ .0221 & .5112 $\\pm$ .1291 \\\\\n",
      "gan & .4569 $\\pm$ .0595 & .8144 $\\pm$ .1343 & .5506 $\\pm$ .0414 & .9348 $\\pm$ .0179 & .0848 $\\pm$ .1291 \\\\\n",
      "lora & .3778 $\\pm$ .0697 & .716 $\\pm$ .1297 & .5669 $\\pm$ .0936 & .9501 $\\pm$ .0029 & .3738 $\\pm$ .0928 \\\\\n",
      "unconditional & .4254 $\\pm$ .1318 & .7038 $\\pm$ .0405 & .639 $\\pm$ .0673 & .9391 $\\pm$ .0135 & .4383 $\\pm$ .1233 \\\\\n",
      "\n",
      "Recall \\\\\n",
      "baseline & .3474 $\\pm$ .0976 & .7478 $\\pm$ .0928 & .5517 $\\pm$ .0899 & .9923 $\\pm$ .0049 & .1 $\\pm$ .0848 \\\\\n",
      "dreambooth & .3684 $\\pm$ .1104 & .8174 $\\pm$ .0174 & .5034 $\\pm$ .1536 & .9954 $\\pm$ .0038 & .1375 $\\pm$ .1275 \\\\\n",
      "finetuning & .3474 $\\pm$ .2297 & .7478 $\\pm$ .0887 & .6276 $\\pm$ .1142 & .9892 $\\pm$ .0062 & .2375 $\\pm$ .0468 \\\\\n",
      "gan & .4 $\\pm$ .1511 & .8 $\\pm$ .0443 & .5931 $\\pm$ .2108 & .9877 $\\pm$ .0038 & .0875 $\\pm$ .1458 \\\\\n",
      "lora & .3053 $\\pm$ .0614 & .8087 $\\pm$ .0976 & .4138 $\\pm$ .1731 & .9954 $\\pm$ .0038 & .3625 $\\pm$ .1075 \\\\\n",
      "unconditional & .2842 $\\pm$ .0714 & .7826 $\\pm$ .1603 & .669 $\\pm$ .0516 & .9923 $\\pm$ .0 & .2625 $\\pm$ .0729 \\\\\n",
      "\n",
      "F1-Score \\\\\n",
      "baseline & .3307 $\\pm$ .0579 & .7793 $\\pm$ .0296 & .5179 $\\pm$ .0386 & .978 $\\pm$ .0016 & .1136 $\\pm$ .0949 \\\\\n",
      "dreambooth & .3943 $\\pm$ .0486 & .7767 $\\pm$ .0456 & .499 $\\pm$ .0983 & .9651 $\\pm$ .0109 & .1452 $\\pm$ .1224 \\\\\n",
      "finetuning & .3071 $\\pm$ .1677 & .7252 $\\pm$ .0324 & .6069 $\\pm$ .034 & .9692 $\\pm$ .0112 & .3164 $\\pm$ .0465 \\\\\n",
      "gan & .4054 $\\pm$ .055 & .7983 $\\pm$ .0536 & .5507 $\\pm$ .0959 & .9604 $\\pm$ .0093 & .0854 $\\pm$ .1368 \\\\\n",
      "lora & .3272 $\\pm$ .0304 & .7447 $\\pm$ .0428 & .4613 $\\pm$ .1171 & .9722 $\\pm$ .003 & .3546 $\\pm$ .066 \\\\\n",
      "unconditional & .3321 $\\pm$ .0764 & .7325 $\\pm$ .0906 & .6497 $\\pm$ .0341 & .9649 $\\pm$ .0071 & .3266 $\\pm$ .0876 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_names = {'Precision' : 'precision',\n",
    "                  'Recall' : 'recall',\n",
    "                  'F1-Score' : 'f1'}\n",
    "print('model & B & C & F & H & V \\\\\\\\ \\midrule')\n",
    "for metric_name,metric in metric_names.items():\n",
    "    print(f'{metric_name} \\\\\\\\')\n",
    "    values = []\n",
    "    for (method,image_bracket),stat in itertools.product(best_method_image_brackets.items(),['mean','std']):\n",
    "        filt_df = df_long[(df_long['architecture'] == 'ConvNeXt_small') & (df_long['var'] == metric) & (df_long['images'] == image_bracket) & (df_long['method'] == method) & (df_long['aggfunc'] == stat)]\n",
    "        filt_df_pivot = filt_df.pivot_table(columns='class',values='value',aggfunc=max)\n",
    "        values.append(filt_df_pivot.values.tolist())\n",
    "        \n",
    "    \n",
    "    for i,(method,_) in enumerate(best_method_image_brackets.items()):\n",
    "        mean_values = values[i*2][0]\n",
    "        std_values = values[i*2+1][0]\n",
    "        combined = [x for row in list(zip(mean_values,std_values)) for x in row]\n",
    "        print(f'{method} & {list_to_latex(combined,two_elements=True)} \\\\\\\\')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>F</th>\n",
       "      <th>H</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class       B       C       F       H       V\n",
       "value  0.0764  0.0906  0.0341  0.0071  0.0876"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt_df_pivot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
